
File path: init_app_files.py:
import os
import logging
import json
import yaml
from typing import List, Dict, Any

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.constants.default_config import DEFAULT_CONFIG_VALUES
from leetcode_cli.constants.default_formatting_config import (
    DEFAULT_FORMATTING_CONFIG_YAML,
)

logger = logging.getLogger(__name__)


def initialize_leetcode_cli():
    """
    Main entry point to ensure all necessary files and folders exist in ~/.leetcode/.
    This function is idempotent—safe to call multiple times without harm.
    """
    try:
        # Instantiate the config_manager
        config_manager = ConfigManager()
        # Grab the paths
        config_dir = config_manager.config_dir
        config_path = config_manager.config_path

        _ensure_config_directory(config_dir)
        _ensure_config_file_exists(config_path)
        _ensure_minimum_config_fields(config_manager)

        _ensure_formatting_config_file_exists(config_dir)
        _ensure_minimum_formatting_config_fields(config_dir)

        # Use the theme manager to get the themes_dir
        theme_manager = ThemeManager(config_manager)
        themes_dir = theme_manager.get_themes_dir()
        _ensure_themes_directory(themes_dir)

        available_themes = _discover_available_themes()
        for theme_name in available_themes:
            _ensure_theme_folder(theme_name, theme_manager)

    except Exception as e:
        logger.error(f"Failed to initialize LeetCode CLI: {e}", exc_info=True)
        raise


def _ensure_config_directory(config_dir: str):
    """
    Creates ~/.leetcode directory if it does not exist.
    """
    try:
        os.makedirs(config_dir, exist_ok=True)
        logger.info(f"Ensured configuration directory exists at '{config_dir}'.")

    except Exception as e:
        logger.error(f"Error creating configuration directory '{config_dir}': {e}")
        raise


def _ensure_config_file_exists(config_path: str):
    """
    Creates ~/.leetcode/config.json file if it does not exist.
    """
    if not os.path.exists(config_path):
        try:
            with open(config_path, "w", encoding="utf-8") as f:
                json.dump({}, f, indent=4)

            logger.info(f"Created empty config.json at '{config_path}'.")

        except Exception as e:
            logger.error(f"Error creating config.json at '{config_path}': {e}")
            raise

    else:
        logger.debug(f"config.json at '{config_path}' already exists.")


def _ensure_minimum_config_fields(config_manager: ConfigManager):
    config = config_manager.config
    updated = False

    for key, default_value in DEFAULT_CONFIG_VALUES.items():
        if key not in config:
            config[key] = default_value
            logger.warning(f"Config missing '{key}', setting default: {default_value}")
            updated = True

    if updated:
        config_manager.save_config()
        logger.info("Updated config.json with missing default fields.")

    else:
        logger.debug("No missing fields in config.json; no updates needed.")


def _ensure_formatting_config_file_exists(config_dir: str):
    """
    Creates ~/.leetcode/formatting_config.yaml if it does not exist,
    or re-creates it if the existing file is corrupted/unusable.
    """
    formatting_path = os.path.join(config_dir, "formatting_config.yaml")

    if not os.path.exists(formatting_path):
        try:
            with open(formatting_path, "w", encoding="utf-8") as f:
                f.write(DEFAULT_FORMATTING_CONFIG_YAML)

            logger.info(
                f"Created default formatting_config.yaml at '{formatting_path}'."
            )

        except Exception as e:
            logger.error(
                f"Error creating formatting_config.yaml at '{formatting_path}': {e}"
            )
            raise e

        return

    # If it already exists, verify it's valid YAML
    try:
        with open(formatting_path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
            if not isinstance(data, dict):
                raise ValueError("formatting_config.yaml is not a valid dictionary.")

        logger.debug("formatting_config.yaml is valid.")

    except (yaml.YAMLError, ValueError) as e:
        logger.warning(
            f"formatting_config.yaml is corrupted or invalid: {e}. Recreating from defaults."
        )

        try:
            with open(formatting_path, "w", encoding="utf-8") as f:
                f.write(DEFAULT_FORMATTING_CONFIG_YAML)

            logger.info(f"Recreated formatting_config.yaml at '{formatting_path}'.")

        except Exception as ex:
            logger.error(
                f"Error recreating formatting_config.yaml at '{formatting_path}': {ex}"
            )
            raise ex


def _ensure_minimum_formatting_config_fields(config_dir: str):
    """
    Fills ~/.leetcode/formatting_config.yaml with top-level sections
    if they’re missing (e.g., 'interpretation', 'submission', 'problem_show').
    """
    formatting_path = os.path.join(config_dir, "formatting_config.yaml")

    try:
        with open(formatting_path, "r", encoding="utf-8") as f:
            user_data = yaml.safe_load(f) or {}

        default_data = yaml.safe_load(DEFAULT_FORMATTING_CONFIG_YAML)
        updated = False

        for key, default_section in default_data.items():
            if key not in user_data:
                user_data[key] = default_section
                logger.warning(
                    f"formatting_config.yaml missing '{key}', adding defaults."
                )
                updated = True

        if updated:
            with open(formatting_path, "w", encoding="utf-8") as f:
                yaml.dump(user_data, f, sort_keys=False)
            logger.info("Updated formatting_config.yaml with missing sections.")
        else:
            logger.debug(
                "No missing sections in formatting_config.yaml; no updates needed."
            )

    except Exception as e:
        logger.error(f"Error ensuring minimum formatting config fields: {e}")
        raise e


def _ensure_themes_directory(themes_dir: str):
    """
    Creates ~/.leetcode/themes directory if it doesn't exist.
    """
    try:
        os.makedirs(themes_dir, exist_ok=True)
        logger.info(f"Ensured themes directory exists at '{themes_dir}'.")

    except Exception as e:
        logger.error(f"Error creating themes directory '{themes_dir}': {e}")
        raise e


def _discover_available_themes() -> List[str]:
    """
    Discovers available themes by listing subdirectories in the constants/themes directory.
    Returns a list of theme names.
    """
    themes_constants_dir = os.path.join(
        os.path.dirname(__file__), "constants", "themes"
    )
    try:
        themes = [
            name
            for name in os.listdir(themes_constants_dir)
            if os.path.isdir(os.path.join(themes_constants_dir, name))
            and not name.startswith("__")
        ]

        logger.info(f"Discovered themes: {themes}")

        return themes

    except Exception as e:
        logger.error(
            f"Error discovering available themes in '{themes_constants_dir}': {e}"
        )
        raise e


def _ensure_theme_folder(theme_name: str, theme_manager: ThemeManager):
    """
    Ensures that a theme folder exists in ~/.leetcode/themes/{theme_name},
    and that it contains the necessary YAML files (ansi_codes.yaml, symbols.yaml, mappings.yaml).
    """
    themes_dir = theme_manager.get_themes_dir()
    theme_constants_dir = os.path.join(
        os.path.dirname(__file__), "constants", "themes", theme_name
    )
    theme_user_dir = os.path.join(themes_dir, theme_name)

    try:
        os.makedirs(theme_user_dir, exist_ok=True)
        logger.info(f"Ensured theme directory exists at '{theme_user_dir}'.")

    except Exception as e:
        logger.error(f"Error creating theme directory '{theme_user_dir}': {e}")
        raise e

    yaml_files = {
        "ansi_codes.yaml": "ANSI_CODES_YAML",
        "symbols.yaml": "SYMBOLS_YAML",
        "mappings.yaml": "MAPPINGS_YAML",
    }

    for filename, var_name in yaml_files.items():
        _write_yaml_if_missing(theme_constants_dir, theme_user_dir, filename, var_name)


def _write_yaml_if_missing(
    source_dir: str, target_dir: str, filename: str, variable_name: str
):
    """
    Helper to create the theme YAML file if it doesn't exist already by extracting
    the YAML content from the corresponding Python module variable.
    """
    source_file = os.path.join(source_dir, f"{filename.replace('.yaml', '')}_yaml.py")
    target_file = os.path.join(target_dir, filename)

    if not os.path.exists(target_file):
        try:
            yaml_content = _extract_yaml_from_py(source_file, variable_name)
            if yaml_content:
                with open(target_file, "w", encoding="utf-8") as f:
                    f.write(yaml_content)
                logger.info(f"Created '{filename}' in '{target_dir}'.")

            else:
                logger.error(
                    f"YAML content for '{variable_name}' not found in '{source_file}'."
                )

        except Exception as e:
            logger.error(f"Error writing '{filename}' in '{target_dir}': {e}")
            raise e

    else:
        logger.debug(f"'{filename}' already exists in '{target_dir}'; not overwriting.")


def _extract_yaml_from_py(file_path: str, variable_name: str) -> str:
    """
    Safely extracts the YAML string from a Python file by executing it in a controlled namespace.
    Returns the YAML string if found, else an empty string.
    """
    namespace: Dict[str, Any] = {}
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            exec(f.read(), namespace)

        yaml_content = namespace.get(variable_name, "")

        if not isinstance(yaml_content, str):
            logger.error(
                f"Variable '{variable_name}' in '{file_path}' is not a string."
            )
            return ""

        return yaml_content

    except Exception as e:
        logger.error(f"Error extracting '{variable_name}' from '{file_path}': {e}")

        return ""


if __name__ == "__main__":
    initialize_leetcode_cli()

File path: cli.py:
import logging
import click

from leetcode_cli.commands.config import config_cmd
from leetcode_cli.commands.list_problems import list_cmd
from leetcode_cli.commands.show_problem import show_cmd
from leetcode_cli.commands.show_random import random_cmd
from leetcode_cli.commands.submit import submit_cmd
from leetcode_cli.commands.test_solution import test_cmd
from leetcode_cli.commands.download_problems import download_problems_cmd
from leetcode_cli.commands.stats import stats_cmd
from leetcode_cli.commands.create_solution import create_cmd
from leetcode_cli.commands.theme import theme_cmd

from leetcode_cli.init_app_files import initialize_leetcode_cli


class OrderedGroup(click.Group):
    def list_commands(self, ctx):
        """List commands in the order they were added."""
        return self.commands.keys()


def configure_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
        handlers=[logging.StreamHandler()],
    )


@click.group(
    cls=OrderedGroup,
    context_settings=dict(help_option_names=["-h", "--help"], max_content_width=200),
)
@click.pass_context
def cli(ctx):
    """
    LeetCode CLI Tool

    Manage your LeetCode activities directly from the command line.
    """
    if ctx.invoked_subcommand is None:
        click.echo(cli.get_help(ctx))


cli.add_command(list_cmd, "list")
cli.add_command(show_cmd, "show")
cli.add_command(random_cmd, "random")
cli.add_command(create_cmd, "create")
cli.add_command(test_cmd, "test")
cli.add_command(submit_cmd, "submit")
cli.add_command(stats_cmd, "stats")
cli.add_command(config_cmd, "config")
cli.add_command(theme_cmd, "theme")
cli.add_command(download_problems_cmd, "download-problems")


def main():
    configure_logging()
    # Optionally disable critical logs; up to you:
    logging.disable(logging.CRITICAL)

    initialize_leetcode_cli()
    cli()


if __name__ == "__main__":
    main()

File path: parsers/stats_data_parser.py:
# file: leetcode_cli/parsers/stats_data_parser.py

import logging
from typing import Dict, Any
from leetcode_cli.models.stats import UserStatsModel
from leetcode_cli.exceptions.exceptions import ParsingError

logger = logging.getLogger(__name__)


def parse_user_stats_data(json_data: Dict[str, Any]) -> UserStatsModel:
    """
    Parse the raw stats JSON into a UserStatsModel (accepted/failed/untouched).
    """
    try:
        user_progress = json_data["data"]["userProfileUserQuestionProgressV2"]
        accepted = {
            item["difficulty"].upper(): item["count"]
            for item in user_progress.get("numAcceptedQuestions", [])
        }
        failed = {
            item["difficulty"].upper(): item["count"]
            for item in user_progress.get("numFailedQuestions", [])
        }
        untouched = {
            item["difficulty"].upper(): item["count"]
            for item in user_progress.get("numUntouchedQuestions", [])
        }
        return UserStatsModel(accepted=accepted, failed=failed, untouched=untouched)

    except KeyError as e:
        logger.error(f"Missing key in stats data: {e}")
        raise ParsingError(f"Missing key in stats data: {e}")

    except TypeError as e:
        logger.error(f"Invalid structure in stats data: {e}")
        raise ParsingError(f"Invalid structure in stats data: {e}")


def parse_single_year_calendar(json_data: Dict[str, Any]) -> Dict[int, int]:
    """
    Parse the raw JSON for a single year's userCalendar submissionCalendar
    into a dict {timestamp: submissionCount}, without join/fill logic.
    """
    try:
        matched = json_data["data"]["matchedUser"]
        calendar_str = matched["userCalendar"][
            "submissionCalendar"
        ]  # e.g. "{\"1620000000\":1, ...}"
    except (KeyError, TypeError) as e:
        logger.error(f"Missing or invalid calendar data: {e}")
        raise ParsingError(f"Missing or invalid calendar data: {e}")

    import json

    try:
        calendar_dict = json.loads(calendar_str)  # { "1620000000": 1, ...}
        # Convert keys to int
        parsed_calendar = {int(k): v for k, v in calendar_dict.items()}
        return parsed_calendar
    except json.JSONDecodeError as e:
        logger.error(f"Error decoding submissionCalendar JSON: {e}")
        raise ParsingError(f"Invalid submissionCalendar JSON: {e}")

File path: parsers/submission_result_parser.py:
from typing import Dict, Any
from leetcode_cli.exceptions.exceptions import ParsingError
from leetcode_cli.models.submission import SubmissionResult


def parse_submission_result(json_data: Dict[str, Any]) -> SubmissionResult:
    # Define required fields
    required_fields = [
        "status_code",
        "status_msg",
        "lang",
        "run_success",
        "status_runtime",
        "memory",
        "state",
    ]

    # Validate required fields
    for field in required_fields:
        if field not in json_data:
            raise ParsingError(
                f"Missing required field '{field}' in submission result data."
            )

    """
    run_success = bool(json_data["run_success"])
    if not run_success:
        # If run was unsuccessful, at least one error field should be present
        error_fields = ["runtime_error", "compile_error"]
        if not any(json_data.get(error) for error in error_fields):
            raise ParsingError("Run failed but no error message provided in 'runtime_error' or 'compile_error'.")
    """

    return SubmissionResult(
        status_code=int(json_data["status_code"]),
        lang=str(json_data["lang"]),
        run_success=bool(json_data["run_success"]),
        runtime_error=json_data.get("runtime_error"),
        full_runtime_error=json_data.get("full_runtime_error"),
        compile_error=json_data.get("compile_error"),
        full_compile_error=json_data.get("full_compile_error"),
        status_runtime=str(json_data.get("status_runtime", "")),
        memory=int(json_data.get("memory", 0)),
        display_runtime=str(json_data.get("display_runtime", "")),
        question_id=json_data.get("question_id"),
        elapsed_time=json_data.get("elapsed_time"),
        compare_result=json_data.get("compare_result"),
        code_output=json_data.get("code_output"),
        std_output=json_data.get("std_output"),
        last_testcase=json_data.get("last_testcase"),
        expected_output=json_data.get("expected_output"),
        task_finish_time=json_data.get("task_finish_time"),
        task_name=json_data.get("task_name"),
        finished=json_data.get("finished"),
        total_correct=json_data.get("total_correct"),
        total_testcases=json_data.get("total_testcases"),
        runtime_percentile=json_data.get("runtime_percentile"),
        status_memory=json_data.get("status_memory"),
        memory_percentile=json_data.get("memory_percentile"),
        pretty_lang=json_data.get("pretty_lang"),
        submission_id=json_data.get("submission_id"),
        input_formatted=json_data.get("input_formatted"),
        input=json_data.get("input"),
        status_msg=str(json_data["status_msg"]),
        state=str(json_data["state"]),
    )

File path: parsers/problemset_data_parser.py:
from typing import Dict, Any
from leetcode_cli.exceptions.exceptions import ParsingError
from leetcode_cli.models.problemset import ProblemSet, ProblemSummary


def parse_problemset_data(json_data: Dict[str, Any]) -> ProblemSet:
    """
    Parses the JSON returned by fetch_problemset into a ProblemSet model.
    """
    if "data" not in json_data or "problemsetQuestionList" not in json_data["data"]:
        raise ParsingError(
            "Invalid problemset data structure: 'data.problemsetQuestionList' key not found."
        )

    plist = json_data["data"]["problemsetQuestionList"]

    if "questions" not in plist or "total" not in plist:
        raise ParsingError("Missing 'questions' or 'total' in problemset data.")

    total = plist["total"]
    questions_data = plist["questions"]

    questions = []
    for q in questions_data:
        # Validate required fields
        required_fields = [
            "acRate",
            "difficulty",
            "questionId",
            "topicTags",
            "frontendQuestionId",
            "paidOnly",
            "status",
            "title",
            "titleSlug",
        ]
        for field in required_fields:
            if field not in q:
                raise ParsingError(f"Missing '{field}' in question data.")

        # Extract topic tags (list of slugs)
        topic_slugs = [tag["slug"] for tag in q.get("topicTags", []) if "slug" in tag]

        summary = ProblemSummary(
            ac_rate=float(q["acRate"]),
            difficulty=q["difficulty"],
            question_id=str(q["questionId"]),
            topic_tags=topic_slugs,
            frontend_question_id=str(q["frontendQuestionId"]),
            paid_only=bool(q["paidOnly"]),
            status=q["status"],
            title=q["title"],
            title_slug=q["titleSlug"],
        )
        questions.append(summary)

    return ProblemSet(total=total, questions=questions)

File path: parsers/interpretation_result_parser.py:
from typing import Dict, Any

from leetcode_cli.models.interpretation import InterpretationResult
from leetcode_cli.exceptions.exceptions import ParsingError


def parse_interpretation_result(json_data: Dict[str, Any]) -> InterpretationResult:
    # Define required fields
    required_fields = [
        "status_code",
        "status_msg",
        "lang",
        "run_success",
        "code_answer",
        "code_output",
        "std_output_list",
        "state",
        "memory",
        "status_runtime",
    ]

    # Validate required fields
    for field in required_fields:
        if field not in json_data:
            raise ParsingError(
                f"Missing required field '{field}' in interpretation result data."
            )

    # Parse and assign each field, providing defaults where necessary
    return InterpretationResult(
        status_code=int(json_data["status_code"]),
        lang=str(json_data["lang"]),
        run_success=bool(json_data["run_success"]),
        runtime_error=json_data.get("runtime_error"),
        full_runtime_error=json_data.get("full_runtime_error"),
        compile_error=json_data.get("compile_error"),
        full_compile_error=json_data.get("full_compile_error"),
        status_runtime=str(json_data.get("status_runtime", "")),
        memory=int(json_data.get("memory", 0)),
        display_runtime=str(json_data.get("display_runtime", "")),
        code_answer=list(json_data.get("code_answer", [])),
        code_output=list(json_data.get("code_output", [])),
        std_output_list=list(json_data.get("std_output_list", [])),
        elapsed_time=json_data.get("elapsed_time"),
        task_finish_time=json_data.get("task_finish_time"),
        task_name=json_data.get("task_name"),
        expected_status_code=json_data.get("expected_status_code"),
        expected_lang=json_data.get("expected_lang"),
        expected_run_success=json_data.get("expected_run_success"),
        expected_status_runtime=json_data.get("expected_status_runtime"),
        expected_memory=json_data.get("expected_memory"),
        expected_display_runtime=json_data.get("expected_display_runtime"),
        expected_code_answer=json_data.get("expected_code_answer"),
        expected_code_output=json_data.get("expected_code_output"),
        expected_std_output_list=json_data.get("expected_std_output_list"),
        expected_elapsed_time=json_data.get("expected_elapsed_time"),
        expected_task_finish_time=json_data.get("expected_task_finish_time"),
        expected_task_name=json_data.get("expected_task_name"),
        correct_answer=json_data.get("correct_answer"),
        compare_result=json_data.get("compare_result"),
        total_correct=json_data.get("total_correct"),
        total_testcases=json_data.get("total_testcases"),
        runtime_percentile=json_data.get("runtime_percentile"),
        status_memory=json_data.get("status_memory"),
        memory_percentile=json_data.get("memory_percentile"),
        pretty_lang=json_data.get("pretty_lang"),
        submission_id=json_data.get("submission_id"),
        status_msg=str(json_data["status_msg"]),
        state=str(json_data["state"]),
    )

File path: parsers/problem_data_parser.py:
import json
from typing import Dict
from bs4 import BeautifulSoup, Tag, NavigableString

from leetcode_cli.models.problem import Problem


def parse_problem_data(json_data: Dict) -> Problem:
    """
    Parses raw JSON data of a LeetCode problem and returns a Problem instance.

    Args:
        json_data (Dict): The raw JSON data containing problem details.

    Returns:
        Problem: An instance of the Problem dataclass populated with parsed data.
    """
    question = json_data.get("data", {}).get("question", {})

    # Extract basic fields
    title = question.get("title", "")
    question_frontend_id = question.get("questionFrontendId", "")
    category_title = question.get("categoryTitle", "")
    difficulty = question.get("difficulty", "")
    topic_tags = [tag.get("name", "") for tag in question.get("topicTags", [])]

    # Parsing stats
    stats_str = question.get("stats", "{}")
    try:
        stats = json.loads(stats_str)
    except json.JSONDecodeError:
        stats = {}

    likes = question.get("likes", 0)
    dislikes = question.get("dislikes", 0)
    is_paid_only = question.get("isPaidOnly", False)
    solution_info = question.get("solution")
    code_snippets = question.get("codeSnippets", [])

    # Parsing HTML content
    content_html = question.get("content", "") or ""
    soup = BeautifulSoup(content_html, "html.parser")

    description_parts = []
    examples = []
    constraints = []

    # Whether we have begun parsing examples
    in_examples = False

    # Iterate through all top-level elements
    for elem in soup.find_all(recursive=False):
        # A <p> with <strong class="example"> indicates the start of an example
        if elem.name == "p":
            strong_example = elem.find("strong", class_="example")
            if strong_example:
                in_examples = True
                # e.g. "Example 1:", "Example 2:"
                example_title = strong_example.get_text(strip=True).rstrip(":")

                # We'll attempt two patterns:
                #   A) If next sibling is <div class="example-block"> => parse that
                #   B) Else walk siblings to find a <pre> (old style)

                # Let's find siblings until we see either <div class="example-block"> or <pre> or we run out
                sibling = elem.next_sibling
                pre_tag = None
                example_div = None

                while sibling:
                    if isinstance(sibling, Tag):
                        # Check if it's a <div class="example-block">
                        if sibling.name == "div" and "example-block" in sibling.get(
                            "class", []
                        ):
                            example_div = sibling
                            break
                        # Or if it's <pre> (old style approach)
                        if sibling.name == "pre":
                            pre_tag = sibling
                            break
                    sibling = sibling.next_sibling

                # Now parse accordingly
                if example_div:
                    # Newer approach: parse the <div class="example-block"> for p strong: "Input", "Output", "Explanation"
                    ex_obj = _parse_div_example_block(example_title, example_div)
                    examples.append(ex_obj)

                elif pre_tag:
                    # Old approach: parse <pre> for strong "Input"/"Output"/"Explanation"
                    ex_obj = _parse_pre_example_block(example_title, pre_tag)
                    examples.append(ex_obj)

                # Move on to next top-level element
                continue

            # Check if it’s constraints
            strong_constraints = elem.find("strong")
            if strong_constraints and "Constraints" in strong_constraints.get_text():
                ul = elem.find_next_sibling("ul")
                if ul:
                    for li in ul.find_all("li"):
                        constraints.append(li.decode_contents().strip())
                continue

        # If we haven't hit examples yet, it's description
        if not in_examples:
            description_parts.append(str(elem))

    # Combine description parts
    description = "".join(description_parts).strip()

    # Create the Problem instance
    problem = Problem(
        title=title,
        question_frontend_id=question_frontend_id,
        description=description,
        examples=examples,
        constraints=constraints,
        category_title=category_title,
        difficulty=difficulty,
        topic_tags=topic_tags,
        stats=stats,
        likes=likes,
        dislikes=dislikes,
        is_paid_only=is_paid_only,
        solution_info=solution_info,
        code_snippets=code_snippets,
    )

    return problem


def _parse_div_example_block(example_title: str, example_div: Tag) -> dict:
    """
    Handles the 'newer' style examples that look like:
      <div class="example-block">
         <p><strong>Input:</strong> ...</p>
         <p><strong>Output:</strong> ...</p>
         <p><strong>Explanation:</strong> ...</p>
         ...
      </div>

    Returns a dict { "title", "input", "output", "explanation" }
    """
    example = {
        "title": example_title,
        "input": [],
        "output": "",
        "explanation": "",
    }

    # We look for direct <p> tags with <strong> text like "Input:", "Output:", "Explanation:"
    # or variations. We'll store them accordingly.
    # If we want to be robust, we can also handle <ul> or subsequent lines for explanation.

    # For each <p> inside example_div:
    for p_tag in example_div.find_all("p", recursive=False):
        strong_tag = p_tag.find("strong")
        if not strong_tag:
            continue
        label_text = strong_tag.get_text(strip=True).rstrip(":").lower()
        # The content is the text outside the strong tag
        # e.g. in <p><strong>Input:</strong> <span>nums=...</span></p>
        # we want to gather the rest of the text or <span> after the strong
        # We'll do so by taking p_tag.get_text... but that might re-include "Input:" if not careful.

        # We'll build the content by ignoring the <strong> text:
        content = ""
        # after we skip the <strong> itself, gather siblings
        for sib in strong_tag.next_siblings:
            if isinstance(sib, NavigableString):
                content += sib.strip()
            elif isinstance(sib, Tag):
                content += sib.get_text(separator=" ", strip=True)

        content = content.strip()

        if label_text == "input":
            # We do example["input"].append(...) or combine
            if content:
                example["input"].append(content)
        elif label_text == "output":
            example["output"] = content
        elif label_text == "explanation":
            example["explanation"] = content

    # Some example-blocks might have extra stuff (like <ul> for explanation),
    # so optionally we can parse more. For now, let's keep it simple.

    return example


def _parse_pre_example_block(example_title: str, pre_tag: Tag) -> dict:
    """
    Handles the 'old' style example using <pre> with multiple <strong> sections
    for "Input", "Output", "Explanation".
    """
    example = {
        "title": example_title,
        "input": [],
        "output": "",
        "explanation": "",
    }

    # Find all <strong> tags
    strong_tags = pre_tag.find_all("strong")
    current_section = None

    from bs4 import NavigableString, Tag

    for strong in strong_tags:
        section_title = strong.get_text(strip=True).rstrip(":").lower()
        current_section = section_title

        # Gather text after this <strong> until next <strong>
        content = ""
        for sibling in strong.next_siblings:
            if isinstance(sibling, Tag) and sibling.name == "strong":
                break
            elif isinstance(sibling, Tag):
                content += sibling.get_text(separator=" ", strip=True)
            elif isinstance(sibling, NavigableString):
                content += sibling.strip()

        if current_section == "input":
            if content:
                example["input"].append(content)
        elif current_section == "output":
            if content:
                example["output"] += content
        elif current_section == "explanation":
            # For explanation, capture all remaining content
            explanation_content = []
            for sib in strong.next_siblings:
                if isinstance(sib, Tag) and sib.name == "strong":
                    break
                elif isinstance(sib, Tag):
                    explanation_content.append(str(sib))
                elif isinstance(sib, NavigableString):
                    explanation_content.append(sib.strip())
            example["explanation"] = "".join(explanation_content).strip()

    return example

File path: data_fetchers/stats_data_fetcher.py:
import requests
import logging

from leetcode_cli.data_fetchers.graphql_queries import GRAPHQL_URL, GRAPHQL_QUERIES
from leetcode_cli.exceptions.exceptions import FetchingError

logger = logging.getLogger(__name__)


def fetch_user_stats(username):
    query = GRAPHQL_QUERIES["user_problem_stats"]
    payload = {
        "query": query,
        "variables": {"userSlug": username},
        "operationName": "userProfileUserQuestionProgressV2",
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(
            f"Network error while fetching stats for user {username}: {e}"
        )

    except ValueError:
        raise FetchingError("Failed to parse JSON response while fetching user stats.")

    return result


def fetch_user_activity(username, year):
    query = GRAPHQL_QUERIES["user_calendar"]
    payload = {
        "query": query,
        "variables": {"username": username, "year": year},
        "operationName": "userProfileCalendar",
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(
            f"Network error while fetching user activity for {username} in {year}: {e}"
        )

    except ValueError:
        raise FetchingError(
            "Failed to parse JSON response while fetching user activity."
        )

    return result

File path: data_fetchers/code_snippet_fetcher.py:
import requests
import logging

from leetcode_cli.data_fetchers.graphql_queries import GRAPHQL_URL, GRAPHQL_QUERIES
from leetcode_cli.exceptions.exceptions import FetchingError

logger = logging.getLogger(__name__)


def fetch_code_snippet(title_slug, lang_slug):
    query = GRAPHQL_QUERIES["code_snippets"]
    payload = {"query": query, "variables": {"titleSlug": title_slug}}

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(
            f"Network error while fetching code snippet for {title_slug} in {lang_slug}: {e}"
        )

    except ValueError:
        raise FetchingError(
            "Failed to parse JSON response while fetching code snippet."
        )

    return result

File path: data_fetchers/interpretation_result_fetcher.py:
import requests
import time
from typing import Dict
from leetcode_cli.exceptions.exceptions import FetchingError


def fetch_interpretation_result(
    cookie: str,
    csrf_token: str,
    title_slug: str,
    code: str,
    language: str,
    testcases: str,
    question_id: int,
) -> Dict:
    """
    Fetch the 'Run Code' / interpretation result from LeetCode for a given problem.

    Args:
        cookie (str): User's session cookie.
        csrf_token (str): CSRF token for request validation.
        title_slug (str): The slug of the problem title.
        code (str): The user's code submission.
        language (str): The programming language of the submission.
        testcases (str): Testcases input as a string.
        question_id (int): The unique identifier for the problem.

    Returns:
        Dict: The interpretation result.

    Raises:
        FetchingError: If any step in the process fails.
    """
    submit_url = f"https://leetcode.com/problems/{title_slug}/interpret_solution/"
    payload = {
        "data_input": testcases,
        "lang": language,
        "question_id": question_id,
        "typed_code": code,
    }

    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0",
        "Cookie": cookie,
        "x-csrftoken": csrf_token,
        "Referer": f"https://leetcode.com/problems/{title_slug}/",
    }

    try:
        response = requests.post(submit_url, json=payload, headers=headers)
        response.raise_for_status()
        submission = response.json()

    except requests.RequestException as e:
        raise FetchingError(f"Submission failed: {e}")

    except ValueError:
        raise FetchingError("Invalid response format from LeetCode.")

    interpret_id = submission.get("interpret_id")
    if not interpret_id:
        raise FetchingError("Interpretation ID not received.")

    # Check interpretation status until complete
    check_submission_url = (
        f"https://leetcode.com/submissions/detail/{interpret_id}/check/"
    )
    while True:
        try:
            r = requests.get(check_submission_url, headers=headers)
            r.raise_for_status()
            result = r.json()

        except requests.RequestException as e:
            raise FetchingError(f"Failed to check interpretation: {e}")

        except ValueError:
            raise FetchingError("Invalid response format.")

        if result.get("state") == "SUCCESS":
            return result

        time.sleep(0.10)

File path: data_fetchers/submission_result_fetcher.py:
import requests
import time
from typing import Dict
from leetcode_cli.exceptions.exceptions import FetchingError


def fetch_submission_result(
    cookie: str,
    csrf_token: str,
    title_slug: str,
    code: str,
    language: str,
    question_id: int,
) -> Dict:
    """
    Fetches the final submission result from LeetCode (i.e., the "Submit" action).

    Args:
        cookie (str): User's session cookie.
        csrf_token (str): CSRF token for request validation.
        title_slug (str): The slug of the problem title.
        code (str): The user's code submission.
        language (str): The programming language of the submission.
        question_id (int): The unique identifier for the problem.

    Returns:
        Dict: The submission result.

    Raises:
        FetchingError: If any step in the process fails.
    """
    submit_url = f"https://leetcode.com/problems/{title_slug}/submit/"
    payload = {
        "lang": language,
        "question_id": str(question_id),
        "typed_code": code,
    }

    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0",
        "Cookie": cookie,
        "x-csrftoken": csrf_token,
        "Referer": f"https://leetcode.com/problems/{title_slug}/",
    }

    try:
        response = requests.post(submit_url, json=payload, headers=headers)
        response.raise_for_status()
        submission = response.json()

    except requests.RequestException as e:
        raise FetchingError(f"Submission failed: {e}")

    except ValueError:
        raise FetchingError("Invalid response format from LeetCode.")

    submission_id = submission.get("submission_id")
    if not submission_id:
        raise FetchingError("Submission ID not received.")

    # Poll for final status
    check_submission_url = (
        f"https://leetcode.com/submissions/detail/{submission_id}/check/"
    )
    while True:
        try:
            r = requests.get(check_submission_url, headers=headers)
            r.raise_for_status()
            result = r.json()

        except requests.RequestException as e:
            raise FetchingError(f"Failed to check submission: {e}")

        except ValueError:
            raise FetchingError("Invalid response format.")

        if result.get("state") == "SUCCESS":
            return result

        time.sleep(0.10)

File path: data_fetchers/graphql_queries.py:
GRAPHQL_URL = "https://leetcode.com/graphql"

GRAPHQL_QUERIES = {
    "user_problem_stats": """
        query userProfileUserQuestionProgressV2($userSlug: String!) {
          userProfileUserQuestionProgressV2(userSlug: $userSlug) {
            numAcceptedQuestions {
              count
              difficulty
            }
            numFailedQuestions {
              count
              difficulty
            }
            numUntouchedQuestions {
              count
              difficulty
            }
            userSessionBeatsPercentage {
              difficulty
              percentage
            }
            totalQuestionBeatsPercentage
          }
        }
    """,
    "user_calendar": """
        query userProfileCalendar($username: String!, $year: Int) {
          matchedUser(username: $username) {
            userCalendar(year: $year) {
              activeYears
              streak
              totalActiveDays
              dccBadges {
                timestamp
                badge {
                  name
                  icon
                }
              }
              submissionCalendar
            }
          }
        }
    """,
    "problemset_data": """
        query problemsetQuestionList($categorySlug: String, $limit: Int, $skip: Int, $filters: QuestionListFilterInput) {
          problemsetQuestionList: questionList(
            categorySlug: $categorySlug
            limit: $limit
            skip: $skip
            filters: $filters
          ) {
            total: totalNum
            questions: data {
              acRate
              difficulty
              questionId
              topicTags {
                slug
              }
              frontendQuestionId: questionFrontendId
              paidOnly: isPaidOnly
              status
              title
              titleSlug
            }
          }
        }
    """,
    "problemset_metadata": """
        query problemsetQuestionList($categorySlug: String, $limit: Int, $skip: Int, $filters: QuestionListFilterInput) {
          problemsetQuestionList: questionList(
            categorySlug: $categorySlug
            limit: $limit
            skip: $skip
            filters: $filters
          ) {
            total: totalNum
            questions: data {
              questionId
              frontendQuestionId: questionFrontendId
              titleSlug
            }
          }
        }
    """,
    "code_snippets": """
        query getQuestionDetail($titleSlug: String!) {
          question(titleSlug: $titleSlug) {
            questionId
            titleSlug
            codeSnippets {
              lang
              langSlug
              code
            }
          }
        }
    """,
    "problem_detail": """
        query questionDetail($titleSlug: String!) {
          question(titleSlug: $titleSlug) {
            title
            questionFrontendId
            questionTitle
            content
            categoryTitle
            difficulty
            topicTags {
              name
            }
            stats
            likes
            dislikes
            isPaidOnly
            solution {
              id
              paidOnly
              hasVideoSolution
              canSeeDetail
            }
            codeSnippets {
              lang
              langSlug
            }
          }
        }
    """,
    "random_title_slug": """
        query randomQuestion($categorySlug: String, $filters: QuestionListFilterInput) {
            randomQuestion(categorySlug: $categorySlug, filters: $filters) {
                titleSlug
            }
        }
    """,
    "problem_id": """
        query questionDetail($titleSlug: String!) {
          question(titleSlug: $titleSlug) {
            questionId
          }
        }
    """,
    "problem_frontend_id": """
        query questionDetail($titleSlug: String!) {
          question(titleSlug: $titleSlug) {
            questionFrontendId
          }
        }
    """,
    "problem_testcases": """
        query questionData($titleSlug: String!) {
          question(titleSlug: $titleSlug) {
            exampleTestcases
          }
        }
    """,
}

File path: data_fetchers/problem_data_fetcher.py:
import requests
import logging
from leetcode_cli.data_fetchers.graphql_queries import GRAPHQL_URL, GRAPHQL_QUERIES
from leetcode_cli.exceptions.exceptions import FetchingError

logger = logging.getLogger(__name__)


def fetch_problem_testcases(title_slug):
    query = GRAPHQL_QUERIES["problem_testcases"]
    payload = {
        "query": query,
        "variables": {"titleSlug": title_slug},
        "operationName": "questionData",
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(
            f"Network error while fetching testcases for {title_slug}: {e}"
        )

    except ValueError:
        raise FetchingError(
            "Failed to parse JSON response while fetching problem testcases."
        )

    return result


def fetch_problem_id(title_slug):
    query = GRAPHQL_QUERIES["problem_id"]
    payload = {
        "query": query,
        "variables": {"titleSlug": title_slug},
        "operationName": "questionDetail",
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(
            f"Network error while fetching problem ID for {title_slug}: {e}"
        )

    except ValueError:
        raise FetchingError("Failed to parse JSON response while fetching problem ID.")

    return result


def fetch_problem_frontend_id(title_slug):
    query = GRAPHQL_QUERIES["problem_frontend_id"]
    payload = {
        "query": query,
        "variables": {"titleSlug": title_slug},
        "operationName": "questionDetail",
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(
            f"Network error while fetching problem ID for {title_slug}: {e}"
        )

    except ValueError:
        raise FetchingError("Failed to parse JSON response while fetching problem ID.")

    return result


def fetch_random_title_slug(difficulty, tags):
    query = GRAPHQL_QUERIES["random_title_slug"]
    payload = {
        "query": query,
        "variables": {"categorySlug": "all-code-essentials", "filters": {}},
        "operationName": "randomQuestion",
    }

    if difficulty:
        payload["variables"]["filters"]["difficulty"] = difficulty

    if tags:
        payload["variables"]["filters"]["tags"] = tags

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(f"Netword error while fetching random title slug: {e}")

    except ValueError:
        raise FetchingError(
            "Failed to parse JSON response while fetching random title slug."
        )

    return result


def fetch_problem_data(title_slug):
    query = GRAPHQL_QUERIES["problem_detail"]
    payload = {
        "query": query,
        "variables": {"titleSlug": title_slug},
        "operationName": "questionDetail",
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(
            f"Network error while fetching problem data for {title_slug}: {e}"
        )

    except ValueError:
        raise FetchingError(
            "Failed to parse JSON response while fetching problem data."
        )

    return result

File path: data_fetchers/problemset_data_fetcher.py:
import requests
import logging

from leetcode_cli.data_fetchers.graphql_queries import GRAPHQL_QUERIES, GRAPHQL_URL
from leetcode_cli.exceptions.exceptions import FetchingError

logger = logging.getLogger(__name__)


def fetch_problemset(
    cookie=None, csrf_token=None, tags=None, difficulty=None, limit=50, skip=0
):
    query = GRAPHQL_QUERIES["problemset_data"]
    payload = {
        "query": query,
        "variables": {
            "categorySlug": "all-code-essentials",
            "skip": skip,
            "limit": limit,
            "filters": {},
        },
        "operationName": "problemsetQuestionList",
    }

    if tags:
        payload["variables"]["filters"]["tags"] = tags

    if difficulty:
        payload["variables"]["filters"]["difficulty"] = difficulty

    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0",
    }

    if cookie and csrf_token:
        headers["Cookie"] = cookie
        headers["x-csrftoken"] = csrf_token
        headers["Referer"] = "https://leetcode.com/problemset/"

    try:
        response = requests.post(GRAPHQL_URL, json=payload, headers=headers)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(f"Network error while fetching problemset: {e}")

    except ValueError:
        raise FetchingError("Failed to parse JSON response while fetching problemset.")

    return result


def fetch_problemset_metadata():
    query = GRAPHQL_QUERIES["problemset_metadata"]
    payload = {
        "query": query,
        "variables": {
            "categorySlug": "all-code-essentials",
            "skip": 0,
            "limit": 10000000,
            "filters": {},
        },
        "operationName": "problemsetQuestionList",
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        response.raise_for_status()
        result = response.json()

    except requests.RequestException as e:
        raise FetchingError(f"Network error while fetching problemset: {e}")

    except ValueError:
        raise FetchingError("Failed to parse JSON response while fetching problemset.")

    return result

File path: constants/stats_constants.py:
RECTANGLES_TOTAL = 66
DIFFICULTIES = ["EASY", "MEDIUM", "HARD"]
MONTH_NAMES = [
    "Jan",
    "Feb",
    "Mar",
    "Apr",
    "May",
    "Jun",
    "Jul",
    "Aug",
    "Sep",
    "Oct",
    "Nov",
    "Dec",
]
MONTH_SEPARATION = 3
COLUMNS = 100

File path: constants/problem_constants.py:
POSSIBLE_LANG_SLUGS = [
    "cpp",
    "java",
    "python",
    "python3",
    "c",
    "csharp",
    "javascript",
    "typescript",
    "php",
    "swift",
    "kotlin",
    "dart",
    "golang",
    "ruby",
    "scala",
    "rust",
    "racket",
    "erlang",
    "elixir",
]

POSSIBLE_FILE_EXTENSIONS = [
    "cpp",
    "java",
    "py",
    "py3",
    "c",
    "cs",
    "js",
    "ts",
    "php",
    "swift",
    "kt",
    "dart",
    "go",
    "rb",
    "scala",
    "rs",
    "rkt",
    "erl",
    "ex",
]

EXTENSION_TO_LANG_SLUG = {
    "cpp": "cpp",
    "java": "java",
    "py": "python",
    "py3": "python3",
    "c": "c",
    "cs": "csharp",
    "js": "javascript",
    "ts": "typescript",
    "php": "php",
    "swift": "swift",
    "kt": "kotlin",
    "dart": "dart",
    "go": "golang",
    "rb": "ruby",
    "scala": "scala",
    "rs": "rust",
    "rkt": "racket",
    "erl": "erlang",
    "ex": "elixir",
}

LANG_SLUG_TO_EXTENSION = {
    "cpp": "cpp",
    "java": "java",
    "python": "py",
    "python3": "py3",
    "c": "c",
    "csharp": "cs",
    "javascript": "js",
    "typescript": "ts",
    "php": "php",
    "swift": "swift",
    "kotlin": "kt",
    "dart": "dart",
    "golang": "go",
    "ruby": "rb",
    "scala": "scala",
    "rust": "rs",
    "racket": "rkt",
    "erlang": "erl",
    "elixir": "ex",
}

POSSIBLE_TAGS = [
    "array",
    "string",
    "hash-table",
    "dynamic-programming",
    "math",
    "sorting",
    "greedy",
    "depth-first-search",
    "binary-search",
    "database",
    "matrix",
    "tree",
    "breadth-first-search",
    "bit-manipulation",
    "two-pointers",
    "prefix-sum",
    "heap-priority-queue",
    "binary-tree",
    "simulation",
    "stack",
    "counting",
    "graph",
    "sliding-window",
    "design",
    "backtracking",
    "enumeration",
    "union-find",
    "linked-list",
    "ordered-set",
    "number-theory",
    "monotonic-stack",
    "trie",
    "segment-tree",
    "bitmask",
    "queue",
    "divide-and-conquer",
    "recursion",
    "combinatorics",
    "binary-search-tree",
    "hash-function",
    "memoization",
    "binary-indexed-tree",
    "geometry",
    "string-matching",
    "topological-sort",
    "shortest-path",
    "rolling-hash",
    "game-theory",
    "interactive",
    "data-stream",
    "monotonic-queue",
    "brainteaser",
    "randomized",
    "merge-sort",
    "doubly-linked-list",
    "counting-sort",
    "iterator",
    "concurrency",
    "probability-and-statistics",
    "quickselect",
    "suffix-array",
    "bucket-sort",
    "minimum-spanning-tree",
    "shell",
    "line-sweep",
    "reservoir-sampling",
    "strongly-connected-component",
    "eulerian-circuit",
    "radix-sort",
    "rejection-sampling",
    "biconnected-component",
]

File path: constants/default_formatting_config.py:
DEFAULT_FORMATTING_CONFIG_YAML = """# formatting_config.yaml
# This file configures how certain CLI outputs are displayed.

interpretation:
  show_language: true
  show_testcases: true
  show_expected_output: true
  show_code_output: true
  show_stdout: true
  show_error_messages: true
  show_detailed_error_messages: true

submission:
  show_language: true
  show_testcases: true
  show_runtime_memory: true
  show_code_output: true
  show_stdout: true
  show_error_messages: true
  show_detailed_error_messages: true
  show_expected_output: true

problem_show:
  show_title: true
  show_tags: true
  show_langs: true
  show_description: true
  show_examples: true
  show_constraints: true
"""

File path: constants/default_config.py:
DEFAULT_CONFIG_VALUES = {
    "cookie": "",
    "username": "",
    "language": "",
    "theme": "default_theme",
}

File path: constants/themes/default_theme/mappings_yaml.py:
MAPPINGS_YAML = """# This file unifies ANSI and symbol references under a single dictionary
# Each category (INTERPRETATION, SUBMISSION, PROBLEMSET, PROBLEM_DESCRIPTION, STATS_FORMATTER)
# contains keys that map to 'ansi' styles and symbols used in the CLI output.

INTERPRETATION: # Category for styling interpretation results
  # Status mappings for code interpretation results
  Accepted: # Status when a submission is accepted
    ansi: "green,bold"               # Green color and bold text indicate accepted submissions
    symbol_left: "checkmark,space"   # Symbols before the status: checkmark followed by a space
    symbol_right: ""                 # No symbol after the status
  Wrong Answer: # Status when the answer is wrong
    ansi: "red,bold"                 # Red color and bold text indicate wrong answers
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Memory Limit Exceeded: # Status when memory limit is exceeded
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Output Limit Exceeded: # Status when output limit is exceeded
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Time Limit Exceeded: # Status when time limit is exceeded
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Runtime Error: # Status when a runtime error occurs
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Compile Error: # Status when a compile error occurs
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  unknown: # Status for unknown results
    ansi: "orange,bold"              # Orange color and bold text indicate an unknown status
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  field_label: # Styling for field labels in interpretation
    ansi: "white"                    # White color for field labels
    symbol_left: ""                  # No symbol before the label
    symbol_right: "colon"            # Colon symbol after the label
  field_value: # Styling for field values in interpretation
    ansi: "white"                    # White color for field values
    symbol_left: ""                  # No symbol before the value
    symbol_right: ""                 # No symbol after the value

SUBMISSION: # Category for styling submission results, similar to INTERPRETATION
  # Status mappings for submission results
  Accepted: # Status when a submission is accepted
    ansi: "green,bold"               # Green color and bold text indicate accepted submissions
    symbol_left: "checkmark,space"   # Symbols before the status: checkmark followed by a space
    symbol_right: ""                 # No symbol after the status
  Wrong Answer: # Status when the answer is wrong
    ansi: "red,bold"                 # Red color and bold text indicate wrong answers
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Memory Limit Exceeded: # Status when memory limit is exceeded
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Output Limit Exceeded: # Status when output limit is exceeded
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Time Limit Exceeded: # Status when time limit is exceeded
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Runtime Error: # Status when a runtime error occurs
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  Compile Error: # Status when a compile error occurs
    ansi: "red,bold"                 # Consistent red color and bold text
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  unknown: # Status for unknown results
    ansi: "orange,bold"              # Orange color and bold text indicate an unknown status
    symbol_left: "cross,space"       # Symbols before the status: cross followed by a space
    symbol_right: ""                 # No symbol after the status
  field_label: # Styling for field labels in submissions
    ansi: "white"                    # White color for field labels
    symbol_left: ""                  # No symbol before the label
    symbol_right: "colon"            # Colon symbol after the label
  field_value: # Styling for field values in submissions
    ansi: "white"                    # White color for field values
    symbol_left: ""                  # No symbol before the value
    symbol_right: ""                 # No symbol after the value

PROBLEMSET: # Category for styling problem set listings
  # Mappings for styling problem list entries
  title: # Styling for the title of the problem set
    ansi: "white"                      # White color for the title text
    symbol_left: ""                    # No symbol before the title
    symbol_right: ""                   # No symbol after the title
  acceptance_rate: # Styling for the acceptance rate display
    ansi: "white"                      # White color for acceptance rate
    symbol_left: "parenthesis_left"    # Left parenthesis symbol before the rate
    symbol_right: "percentage,parenthesis_right"  # Percentage symbol and right parenthesis after the rate
  question_id: # Styling for the question ID
    ansi: "white,bold"                 # White color and bold text for question ID
    symbol_left: "bracket_left"        # Left bracket before the ID
    symbol_right: "bracket_right"      # Right bracket after the ID
  Easy: # Styling for Easy difficulty label
    ansi: "green,bold"                 # Green color and bold text indicate Easy difficulty
    symbol_left: ""                    # No symbol before difficulty
    symbol_right: ""                   # No symbol after difficulty
  Medium: # Styling for Medium difficulty label
    ansi: "orange,bold"                # Orange color and bold text indicate Medium difficulty
    symbol_left: ""                    # No symbol before difficulty
    symbol_right: ""                   # No symbol after difficulty
  Hard: # Styling for Hard difficulty label
    ansi: "red,bold"                   # Red color and bold text indicate Hard difficulty
    symbol_left: ""                    # No symbol before difficulty
    symbol_right: ""                   # No symbol after difficulty
  ac: # Styling for accepted submissions count
    ansi: "green"                      # Green color for accepted submissions
    symbol_left: "checkmark"           # Checkmark symbol before the status
    symbol_right: ""                   # No symbol after the status
  notac: # Styling for not accepted submissions count
    ansi: "orange"                     # Orange color for not accepted submissions
    symbol_left: "snowflake"           # Snowflake symbol before the status
    symbol_right: ""                   # No symbol after the status
  not_started: # Styling for not started status
    ansi: ""                           # Default color implies white for not started status
    symbol_left: "space"               # Space before the status
    symbol_right: ""                   # No symbol after the status

PROBLEM_DESCRIPTION: # Category for styling problem descriptions
  # Mappings for styling problem descriptions
  strong: # Styling for strong text
    ansi: "bold"                        # Bold text
    symbol_left: ""                     # No symbol before strong text
    symbol_right: ""                    # No symbol after strong text
  p: # Styling for paragraphs
    ansi: ""                            # Default styling for paragraph
    symbol_left: ""                     # No symbol before the paragraph
    symbol_right: ""                  # Newline after paragraph
  br: # Styling for line breaks
    ansi: ""                            # No styling for line breaks
    symbol_left: ""                     # No symbol before the line break
    symbol_right: ""                  # Newline after line break
  ul: # Styling for unordered lists
    ansi: ""                            # Default styling for unordered lists
    symbol_left: ""                     # No symbol before the unordered list
    symbol_right: ""                    # No symbol after the unordered list
  li: # Styling for list items
    ansi: ""                            # Default styling for list items
    symbol_left: "dot"                  # Dot symbol before list item
    symbol_right: ""                    # No symbol after list item
  sup: # Styling for superscript text
    ansi: ""                            # No additional styling for superscript
    symbol_left: "caret"                # Caret symbol before superscript
    symbol_right: ""                    # No symbol after superscript
  b: # Styling for bold text
    ansi: "bold"                        # Bold text
    symbol_left: ""                     # No symbol before bold text
    symbol_right: ""                    # No symbol after bold text
  em: # Styling for emphasized text
    ansi: "italic"                      # Italic text
    symbol_left: ""                     # No symbol before emphasized text
    symbol_right: ""                    # No symbol after emphasized text
  i: # Styling for italic text
    ansi: "italic"                      # Italic text
    symbol_left: ""                     # No symbol before italic text
    symbol_right: ""                    # No symbol after italic text
  u: # Styling for underlined text
    ansi: "underline"                   # Underlined text
    symbol_left: ""                     # No symbol before underlined text
    symbol_right: ""                    # No symbol after underlined text
  span: # Styling for span elements
    ansi: ""                            # Default styling for span
    symbol_left: ""                     # No symbol before span
    symbol_right: ""                    # No symbol after span
  ol: # Styling for ordered lists
    ansi: ""                            # Default styling for ordered lists
    symbol_left: ""                     # No symbol before ordered list
    symbol_right: ""                    # No symbol after ordered list
  table: # Styling for tables
    ansi: ""                            # Default styling for tables
    symbol_left: ""                     # No symbol before table
    symbol_right: ""                    # No symbol after table
  img: # Styling for images
    ansi: ""                            # No styling for images
    symbol_left: ""                     # No symbol before image
    symbol_right: ""                    # No symbol after image
  a: # Styling for links
    ansi: ""                            # Default styling for links
    symbol_left: ""                     # No symbol before link
    symbol_right: ""                    # No symbol after link
  sub: # Styling for subscript text
    ansi: ""                            # No additional styling for subscript
    symbol_left: ""                     # No symbol before subscript
    symbol_right: ""                    # No symbol after subscript
  blockquote: # Styling for blockquotes
    ansi: ""                            # Default styling for blockquotes
    symbol_left: ""                     # No symbol before blockquote
    symbol_right: ""                    # No symbol after blockquote
  ptable: # Styling for property tables
    ansi: ""                            # Default styling for property tables
    symbol_left: ""                     # No symbol before property table
    symbol_right: ""                    # No symbol after property table
  font: # Styling for font tags
    ansi: ""                            # Default styling for font tags
    symbol_left: ""                     # No symbol before font tag
    symbol_right: ""                    # No symbol after font tag
  var: # Styling for variables
    ansi: ""                            # Default styling for variables
    symbol_left: ""                     # No symbol before variable
    symbol_right: ""                    # No symbol after variable
  meta: # Styling for meta tags
    ansi: ""                            # Default styling for meta tags
    symbol_left: ""                     # No symbol before meta tag
    symbol_right: ""                    # No symbol after meta tag
  div: # Styling for divs
    ansi: ""                            # Default styling for divs
    symbol_left: ""                     # No symbol before div
    symbol_right: ""                    # No symbol after div
  style: # Styling for style tags
    ansi: ""                            # No styling for style tags
    symbol_left: ""                     # No symbol before style tag
    symbol_right: ""                    # No symbol after style tag
  code: # Styling for inline code
    ansi: "gray_bg"                     # Gray background for inline code
    symbol_left: "space"                # Space before inline code
    symbol_right: "space"               # Space after inline code
  pre: # Styling for preformatted text
    ansi: "red"                         # Red color for preformatted text
    symbol_left: ""                     # No symbol before preformatted text
    symbol_right: ""                    # No symbol after preformatted text

  tag_label: # Styling for tag labels
    ansi: "white,bold"                  # Bold white text for tag labels
    symbol_left: ""                     # No symbol before tag label
    symbol_right: ""                    # No symbol after tag label
  tag: # Styling for tags
    ansi: "cyan_bg,white,bold"          # Cyan background with white bold text for tags
    symbol_left: "space"                # Space before the tag
    symbol_right: "space"               # Space after the tag
  language_label: # Styling for language labels
    ansi: "white,bold"                  # Bold white text for language labels
    symbol_left: ""                     # No symbol before language label
    symbol_right: ""                    # No symbol after language label
  language: # Styling for language tags
    ansi: "orange_bg,black,bold"        # Orange background with black bold text for languages
    symbol_left: "space"                # Space before the language
    symbol_right: "space"               # Space after the language
  title: # Styling for titles within problem descriptions
    ansi: "white,bold"                  # Bold white text for titles
    symbol_left: ""                     # No symbol before the title
    symbol_right: ""                    # No symbol after the title
  Easy: # Styling for Easy difficulty within problem descriptions
    ansi: "green,bold"                  # Bold green text for Easy difficulty
    symbol_left: "bracket_left"         # Left bracket before difficulty
    symbol_right: "bracket_right"       # Right bracket after difficulty
  Medium: # Styling for Medium difficulty within problem descriptions
    ansi: "orange,bold"                 # Bold orange text for Medium difficulty
    symbol_left: "bracket_left"         # Left bracket before difficulty
    symbol_right: "bracket_right"       # Right bracket after difficulty
  Hard: # Styling for Hard difficulty within problem descriptions
    ansi: "red,bold"                    # Bold red text for Hard difficulty
    symbol_left: "bracket_left"         # Left bracket before difficulty
    symbol_right: "bracket_right"       # Right bracket after difficulty
  example_title: # Styling for example titles
    ansi: "bold"                        # Bold text for example titles
    symbol_left: ""                     # No symbol before example title
    symbol_right: ""                    # No symbol after example title
  example_input_string: # Styling for "Input" label in examples
    ansi: "bold"                        # Bold text for "Input" label
    symbol_left: "pipe,space"                     # No symbol before "Input" label
    symbol_right: "colon,space"                    # No symbol after "Input" label
  example_output_string: # Styling for "Output" label in examples
    ansi: "bold"                        # Bold text for "Output" label
    symbol_left: "pipe,space"                     # No symbol before "Output" label
    symbol_right: "colon,space"                    # No symbol after "Output" label
  example_explanation_string: # Styling for "Explanation" label in examples
    ansi: "bold"                        # Bold text for "Explanation" label
    symbol_left: "pipe,space"                     # No symbol before "Explanation" label
    symbol_right: "colon,space"                    # No symbol after "Explanation" label
  example_input_data: # Styling for example input data
    ansi: "gray"                        # Gray text for input data
    symbol_left: ""                     # No symbol before input data
    symbol_right: ""                    # No symbol after input data
  example_output_data: # Styling for example output data
    ansi: "gray"                        # Gray text for output data
    symbol_left: ""                     # No symbol before output data
    symbol_right: ""                    # No symbol after output data
  example_explanation_data: # Styling for example explanation data
    ansi: "gray"                        # Gray text for explanation data
    symbol_left: ""                     # No symbol before explanation data
    symbol_right: ""                    # No symbol after explanation data
  constraints_string: # Styling for "Constraints" label
    ansi: "bold"                        # Bold text for "Constraints" label
    symbol_left: ""                     # No symbol before "Constraints" label
    symbol_right: ""                    # No symbol after "Constraints" label

STATS: # Category for styling user statistics and activity calendar
  # Mappings for styling user statistics and activity calendar
  EASY: # Styling for Easy solved problems count
    ansi: "green"                       # Green color for Easy solved problems
    symbol_left: ""                     # No symbol before Easy count
    symbol_right: ""                    # No symbol after Easy count
  MEDIUM: # Styling for Medium solved problems count
    ansi: "orange"                      # Orange color for Medium solved problems
    symbol_left: ""                     # No symbol before Medium count
    symbol_right: ""                    # No symbol after Medium count
  HARD: # Styling for Hard solved problems count
    ansi: "red"                         # Red color for Hard solved problems
    symbol_left: ""                     # No symbol before Hard count
    symbol_right: ""                    # No symbol after Hard count
  CALENDAR_TIER0: # Styling for lowest tier in calendar
    ansi: "gray"                        # Gray color for lowest tier in calendar
    symbol_left: ""                     # No symbol before tier
    symbol_right: ""                    # No symbol after tier
  CALENDAR_TIER1: # Styling for higher tier in calendar
    ansi: "orange,bold"                 # Bold orange color for higher tier in calendar
    symbol_left: ""                     # No symbol before tier
    symbol_right: ""                    # No symbol after tier
  filled_square: # Styling for filled squares in calendar
    ansi: ""                            # Default color for filled squares
    symbol_left: "filled_square"        # Filled square symbol
    symbol_right: ""                    # No symbol after filled square
  empty_square: # Styling for empty squares in calendar
    ansi: ""                            # Default color for empty squares
    symbol_left: "empty_square"         # Empty square symbol
    symbol_right: ""                    # No symbol after empty square
  field: # Styling for statistical fields
    ansi: "white,bold"                  # Bold white text for statistical fields
    symbol_left: ""                     # No symbol before field
    symbol_right: ""                    # No symbol after field
"""

File path: constants/themes/default_theme/symbols_yaml.py:
SYMBOLS_YAML = """# This file defines textual symbols used for representing different statuses
# (e.g., checkmarks, crosses, etc.) in the CLI.

SYMBOLS:
  filled_square: "■"             # Solid square symbol
  empty_square: "▢"              # Hollow square symbol
  caret: "^"                     # Caret symbol, often used for superscripts
  dot: "•"                       # Bullet point symbol
  checkmark: "✔"                 # Checkmark symbol indicating success or completion
  cross: "✘"                     # Cross symbol indicating failure or error
  snowflake: "❋"                 # Snowflake symbol, can represent uniqueness or a specific status
  parenthesis_left: "("          # Left parenthesis symbol
  parenthesis_right: ")"         # Right parenthesis symbol
  bracket_left: "["              # Left bracket symbol
  bracket_right: "]"             # Right bracket symbol
  colon: ":"                     # Colon symbol
  percentage: "%"                # Percentage symbol
  pipe: "|"
  space: " "                     # Space character for spacing
"""

File path: constants/themes/default_theme/ansi_codes_yaml.py:
ANSI_CODES_YAML = """# This file defines ANSI escape codes used for styling text in the CLI.
# Each key is a name for a style/color, and the value is the actual escape code.

ANSI_CODES:
  # Standard Colors
  green: "\\u001b[38;2;80;250;123m"       # Green color using RGB values
  orange: "\\u001b[38;2;255;165;0m"       # Orange color using RGB values
  red: "\\u001b[38;2;255;85;85m"          # Red color using RGB values
  gray: "\\u001b[90m"                     # Gray text color
  white: "\\u001b[38;2;255;255;255m"      # White text color using RGB values
  black: "\\u001b[38;2;0;0;0m"            # Black text color using RGB values

  # Background Colors
  gray_bg: "\\u001b[100m"                 # Gray background color
  cyan_bg: "\\u001b[48;2;66;205;245m"     # Cyan background using RGB values
  orange_bg: "\\u001b[48;2;245;158;66m"   # Orange background using RGB values

  # Text Styles
  bold: "\\u001b[1m"                      # Bold text style
  italic: "\\u001b[3m"                    # Italic text style
  underline: "\\u001b[4m"                 # Underlined text style
"""

File path: constants/themes/gruvbox/mappings_yaml.py:
MAPPINGS_YAML = """# Gruvbox-inspired mappings, replicating ALL keys from default_theme

INTERPRETATION:
  Accepted:
    ansi: "green,bold"
    symbol_left: "checkmark,space"
    symbol_right: ""
  Wrong Answer:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Memory Limit Exceeded:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Output Limit Exceeded:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Time Limit Exceeded:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Runtime Error:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Compile Error:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  unknown:
    ansi: "orange,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  field_label:
    ansi: "white,bold"
    symbol_left: ""
    symbol_right: "colon"
  field_value:
    ansi: "white"
    symbol_left: ""
    symbol_right: ""

SUBMISSION:
  Accepted:
    ansi: "green,bold"
    symbol_left: "checkmark,space"
    symbol_right: ""
  Wrong Answer:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Memory Limit Exceeded:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Output Limit Exceeded:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Time Limit Exceeded:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Runtime Error:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  Compile Error:
    ansi: "red,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  unknown:
    ansi: "orange,bold"
    symbol_left: "cross,space"
    symbol_right: ""
  field_label:
    ansi: "white,bold"
    symbol_left: ""
    symbol_right: "colon"
  field_value:
    ansi: "white"
    symbol_left: ""
    symbol_right: ""

PROBLEMSET:
  title:
    ansi: "white,bold"
    symbol_left: ""
    symbol_right: ""
  acceptance_rate:
    ansi: "white"
    symbol_left: "parenthesis_left"
    symbol_right: "percentage,parenthesis_right"
  question_id:
    ansi: "white,bold"
    symbol_left: "bracket_left"
    symbol_right: "bracket_right"
  Easy:
    ansi: "green,bold"
    symbol_left: ""
    symbol_right: ""
  Medium:
    ansi: "orange,bold"
    symbol_left: ""
    symbol_right: ""
  Hard:
    ansi: "red,bold"
    symbol_left: ""
    symbol_right: ""
  ac:
    ansi: "green"
    symbol_left: "checkmark"
    symbol_right: ""
  notac:
    ansi: "orange"
    symbol_left: "snowflake"
    symbol_right: ""
  not_started:
    ansi: ""
    symbol_left: "space"
    symbol_right: ""

PROBLEM_DESCRIPTION:
  strong:
    ansi: "bold"
    symbol_left: ""
    symbol_right: ""
  p:
    ansi: "white"
    symbol_left: ""
    symbol_right: ""
  br:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  ul:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  li:
    ansi: ""
    symbol_left: "dot"
    symbol_right: ""
  sup:
    ansi: ""
    symbol_left: "caret"
    symbol_right: ""
  b:
    ansi: "bold"
    symbol_left: ""
    symbol_right: ""
  em:
    ansi: "italic"
    symbol_left: ""
    symbol_right: ""
  i:
    ansi: "italic"
    symbol_left: ""
    symbol_right: ""
  u:
    ansi: "underline"
    symbol_left: ""
    symbol_right: ""
  span:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  ol:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  table:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  img:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  a:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  sub:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  blockquote:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  ptable:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  font:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  var:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  meta:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  div:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  style:
    ansi: ""
    symbol_left: ""
    symbol_right: ""
  code:
    ansi: "gray_bg"
    symbol_left: "space"
    symbol_right: "space"
  pre:
    ansi: "red"
    symbol_left: ""
    symbol_right: ""

  tag_label:
    ansi: "white,bold"
    symbol_left: ""
    symbol_right: ""
  tag:
    ansi: "orange_bg,black,bold"
    symbol_left: "space"
    symbol_right: "space"
  language_label:
    ansi: "white,bold"
    symbol_left: ""
    symbol_right: ""
  language:
    ansi: "red_bg,white,bold"
    symbol_left: "space"
    symbol_right: "space"
  title:
    ansi: "white,bold"
    symbol_left: ""
    symbol_right: ""
  Easy:
    ansi: "green,bold"
    symbol_left: "bracket_left"
    symbol_right: "bracket_right"
  Medium:
    ansi: "orange,bold"
    symbol_left: "bracket_left"
    symbol_right: "bracket_right"
  Hard:
    ansi: "red,bold"
    symbol_left: "bracket_left"
    symbol_right: "bracket_right"
  example_title:
    ansi: "white,bold"
    symbol_left: ""
    symbol_right: ""
  example_input_string:
    ansi: "white,bold"
    symbol_left: "pipe,space"
    symbol_right: "colon,space"
  example_output_string:
    ansi: "white,bold"
    symbol_left: "pipe,space"
    symbol_right: "colon,space"
  example_explanation_string:
    ansi: "white,bold"
    symbol_left: "pipe,space"
    symbol_right: "colon,space"
  example_input_data:
    ansi: "gray"
    symbol_left: ""
    symbol_right: ""
  example_output_data:
    ansi: "gray"
    symbol_left: ""
    symbol_right: ""
  example_explanation_data:
    ansi: "gray"
    symbol_left: ""
    symbol_right: ""
  constraints_string:
    ansi: "white,bold"
    symbol_left: ""
    symbol_right: ""

STATS_FORMATTER:
  EASY:
    ansi: "green"
    symbol_left: ""
    symbol_right: ""
  MEDIUM:
    ansi: "orange"
    symbol_left: ""
    symbol_right: ""
  HARD:
    ansi: "red"
    symbol_left: ""
    symbol_right: ""
  CALENDAR_TIER0:
    ansi: "gray"
    symbol_left: ""
    symbol_right: ""
  CALENDAR_TIER1:
    ansi: "orange,bold"
    symbol_left: ""
    symbol_right: ""
  filled_square:
    ansi: ""
    symbol_left: "filled_square"
    symbol_right: ""
  empty_square:
    ansi: ""
    symbol_left: "empty_square"
    symbol_right: ""
  field:
    ansi: "white,bold"
    symbol_left: ""
    symbol_right: ""
"""

File path: constants/themes/gruvbox/symbols_yaml.py:
SYMBOLS_YAML = """# Gruvbox-inspired symbols
SYMBOLS:
  checkmark: "✔"
  cross: "✘"
  dot: "•"
  caret: "^"
  space: " "
  pipe: "|"
  parenthesis_left: "("
  parenthesis_right: ")"
  bracket_left: "["
  bracket_right: "]"
  colon: ":"
  percentage: "%"
  snowflake: "❋"
  filled_square: "■"
  empty_square: "□"
"""

File path: constants/themes/gruvbox/ansi_codes_yaml.py:
ANSI_CODES_YAML = """# Gruvbox-inspired ANSI color palette
ANSI_CODES:
  # Gruvbox Colors
  green: "\\u001b[38;2;184;187;38m"
  red: "\\u001b[38;2;251;73;52m"
  orange: "\\u001b[38;2;250;189;47m"
  white: "\\u001b[38;2;235;219;178m"    # Off-white from Gruvbox
  black: "\\u001b[38;2;0;0;0m"            # Black text color using RGB values
  gray: "\\u001b[90m"
  bold: "\\u001b[1m"
  italic: "\\u001b[3m"
  underline: "\\u001b[4m"
  gray_bg: "\\u001b[100m"
  green_bg: "\\u001b[48;2;184;187;38m"
  orange_bg: "\\u001b[48;2;250;189;47m"
  red_bg: "\\u001b[48;2;251;73;52m"
"""

File path: managers/auth_service.py:
class AuthService:
    def __init__(self, config_manager):
        self.config_manager = config_manager

    def get_cookie(self):
        return self.config_manager.get_cookie()

    def get_csrf_token(self):
        return self.config_manager.get_csrf_token()

File path: managers/problemset_manager.py:
import logging
import os
import json
from typing import Dict, Any, Optional, List
import random

from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.exceptions.exceptions import ProblemSetError

from leetcode_cli.data_fetchers.problemset_data_fetcher import fetch_problemset
from leetcode_cli.parsers.problemset_data_parser import parse_problemset_data

logger = logging.getLogger(__name__)


class ProblemSetManager:
    """
    Manages problem set-related functionalities, including loading and saving problem metadata.
    """

    def __init__(self, config_manager: ConfigManager, auth_service: AuthService):
        self.config_manager = config_manager
        self.auth_service = auth_service
        self.problems_data_path = self.get_problems_data_path()

    #
    # ──────────────────────────────────────────────────────
    #   PUBLIC METHODS
    # ──────────────────────────────────────────────────────
    #

    def get_problemset(self, tags=None, difficulty=None, limit=50, page=1):
        """
        High-level method to fetch problemset from the GraphQL API,
        parse it, and return the structured result.
        """
        try:
            raw = fetch_problemset(
                cookie=self.auth_service.get_cookie(),
                csrf_token=self.auth_service.get_csrf_token(),
                tags=tags,
                difficulty=difficulty,
                limit=limit,
                skip=(page - 1) * limit,
            )

        except Exception as e:
            logger.error(e)
            raise e

        try:
            parsed = parse_problemset_data(raw)
            return parsed

        except ProblemSetError as e:
            logger.error(e)
            raise e

    def load_problemset_metadata(self) -> Dict[str, Any]:
        """
        Loads the local JSON file that caches problem set data.

        Returns:
            Dict[str, Any]: The loaded problem set metadata.

        Raises:
            ProblemSetError: If the file cannot be read or is corrupted.
        """
        if os.path.exists(self.problems_data_path):
            try:
                with open(self.problems_data_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    logger.debug("Loaded problem set metadata successfully.")
                    return data

            except json.JSONDecodeError as e:
                logger.error(f"problems_metadata.json is corrupted: {e}")
                raise ProblemSetError("problems_metadata.json is corrupted.")

            except OSError as e:
                logger.error(f"Failed to read problems_metadata.json: {e}")
                raise ProblemSetError("Failed to read problems_metadata.json.")

        else:
            logger.warning(
                f"problems_metadata.json not found at '{self.problems_data_path}'."
            )
            return {}

    def save_problemset_metadata(self, data: Dict[str, Any]) -> None:
        """
        Saves the problem set metadata to the local JSON file.

        Args:
            data (Dict[str, Any]): The problem set data to save.

        Raises:
            ProblemSetError: If the file cannot be written.
        """
        try:
            os.makedirs(os.path.dirname(self.problems_data_path), exist_ok=True)

            with open(self.problems_data_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=4)

            logger.info(f"Problem set data saved to '{self.problems_data_path}'.")

        except OSError as e:
            logger.error(f"Failed to save problems_metadata.json: {e}")
            raise ProblemSetError("Failed to save problems_metadata.json.")

    def get_problem_by_key_value(self, key: str, value: str) -> Dict[str, Any]:
        """
        Retrieves a problem from the problem set based on a key-value pair.

        Args:
            key (str): The key to search by (e.g., 'frontendQuestionId', 'titleSlug').
            value (str): The value to match.

        Returns:
            Dict[str, Any]: The matched problem data.

        Raises:
            ProblemSetError: If the problem cannot be found.
        """
        problems_data = self.load_problemset_metadata()
        questions = (
            problems_data.get("data", {})
            .get("problemsetQuestionList", {})
            .get("questions", [])
        )

        for problem in questions:
            if str(problem.get(key, "")).lower() == str(value).lower():
                logger.debug(f"Found problem with {key}='{value}'.")
                return problem

        logger.warning(f"Problem with {key}='{value}' not found in cached data.")
        return {}

    def get_random_local_problem_slug(
        self, difficulty: Optional[str], tags: Optional[List[str]]
    ) -> Optional[str]:
        """
        Randomly select a local problem that matches the given difficulty and tag filters.
        Returns its 'titleSlug', or None if no match found.
        """
        data = self.load_problemset_metadata()
        questions = (
            data.get("data", {}).get("problemsetQuestionList", {}).get("questions", [])
        )

        # Filter by difficulty & tags if provided
        filtered = []
        for q in questions:
            if difficulty and q.get("difficulty", "").lower() != difficulty.lower():
                continue

            if tags and not self._matches_tags(q, tags):
                continue

            filtered.append(q)

        if not filtered:
            return None

        # Randomly choose one from the filtered list
        chosen = random.choice(filtered)
        return chosen.get("titleSlug")

    def get_problems_data_path(self) -> str:
        """
        Construct the path to problems_metadata.json in config_dir.
        """
        config_dir = self.config_manager.config_dir
        return os.path.join(config_dir, "problems_metadata.json")

    #
    # ──────────────────────────────────────────────────────
    #   PRIVATE HELPERS
    # ──────────────────────────────────────────────────────
    #

    def _matches_tags(self, question: dict, required_tags: List[str]) -> bool:
        """
        Helper to check if the question has all the required tags.
        'topicTags' is typically a list of dicts with 'slug' keys.
        """
        question_tags = [
            t.get("slug", "").lower() for t in question.get("topicTags", [])
        ]

        for required_tag in required_tags:
            if required_tag.lower() not in question_tags:
                return False

        return True

File path: managers/config_manager.py:
import json
import os
import platform
import logging
import re
from typing import Dict

from leetcode_cli.exceptions.exceptions import ConfigError

logger = logging.getLogger(__name__)


class ConfigManager:
    """
    Manages loading and saving of configuration settings.
    """

    def __init__(self):
        self.config_path = self._get_config_path()
        self.config_dir = os.path.dirname(self.config_path)
        self.config = self._load_config()

    #
    # ──────────────────────────────────────────────────────
    #   PUBLIC METHODS
    # ──────────────────────────────────────────────────────
    #

    def _set_key(self, key: str, value) -> None:
        """
        Sets a configuration key to a specified value.
        """
        self.config[key] = value
        self.save_config()

    def _get_key(self, key: str, default=None):
        """
        Retrieves the value of a configuration key.
        """
        return self.config.get(key, default)

    def set_cookie(self, cookie: str) -> None:
        self._set_key("cookie", cookie)

    def get_cookie(self) -> str:
        return self._get_key("cookie", "")

    def set_username(self, username: str) -> None:
        self._set_key("username", username)

    def get_username(self) -> str:
        return self._get_key("username", "")

    def set_language(self, language: str) -> None:
        self._set_key("language", language)

    def get_language(self) -> str:
        return self._get_key("language", "")

    def set_chosen_problem(self, title_slug: str) -> None:
        self._set_key("chosen_problem", title_slug)

    def get_chosen_problem(self) -> str:
        return self._get_key("chosen_problem", "")

    def set_theme(self, theme_name: str):
        self._set_key("theme", theme_name)

    def get_theme(self) -> str:
        return self._get_key("theme", "")

    def get_csrf_token(self) -> str:
        """
        Extracts the CSRF token from the cookie string, if present.
        """
        cookie = self._get_key("cookie", "")
        match = re.search(r"csrftoken=([^;]+)", cookie)
        if match:
            return match.group(1)

        logger.error("CSRF token not found in the cookie.")
        return ""

    def save_config(self) -> None:
        """
        Saves the current configuration to the config file.
        """
        try:
            os.makedirs(self.config_dir, exist_ok=True)
            with open(self.config_path, "w", encoding="utf-8") as f:
                json.dump(self.config, f, indent=4)

            logger.info(f"Configuration saved to {self.config_path}")

        except OSError as e:
            logger.error(f"Failed to save configuration: {e}")
            raise ConfigError("Failed to save configuration.")

    #
    # ──────────────────────────────────────────────────────
    #   PRIVATE HELPERS
    # ──────────────────────────────────────────────────────
    #

    @staticmethod
    def _get_config_path() -> str:
        """
        Determines the configuration file path based on the operating system.
        """
        if platform.system() == "Windows":
            # Use APPDATA for application data directory on Windows, fallback to Roaming
            config_dir = os.getenv("APPDATA", os.path.expanduser("~\\AppData\\Roaming"))
            config_dir = os.path.join(config_dir, "leetcode")

        else:
            # Use ~/.leetcode for Unix-like systems
            config_dir = os.path.expanduser("~/.leetcode")

        # Ensure the directory exists before returning the full path
        os.makedirs(config_dir, exist_ok=True)
        return os.path.join(config_dir, "config.json")

    def _load_config(self) -> Dict:
        """
        Loads the configuration from the config file.
        """
        if os.path.exists(self.config_path):
            try:
                with open(self.config_path, "r", encoding="utf-8") as f:
                    return json.load(f)

            except json.JSONDecodeError:
                logger.warning("config.json is corrupted. Returning empty config.")
                return {}

            except OSError as e:
                logger.error(f"Failed to read config file: {e}")
                raise ConfigError("Failed to read config file.")
        else:
            logger.info("config.json not found. Returning empty config.")
            return {}

File path: managers/stats_manager.py:
# file: leetcode_cli/managers/stats_manager.py

import json
from datetime import datetime, timezone, timedelta
import logging
from typing import Dict

from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.exceptions.exceptions import FetchingError, StatsError, ParsingError
from leetcode_cli.parsers.stats_data_parser import (
    parse_user_stats_data,
    parse_single_year_calendar,
)
from leetcode_cli.models.stats import UserStatsModel, UserActivityModel

from leetcode_cli.data_fetchers.stats_data_fetcher import (
    fetch_user_stats,
    fetch_user_activity,
)

logger = logging.getLogger(__name__)


class StatsManager:
    """
    Manages statistics fetch + parse, plus the logic to join/fill user activity.
    The commands call these manager methods, then pass results to a formatter.
    """

    def __init__(self, config_manager: ConfigManager, auth_service: AuthService):
        self.config_manager = config_manager
        self.auth_service = auth_service

    #
    # ──────────────────────────────────────────────────────
    #   PUBLIC METHODS
    # ──────────────────────────────────────────────────────
    #

    def get_user_stats(self, username: str) -> UserStatsModel:
        """
        Fetch + parse user stats from LeetCode, returning a UserStatsModel.
        """
        try:
            raw = fetch_user_stats(username)
            return parse_user_stats_data(raw)
        except (FetchingError, ParsingError) as e:
            logger.error(f"Failed to get_user_stats: {e}")
            raise StatsError(str(e))

    def get_joined_activity(
        self, username: str, prev_year: int, curr_year: int
    ) -> UserActivityModel:
        """
        Fetch raw calendar data for two years, parse them, then join + slice + fill to produce a final UserActivityModel.
        """
        try:
            # 1) fetch for each year
            raw_prev = fetch_user_activity(username, prev_year)
            raw_curr = fetch_user_activity(username, curr_year)
            # 2) parse each
            prev_dict = parse_single_year_calendar(raw_prev)  # Dict[int, int]
            curr_dict = parse_single_year_calendar(raw_curr)  # Dict[int, int]

            # 3) merge + slice + fill
            joined = self._join_and_slice_calendars(prev_dict, curr_dict)
            filled = self._fill_daily_activity(joined)

            # 4) return final model
            return UserActivityModel(daily_activity=filled)

        except (FetchingError, ParsingError) as e:
            logger.error(f"Failed to get_joined_activity: {e}")
            raise StatsError(str(e))

    #
    # ──────────────────────────────────────────────────────
    #   PRIVATE HELPERS
    # ──────────────────────────────────────────────────────
    #

    def _join_and_slice_calendars(
        self, prev_data: Dict[int, int], curr_data: Dict[int, int]
    ) -> Dict[int, int]:
        """
        Merges two dicts of {timestamp -> submissionCount}, then slices to the last 365 days.
        """
        merged = {**prev_data, **curr_data}

        today_utc = datetime.utcnow().date()
        start_date = today_utc - timedelta(days=365)
        start_dt = datetime.combine(
            start_date, datetime.min.time(), tzinfo=timezone.utc
        )
        end_dt = datetime.combine(today_utc, datetime.min.time(), tzinfo=timezone.utc)

        start_ts = int(start_dt.timestamp())
        end_ts = int(end_dt.timestamp())

        # slice
        sliced = {ts: cnt for ts, cnt in merged.items() if start_ts <= ts < end_ts}
        logger.debug(
            f"Sliced calendar data from {start_date} to {today_utc}, total {len(sliced)} days."
        )
        return sliced

    def _fill_daily_activity(self, daily_activity: Dict[int, int]) -> Dict[int, int]:
        """
        Ensures every day in the last year is present, even if 0 submissions.
        """
        filled = {}
        today_utc = datetime.utcnow().date()
        start_date = today_utc - timedelta(days=365)

        start_dt = datetime.combine(
            start_date, datetime.min.time(), tzinfo=timezone.utc
        )
        end_dt = datetime.combine(today_utc, datetime.min.time(), tzinfo=timezone.utc)

        current = start_dt
        while current <= end_dt:
            ts = int(current.timestamp())
            filled[ts] = daily_activity.get(ts, 0)
            current += timedelta(days=1)

        logger.debug(
            f"Filled missing days from {start_date} to {today_utc}, total {len(filled)} days."
        )
        return filled

File path: managers/code_manager.py:
import os
import logging

from typing import Tuple

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.constants.problem_constants import (
    EXTENSION_TO_LANG_SLUG,
    LANG_SLUG_TO_EXTENSION,
)
from leetcode_cli.exceptions.exceptions import CodeError
from leetcode_cli.data_fetchers.code_snippet_fetcher import fetch_code_snippet

logger = logging.getLogger(__name__)


class CodeManager:
    """
    Manages code-related functionalities, including reading and creating solution files.
    Handles:
      - Reading local code files
      - Inferring language & extension
      - Fetching code snippets and creating solution files
    """

    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager

    #
    # ──────────────────────────────────────────────────────
    #   PUBLIC METHODS
    # ──────────────────────────────────────────────────────
    #

    def read_code_from_file(self, file_path: str) -> str:
        """
        Reads and returns the content of a code file.

        Args:
            file_path (str): The path to the code file.

        Returns:
            str: The content of the code file.

        Raises:
            CodeError: If the file cannot be read.
        """
        if not os.path.exists(file_path):
            logger.error(f"File '{file_path}' does not exist.")
            raise CodeError(f"File '{file_path}' does not exist.")

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                code = f.read()
                logger.debug(f"Read code from file '{file_path}'.")
                return code

        except OSError as e:
            logger.error(f"Failed to read file '{file_path}': {e}")
            raise CodeError(f"Failed to read file '{file_path}': {e}")

    def determine_language_from_extension(self, file_extension: str) -> str:
        """
        Determines the programming language based on the file extension.

        Args:
            file_extension (str): The file extension (e.g., 'py', 'cpp').

        Returns:
            str: The corresponding language slug.

        Raises:
            CodeError: If the file extension is unsupported.
        """
        lang = EXTENSION_TO_LANG_SLUG.get(file_extension.lower())
        if not lang:
            logger.error(f"Unsupported file extension '{file_extension}'.")
            raise CodeError(f"Unsupported file extension '{file_extension}'.")

        logger.debug(f"Determined language '{lang}' from extension '{file_extension}'.")
        return lang

    def get_default_lang_and_ext(self) -> Tuple[str, str]:
        """
        Attempts to retrieve the default language from the user's config,
        then derive the matching extension from LANG_SLUG_TO_EXTENSION.

        Returns:
            (lang_slug, file_extension)

        Raises:
            CodeError: If config language is undefined or unsupported.
        """
        config_lang = self.config_manager.get_language()  # e.g. "python"
        if not config_lang:
            raise CodeError("No default language is set in config.")

        extension = LANG_SLUG_TO_EXTENSION.get(config_lang.lower())
        if not extension:
            raise CodeError(f"No known extension for default language '{config_lang}'.")

        logger.debug(f"Default language '{config_lang}' => extension '{extension}'.")
        return config_lang.lower(), extension.lower()

    def infer_lang_and_ext(self, user_ext: str = "") -> Tuple[str, str]:
        """
        Infers the (lang_slug, file_extension) from either:
        1) user-provided extension (e.g. ".cpp" or "py"), or
        2) config default if user_ext is empty.

        Returns:
            (lang_slug, file_extension)

        Raises:
            CodeError: If either approach fails.
        """
        # If user provided an extension (like ".cpp" or "cpp")
        if user_ext:
            # Remove leading '.' if any
            file_extension = user_ext.lstrip(".").lower()
            lang_slug = self.determine_language_from_extension(file_extension)
            return lang_slug, file_extension

        # Else, fallback to the default from config
        return self.get_default_lang_and_ext()

    def create_solution_file_with_snippet(
        self, frontend_id: str, title_slug: str, lang_slug: str, file_extension: str
    ) -> None:
        """
        Fetches the code snippet and creates the solution file.

        Args:
            frontend_id (str): The numeric ID of the problem.
            title_slug (str): The title slug of the problem.
            lang_slug (str): The language slug.
            file_extension (str): The file extension.

        Raises:
            CodeError: If fetching the code snippet or creating the file fails.
        """
        try:
            code_data = fetch_code_snippet(title_slug, lang_slug)
            snippet_list = (
                code_data.get("data", {}).get("question", {}).get("codeSnippets", [])
            )
            code_str = ""
            for sn in snippet_list:
                if sn.get("langSlug") == lang_slug:
                    code_str = sn.get("code", "")
                    break

            if not code_str:
                code_str = f"# That problem does not have a code snippet for {lang_slug} and is probably not submittable in that language.\n\n"

            self._create_solution_file(
                frontend_id, title_slug, file_extension, code_str
            )
            file_name = f"{frontend_id}.{title_slug}.{file_extension}"
            logger.debug(f"Solution file '{file_name}' has been created successfully.")

        except Exception as e:
            logger.error(f"Failed to create solution file with snippet: {e}")
            raise CodeError(f"Failed to create solution file with snippet: {e}")

    #
    # ──────────────────────────────────────────────────────
    #   PRIVATE HELPERS
    # ──────────────────────────────────────────────────────
    #

    def _create_solution_file(
        self, frontend_id: str, title_slug: str, file_extension: str, code_snippet: str
    ) -> None:
        """
        Creates a new solution file with the provided code snippet.

        Args:
            frontend_id (str): The numeric ID of the problem (a/k/a frontendId).
            title_slug (str): The title slug of the problem.
            file_extension (str): e.g. "py", "cpp", etc.
            code_snippet (str): The code to be written into the solution file.

        Raises:
            CodeError: If the file cannot be created (e.g. file already exists).
        """
        file_name = f"{frontend_id}.{title_slug}.{file_extension}"

        if os.path.exists(file_name):
            logger.warning(
                f"Solution file '{file_name}' already exists. Not overwriting."
            )
            raise CodeError(f"Solution file '{file_name}' already exists.")

        try:
            with open(file_name, "w", encoding="utf-8") as f:
                f.write(code_snippet)

            logger.info(f"Solution file '{file_name}' created successfully.")

        except OSError as e:
            logger.error(f"Failed to create solution file '{file_name}': {e}")
            raise CodeError(f"Failed to create solution file '{file_name}': {e}")

File path: managers/theme_manager.py:
import os
import logging
import yaml
from typing import List, Optional

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.exceptions.exceptions import ThemeError
from leetcode_cli.models.theme import ThemeData

logger = logging.getLogger(__name__)


class ThemeManager:
    """
    Manages theme loading and retrieval of specific styling for each section/key.

    Public methods:
      - list_themes()
      - get_current_theme()
      - set_current_theme()
      - load_theme_data()
      - get_styling()

    Private helpers:
      - _get_themes_dir()
      - _parse_ansi_codes()
      - _parse_symbols()
      - _load_yaml_file()
    """

    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        self.themes_dir = (
            self.get_themes_dir()
        )  # moved the helper call to a private function
        self.theme_data: Optional[ThemeData] = None

    #
    # ──────────────────────────────────────────────────────
    #   PUBLIC METHODS
    # ──────────────────────────────────────────────────────
    #

    def get_themes_dir(self) -> str:
        """
        Private helper to locate the "~/.leetcode/themes" directory.
        """
        config_dir = os.path.dirname(self.config_manager.config_path)
        return os.path.join(config_dir, "themes")

    def list_themes(self) -> List[str]:
        """
        Returns a list of available theme directories.
        """
        if not os.path.exists(self.themes_dir):
            logger.warning(f"Themes directory '{self.themes_dir}' does not exist.")
            return []

        themes = [
            d
            for d in os.listdir(self.themes_dir)
            if os.path.isdir(os.path.join(self.themes_dir, d))
        ]

        logger.debug(f"Available themes: {themes}")
        return themes

    def get_current_theme(self) -> Optional[str]:
        """
        Returns the currently set theme from config.json.
        """
        return self.config_manager.get_theme()

    def set_current_theme(self, theme_name: str) -> bool:
        """
        Sets the current theme to 'theme_name', if it exists in the list of installed themes.
        """
        available_themes = self.list_themes()
        if theme_name not in available_themes:
            logger.error(
                f"Theme '{theme_name}' does not exist. Available themes: {available_themes}"
            )
            return False

        self.config_manager.set_theme(theme_name)
        logger.info(f"Theme set to '{theme_name}'.")

        return True

    def load_theme_data(self) -> ThemeData:
        """
        Loads the theme data from local YAML files into a ThemeData object.
        Raises ThemeError if mandatory fields or files are missing.
        """
        theme_name = self.get_current_theme()
        if not theme_name:
            raise ThemeError("No theme is set in config.json. (key='theme')")

        ansi_data = self._load_yaml_file(theme_name, "ansi_codes.yaml")
        symbols_data = self._load_yaml_file(theme_name, "symbols.yaml")
        mappings_data = self._load_yaml_file(theme_name, "mappings.yaml")

        # Validate mandatory top-level keys
        if "ANSI_CODES" not in ansi_data:
            raise ThemeError(
                f"'ANSI_CODES' missing in ansi_codes.yaml for theme '{theme_name}'."
            )

        if "SYMBOLS" not in symbols_data:
            raise ThemeError(
                f"'SYMBOLS' missing in symbols.yaml for theme '{theme_name}'."
            )

        # Merge the loaded data
        merged = {
            "ANSI_CODES": ansi_data["ANSI_CODES"],
            "SYMBOLS": symbols_data["SYMBOLS"],
            **mappings_data,
        }
        logger.debug(f"Theme data for '{theme_name}': {merged}")

        self.theme_data = ThemeData(
            ANSI_CODES=merged["ANSI_CODES"],
            SYMBOLS=merged["SYMBOLS"],
            INTERPRETATION=merged.get("INTERPRETATION", {}),
            SUBMISSION=merged.get("SUBMISSION", {}),
            PROBLEMSET=merged.get("PROBLEMSET", {}),
            PROBLEM_DESCRIPTION=merged.get("PROBLEM_DESCRIPTION", {}),
            STATS_FORMATTER=merged.get("STATS_FORMATTER", {}),
        )
        return self.theme_data

    def get_styling(self, section: str, key: str) -> tuple:
        """
        Returns (combined_ansi_code, combined_symbol_left, combined_symbol_right).
        E.g., ("\033[32m\033[1m", "✔ ", "")
        """
        if not self.theme_data:
            self.theme_data = self.load_theme_data()

        # Grab the relevant dictionary from the loaded theme data
        try:
            section_data = getattr(self.theme_data, section)
            raw_mapping = section_data[key]

        except AttributeError:
            raise ThemeError(f"Section '{section}' not found in theme data.")

        except KeyError:
            raise ThemeError(f"Key '{key}' not found in section '{section}'.")

        # e.g. raw_mapping => {"ansi": "green,bold", "symbol_left": "checkmark,space", "symbol_right": ""}
        combined_ansi = self._parse_ansi_codes(raw_mapping.get("ansi", ""))
        combined_left = self._parse_symbols(raw_mapping.get("symbol_left", ""))
        combined_right = self._parse_symbols(raw_mapping.get("symbol_right", ""))

        return (combined_ansi, combined_left, combined_right)

    #
    # ──────────────────────────────────────────────────────
    #   PRIVATE METHODS
    # ──────────────────────────────────────────────────────
    #

    def _parse_ansi_codes(self, ansi_field: str) -> str:
        """
        Convert "green,bold" -> combined ANSI codes from self.theme_data.ANSI_CODES.
        Raises ThemeError if a code isn't found in 'ANSI_CODES'.
        """
        if not ansi_field:
            return ""

        codes = ansi_field.split(",")
        final = ""
        for code_key in codes:
            code_key = code_key.strip().lower()
            if code_key not in self.theme_data.ANSI_CODES:
                raise ThemeError(
                    f"ANSI code '{code_key}' not found in 'ANSI_CODES' mapping. "
                    f"Theme configuration is malformed."
                )
            final += self.theme_data.ANSI_CODES[code_key]

        return final

    def _parse_symbols(self, symbol_field: str) -> str:
        """
        Convert "checkmark,space" -> "✔ ".
        Raises ThemeError if symbol isn't found in 'SYMBOLS'.
        """
        if not symbol_field:
            return ""

        parts = symbol_field.split(",")
        final = ""
        for p in parts:
            p = p.strip().lower()
            if p not in self.theme_data.SYMBOLS:
                raise ThemeError(
                    f"Symbol '{p}' not found in 'SYMBOLS' mapping. "
                    "Theme configuration is malformed."
                )
            final += self.theme_data.SYMBOLS[p]
        return final

    def _load_yaml_file(self, theme_name: str, filename: str) -> dict:
        """
        Private helper to load a YAML file from the theme's folder.
        Raises ThemeError if file is missing or invalid.
        """
        file_path = os.path.join(self.themes_dir, theme_name, filename)
        if not os.path.exists(file_path):
            raise ThemeError(f"File '{filename}' is missing for theme '{theme_name}'.")

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f)
                if not isinstance(data, dict):
                    raise ThemeError(
                        f"File '{filename}' for theme '{theme_name}' is not a valid dictionary."
                    )
                return data

        except yaml.YAMLError as e:
            raise ThemeError(
                f"YAML error in '{filename}' for theme '{theme_name}': {e}"
            )

File path: managers/formatting_config_manager.py:
import os
import logging
import yaml

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.models.formatting_config import FormattingConfig
from leetcode_cli.exceptions.exceptions import ConfigError

logger = logging.getLogger(__name__)


class FormattingConfigManager:
    """
    Manages loading and processing of formatting configurations.
    """

    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        self.formatting_config_path = self._get_formatting_config_path()

    #
    # ──────────────────────────────────────────────────────
    #   PUBLIC METHODS
    # ──────────────────────────────────────────────────────
    #

    def load_formatting_config(self) -> FormattingConfig:
        """
        Loads the formatting_config.yaml into a FormattingConfig object.

        Returns:
            FormattingConfig: The loaded formatting configuration.

        Raises:
            ConfigError: If the formatting configuration cannot be loaded.
        """
        if not os.path.exists(self.formatting_config_path):
            logger.error(
                f"Formatting configuration file '{self.formatting_config_path}' not found."
            )
            raise ConfigError(
                f"Formatting configuration file '{self.formatting_config_path}' not found."
            )

        try:
            with open(self.formatting_config_path, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f)
                if not isinstance(data, dict):
                    logger.error(
                        "Formatting configuration is not a valid YAML dictionary."
                    )
                    raise ConfigError("Invalid formatting configuration format.")

        except yaml.YAMLError as e:
            logger.error(f"YAML parsing error in formatting_config.yaml: {e}")
            raise ConfigError(f"YAML parsing error: {e}")

        except OSError as e:
            logger.error(f"Failed to read formatting_config.yaml: {e}")
            raise ConfigError(f"Failed to read formatting_config.yaml: {e}")

        return FormattingConfig(
            interpretation=data.get("interpretation", {}),
            submission=data.get("submission", {}),
            problem_show=data.get("problem_show", {}),
        )

    #
    # ──────────────────────────────────────────────────────
    #   PRIVATE HELPERS
    # ──────────────────────────────────────────────────────
    #

    def _get_formatting_config_path(self) -> str:
        """
        Returns the path to the formatting_config.yaml file.
        """
        config_dir = self.config_manager.config_dir
        return os.path.join(config_dir, "formatting_config.yaml")

File path: managers/problem_manager.py:
import logging
from typing import Optional, Tuple, List

from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.problemset_manager import ProblemSetManager

from leetcode_cli.exceptions.exceptions import FetchingError, ProblemError
from leetcode_cli.models.problem import Problem

# Import fetchers + parsers needed
from leetcode_cli.data_fetchers.problem_data_fetcher import (
    fetch_problem_data,
    fetch_random_title_slug,
    fetch_problem_testcases,
    fetch_problem_id,
    fetch_problem_frontend_id,
)
from leetcode_cli.data_fetchers.interpretation_result_fetcher import (
    fetch_interpretation_result,
)
from leetcode_cli.data_fetchers.submission_result_fetcher import fetch_submission_result

from leetcode_cli.parsers.problem_data_parser import parse_problem_data
from leetcode_cli.parsers.interpretation_result_parser import (
    parse_interpretation_result,
)
from leetcode_cli.parsers.submission_result_parser import parse_submission_result

logger = logging.getLogger(__name__)


class ProblemManager:
    """
    Manages fetching & parsing problem-related data from LeetCode,
    using AuthService for authentication. The commands call these
    manager methods, then pass the results to a formatter for display.

    Enhancements:
      - Before network fetch, attempt to load data from problemset metadata.
      - If metadata is empty or no matching data found, fallback to network.
    """

    def __init__(
        self,
        config_manager: ConfigManager,
        auth_service: AuthService,
        problemset_manager: ProblemSetManager,
    ):
        self.config_manager = config_manager
        self.auth_service = auth_service
        self.problemset_manager = problemset_manager

    #
    # ──────────────────────────────────────────────────────
    #   PUBLIC METHODS
    # ──────────────────────────────────────────────────────
    #

    def get_specific_problem(self, identifier: str) -> Problem:
        """
        Return a parsed `Problem` object for either an ID or a slug.
        1) If it's an ID, tries local metadata => fallback fetch if not found
        2) If it's a slug, tries direct fetch
        """
        # If numeric => interpret as front-end ID
        if identifier.isdigit():
            title_slug = self.get_title_slug_for_frontend_id(identifier)

        else:
            title_slug = identifier

        raw_data = fetch_problem_data(title_slug)
        problem_obj = parse_problem_data(raw_data)

        if not self._is_available_for_free_user(problem_obj):
            raise ProblemError("Sorry, this problem is paid-only and requires a subscription to view, please try again.")

        logger.debug(f"Parsed problem data for slug '{title_slug}'.")

        return problem_obj

    def get_random_problem(
        self, difficulty: Optional[str] = None, tags: Optional[List[str]] = None
    ) -> Problem:
        """
        Fetch a random problem slug, parse the resulting problem,
        and return a Problem object.

        1) Try picking a random local problem that matches difficulty/tags.
        2) If no local match or metadata empty, fallback to network.
        """
        title_slug = self.problemset_manager.get_random_local_problem_slug(
            difficulty, tags
        )

        if not title_slug:
            slug_from_net = fetch_random_title_slug(difficulty=difficulty, tags=tags)
            title_slug = (
                slug_from_net.get("data", {})
                .get("randomQuestion", {})
                .get("titleSlug", "")
            )

        if not title_slug:
            raise FetchingError("No random problem found with those filters.")

        raw_data = fetch_problem_data(title_slug)
        problem_obj = parse_problem_data(raw_data)

        if not self._is_available_for_free_user(problem_obj):
            raise ProblemError("Sorry, this problem is paid-only and requires a subscription to view, please try again.")

        problem_obj.__dict__["_title_slug"] = title_slug

        return problem_obj

    def get_problem_frontend_id(self, title_slug: str) -> int:
        """
        Return numeric front-end question ID for the given slug.
        1) Attempt local metadata => fallback to network.
        """
        # Try local metadata first
        local_frontend_id = self._try_local_frontend_id_by_slug(title_slug)

        if local_frontend_id:
            return int(local_frontend_id)

        raw = fetch_problem_frontend_id(title_slug)
        frontend_id = raw.get("data", {}).get("question", {}).get("questionFrontendId")

        if not frontend_id:
            raise FetchingError(
                f"Unable to find frontend question ID for slug: '{title_slug}'"
            )

        return int(frontend_id)

    def get_problem_id(self, title_slug: str) -> int:
        """
        Return the internal questionId for a given slug.
        Attempt local => fallback network.
        """
        # Try local metadata frist
        local_id = self._try_local_id_by_slug(title_slug)

        if local_id:
            return int(local_id)

        raw = fetch_problem_id(title_slug)
        question_id = raw.get("data", {}).get("question", {}).get("questionId")

        if not question_id:
            raise FetchingError(f"Unable to find questionId for slug: '{title_slug}'")

        return int(question_id)

    def get_title_slug_for_frontend_id(self, frontend_id: str) -> str:
        """
        Use local metadata to find the slug from the ID. Raises ProblemError if not found,
        fallback => attempt a network approach if you prefer (like listing all problems).
        """
        title_slug = self._try_local_slug_by_frontend_id(frontend_id)

        if title_slug:
            logger.debug(
                f"Title slug for ID '{frontend_id}' is '{title_slug}' (from local)."
            )
            return title_slug

        raise ProblemError(
            f"Title slug for frontend ID '{frontend_id}' not found in local metadata."
        )

    def get_interpretation_result(
        self, title_slug: str, code: str, lang_slug: str, testcases: str
    ):
        """
        Return a fully parsed InterpretationResult for 'Run Code' action.
        """
        raw = fetch_interpretation_result(
            cookie=self.auth_service.get_cookie(),
            csrf_token=self.auth_service.get_csrf_token(),
            title_slug=title_slug,
            code=code,
            language=lang_slug,
            testcases=testcases,
            question_id=self.get_problem_id(title_slug),
        )
        return parse_interpretation_result(raw)

    def get_submission_result(self, title_slug: str, code: str, lang_slug: str):
        """
        Return a fully parsed SubmissionResult for the final 'submit' action.
        """
        raw = fetch_submission_result(
            cookie=self.auth_service.get_cookie(),
            csrf_token=self.auth_service.get_csrf_token(),
            title_slug=title_slug,
            code=code,
            language=lang_slug,
            question_id=self.get_problem_id(title_slug),
        )
        return parse_submission_result(raw)

    def get_example_testcases(self, title_slug: str) -> str:
        """
        Manager method for fetching example testcases from the problem detail.
        """
        try:
            data = fetch_problem_testcases(title_slug)
            return data.get("data", {}).get("question", {}).get("exampleTestcases", "")

        except FetchingError as fe:
            logger.error(f"Could not fetch example testcases: {fe}")
            raise fe

    def problem_data_from_path(self, filepath: str) -> Tuple[str, str, str]:
        """
        Parses the problem data from the solution file path.

        Raises ProblemError if format is invalid.
        """
        import os

        filename = os.path.basename(filepath)
        parts = filename.split(".")

        if len(parts) != 3:
            logger.error(
                "Invalid filepath format. Expected {question_id}.{title_slug}.{file_extension}."
            )
            raise ProblemError(
                "Invalid filepath format. Expected {question_id}.{title_slug}.{file_extension}."
            )

        return parts[0], parts[1], parts[2]

    #
    # ──────────────────────────────────────────────────────
    #   PRIVATE HELPERS
    # ──────────────────────────────────────────────────────
    #

    def _try_local_frontend_id_by_slug(self, title_slug: str) -> str:
        """
        Attempt to find front-end ID by searching local metadata.
        If not found, return None.
        """
        problem = self.problemset_manager.get_problem_by_key_value(
            key="titleSlug", value=title_slug
        )

        if not problem:
            return ""

        return problem.get("frontendQuestionId", "")

    def _try_local_id_by_slug(self, title_slug: str) -> str:
        """
        Attempt to find front-end ID by searching local metadata.
        If not found, return None.
        """
        problem = self.problemset_manager.get_problem_by_key_value(
            key="titleSlug", value=title_slug
        )

        if not problem:
            return ""

        return problem.get("questionId", "")

    def _try_local_slug_by_frontend_id(self, frontend_id: str) -> str:
        """
        Attempt to find front-end ID by searching local metadata.
        If not found, return None.
        """
        problem = self.problemset_manager.get_problem_by_key_value(
            key="frontendQuestionId", value=frontend_id
        )

        if not problem:
            return ""

        return problem.get("titleSlug", "")

    def _is_available_for_free_user(self, problem: Problem):
        if problem.is_paid_only and not problem.code_snippets:
            return False

        return True

File path: formatters/interpretation_result_formatter.py:
import logging

from leetcode_cli.models.interpretation import InterpretationResult
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.exceptions.exceptions import ThemeError

logger = logging.getLogger(__name__)


class InterpretationFormatter:
    """
    Formats the 'run code' interpretation results, printing
    a separate "window" of info for each testcase, using the
    'INTERPRETATION' theme mappings. The styling and layout
    approach is similar to the SubmissionFormatter style.
    """

    def __init__(
        self,
        result: InterpretationResult,
        testcases_str: str,
        format_conf: dict,
        theme_manager: ThemeManager,
    ):
        self.result = result
        self.testcases_str = testcases_str
        self.format_conf = format_conf
        self.theme_manager = theme_manager
        self.theme_data = theme_manager.load_theme_data()

        self.ANSI_RESET = "\033[0m"  # Reset all styles

    def get_formatted_interpretation(self) -> str:
        status_code = self.result.status_code
        status_msg = self.result.status_msg
        lang = self.result.pretty_lang or self.result.lang
        total_testcases = self.result.total_testcases or 0

        show_language = self.format_conf.get("show_language", True)
        show_testcases = self.format_conf.get("show_testcases", True)
        show_expected_output = self.format_conf.get("show_expected_output", True)
        show_code_output = self.format_conf.get("show_code_output", True)
        show_stdout = self.format_conf.get("show_stdout", True)
        show_errors = self.format_conf.get("show_error_messages", True)
        detailed_errors = self.format_conf.get("show_detailed_error_messages", True)

        # Split testcases; each group of lines is one testcase's inputs
        testcases_split = self.testcases_str.split("\n") if self.testcases_str else []
        parameters_in_testcase = (
            len(testcases_split) // total_testcases if total_testcases > 0 else 1
        )

        expected_outputs = self.result.expected_code_answer or []
        code_outputs = self.result.code_answer or []
        std_outputs = self.result.std_output_list or []

        # Error fields
        runtime_error = self.result.runtime_error
        full_runtime_error = self.result.full_runtime_error
        compile_error = self.result.compile_error
        full_compile_error = self.result.full_compile_error

        parsed_result = ""

        # For each expected output => 1 testcase
        for i, expected_out in enumerate(expected_outputs):
            if not expected_out:
                break

            # Slice out the matching lines from testcases
            start_idx = i * parameters_in_testcase
            end_idx = start_idx + parameters_in_testcase
            testcase_lines = testcases_split[start_idx:end_idx]

            code_out = code_outputs[i] if i < len(code_outputs) else None
            stdout_line = std_outputs[i] if i < len(std_outputs) else None

            # Convert status_code -> status key
            if status_code == 10:
                # Typically 10 means 'Accepted' or 'Wrong Answer'
                status_key = "Accepted" if code_out == expected_out else "Wrong Answer"
            else:
                status_key = status_msg or "unknown"

            # Attempt theming for the status
            try:
                self.theme_manager.get_styling("INTERPRETATION", status_key)
            except ThemeError as te:
                raise te

            # Retrieve style codes for the status
            try:
                s_ansi, s_left, s_right = self.theme_manager.get_styling(
                    "INTERPRETATION", status_key
                )
            except ThemeError as te:
                raise te

            # Print the status line, e.g. "  ✘ Wrong Answer"
            parsed_result += (
                f"\n  {s_ansi}{s_left}{status_key}{s_right}{self.ANSI_RESET}\n"
            )

            # Show fields
            if show_language:
                parsed_result += self._format_label_value("Language", lang)

            if show_testcases and testcase_lines:
                parsed_result += self._format_label_value(
                    "Testcase", ", ".join(testcase_lines)
                )

            if show_expected_output:
                parsed_result += self._format_label_value(
                    "Expected Output", expected_out
                )

            if show_code_output and code_out:
                parsed_result += self._format_label_value("Your Output", code_out)

            if show_stdout and stdout_line:
                parsed_result += self._format_label_value("Stdout", stdout_line)

            if show_errors:
                if runtime_error:
                    parsed_result += self._format_label_value(
                        "Error Message", runtime_error
                    )
                if compile_error:
                    parsed_result += self._format_label_value(
                        "Error Message", compile_error
                    )

            if detailed_errors:
                if full_runtime_error:
                    parsed_result += self._format_label_value(
                        "Detailed Error", full_runtime_error
                    )
                if full_compile_error:
                    parsed_result += self._format_label_value(
                        "Detailed Error", full_compile_error
                    )

        return parsed_result

    def _format_label_value(self, label: str, value: str) -> str:
        """
        High-level helper that calls _format_field_label and _format_field_value,
        returning a single line (plus potential newlines if value is multiline).
        """
        # Build the label portion (left-justified within some width)
        label_str = self._format_field_label(label)
        # The value portion
        value_str = self._format_field_value(value)

        # We'll place them on the same line separated by a space
        # If the value has multiple lines, we can handle that below
        lines = value_str.split("\n")
        if len(lines) == 1:
            # Single-line scenario
            return f"  {label_str} {lines[0]}\n"
        else:
            # Multi-line scenario: the first line goes with label, subsequent lines are padded
            first_line = f"  {label_str} {lines[0]}\n"
            # Each subsequent line is padded so that it lines up after the label
            padding = " " * (2 + 25 + 1)  # "  " + label_width(25) + 1 space
            subsequent = ""
            for l in lines[1:]:
                if l.strip():
                    subsequent += f"{padding}{l}\n"
            return first_line + subsequent

    def _format_field_label(self, label: str, width: int = 25) -> str:
        """
        Formats the field label using 'field_label' from INTERPRETATION.
        We left-justify label in a fixed-width area so columns align nicely.
        """
        try:
            ansi_code, sym_left, sym_right = self.theme_manager.get_styling(
                "INTERPRETATION", "field_label"
            )
        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        # We combine label and the symbol_right (like a colon, if set in your theme).
        combined_label = f"{label}{sym_right}"
        # We left-justify within 'width' columns
        field_label = f"{ansi_code}{sym_left}{combined_label:<{width}}{self.ANSI_RESET}"
        return field_label

    def _format_field_value(self, value: str) -> str:
        """
        Formats the field value using 'field_value' from INTERPRETATION.
        """
        try:
            ansi_code, sym_left, sym_right = self.theme_manager.get_styling(
                "INTERPRETATION", "field_value"
            )
        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        lines = value.split("\n")
        # Format each line separately so multi-line values work properly
        out_lines = []
        for idx, line in enumerate(lines):
            if not line.strip():
                # If the line is blank, we can skip or just preserve blank line
                out_lines.append("")
                continue
            out_lines.append(f"{ansi_code}{sym_left}{line}{sym_right}{self.ANSI_RESET}")
        return "\n".join(out_lines)

File path: formatters/stats_data_formatter.py:
import logging
from datetime import datetime, timedelta, timezone
from leetcode_cli.models.stats import UserStatsModel, UserActivityModel
from leetcode_cli.constants.stats_constants import (
    RECTANGLES_TOTAL,
    MONTH_SEPARATION,
    DIFFICULTIES,
    COLUMNS,
    MONTH_NAMES,
)
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.exceptions.exceptions import ThemeError

logger = logging.getLogger(__name__)


class StatsFormatter:
    """
    Formats user stats (counts per difficulty) and activity calendar.
    """

    def __init__(self, theme_manager: ThemeManager):
        self.theme_manager = theme_manager
        self.theme_data = theme_manager.load_theme_data()

        self.ANSI_RESET = "\033[0m"  # Reset all styles

    def format_user_stats(self, stats: UserStatsModel) -> str:
        lines = []
        for difficulty in DIFFICULTIES:
            passed = stats.accepted.get(difficulty, 0)
            failed = stats.failed.get(difficulty, 0)
            untouched = stats.untouched.get(difficulty, 0)
            total = passed + failed + untouched
            percentage = (passed / total * 100) if total else 0.0

            ratio = (passed / total) if total else 0.0
            filled = int(round(ratio * RECTANGLES_TOTAL))

            try:
                # Get symbols
                filled_ansi, filled_symbol_left, filled_symbol_right = (
                    self.theme_manager.get_styling("STATS_FORMATTER", "filled_square")
                )
                empty_ansi, empty_symbol_left, empty_symbol_right = (
                    self.theme_manager.get_styling("STATS_FORMATTER", "empty_square")
                )

                # ANSI color for the difficulty
                diff_ansi, diff_symbol_left, diff_symbol_right = (
                    self.theme_manager.get_styling(
                        "STATS_FORMATTER", difficulty.upper()
                    )
                )

                # Build the bar with each symbol wrapped
                filled_bar = "".join(
                    [
                        f"{diff_ansi}{filled_symbol_left}{filled_symbol_right}{self.ANSI_RESET}"
                        for _ in range(filled)
                    ]
                )
                empty_bar = "".join(
                    [
                        f"{diff_ansi}{empty_symbol_left}{empty_symbol_right}{self.ANSI_RESET}"
                        for _ in range(RECTANGLES_TOTAL - filled)
                    ]
                )
                bar = filled_bar + empty_bar

                # Combine all parts with proper styling
                line = f"{diff_ansi}{difficulty:<7}{diff_symbol_left}{diff_symbol_right}{self.ANSI_RESET} {passed:>4}/{total:<4} ({percentage:.2f}%) {bar}"
                lines.append(line)
            except ThemeError as te:
                logger.error(f"Theming Error in format_user_stats: {te}")
                raise te

        return "\n".join(lines)

    def format_user_activity(self, activity: UserActivityModel) -> str:
        daily_activity = activity.daily_activity
        if not daily_activity:
            return "No activity data."

        output = [[" " for _ in range(COLUMNS)] for _ in range(7)]
        date_counts = {}
        for ts, count in daily_activity.items():
            try:
                dt = datetime.fromtimestamp(int(ts), tz=timezone.utc).date()
                date_counts[dt] = count
            except (ValueError, OverflowError):
                continue

        if not date_counts:
            return "No valid daily activity data."

        min_date = min(date_counts.keys())
        max_date = max(date_counts.keys())

        min_sub = min(date_counts.values())
        max_sub = max(date_counts.values())

        total_days = (max_date - min_date).days + 1
        all_dates = [min_date + timedelta(days=i) for i in range(total_days)]

        weekday = all_dates[0].weekday()  # Monday=0
        week_index = 3

        for date in all_dates:
            subs = date_counts.get(date, 0)
            if subs > 0:
                try:
                    # Determine tier based on submissions
                    tier = self._determine_tier(subs, min_sub, max_sub)
                    color, symbol_left, symbol_right = self.theme_manager.get_styling(
                        "STATS_FORMATTER", tier
                    )
                    symbol = self.theme_manager.get_styling(
                        "STATS_FORMATTER", "filled_square"
                    )[1]
                    output[weekday][
                        week_index
                    ] = f"{color}{symbol_left}{symbol}{symbol_right}{self.ANSI_RESET}"
                except ThemeError as te:
                    logger.error(f"Theming Error: {te}")
                    raise te
            else:
                try:
                    tier0_ansi, tier0_symbol_left, tier0_symbol_right = (
                        self.theme_manager.get_styling(
                            "STATS_FORMATTER", "CALENDAR_TIER0"
                        )
                    )
                    symbol = self.theme_manager.get_styling(
                        "STATS_FORMATTER", "empty_square"
                    )[1]
                    output[weekday][
                        week_index
                    ] = f"{tier0_ansi}{tier0_symbol_left}{symbol}{tier0_symbol_right}{self.ANSI_RESET}"
                except ThemeError as te:
                    logger.error(f"Theming Error: {te}")
                    raise te

            if date.day == 1 and week_index < COLUMNS - 1:
                week_index += MONTH_SEPARATION
            if weekday == 6:
                weekday = 0
                week_index += 1
            else:
                weekday += 1

        # Mark months
        output_months = [" " for _ in range(COLUMNS)]
        months_starts = []
        week_index = 3
        weekday = all_dates[0].weekday()

        for date in all_dates:
            if date.day == 1 and week_index < COLUMNS - 1:
                months_starts.append(week_index)
            if weekday == 6:
                weekday = 0
                week_index += 1
            else:
                weekday += 1

        for idx, start_idx in enumerate(months_starts):
            month = MONTH_NAMES[(min_date.month + idx - 1) % 12]
            for i, char in enumerate(month):
                tgt = start_idx - 3 + i
                if 0 <= tgt < COLUMNS:
                    output_months[tgt] = char

        months_parsed = "".join(output_months)
        cal_parsed = "\n".join("".join(row) for row in output)
        return f"{months_parsed}\n{cal_parsed}"

    def _determine_tier(self, subs: int, min_sub: int, max_sub: int) -> str:
        """
        Determines the tier based on submission counts.
        """
        # Define tiers based on percentile or absolute counts
        # For simplicity, define:
        # Tier0: 0
        # Tier1: 1-5
        # Tier2: 6-10
        # Tier3: 11+
        if subs == 0:
            return "CALENDAR_TIER0"
        elif 1 <= subs <= 5:
            return "CALENDAR_TIER1"
        elif 6 <= subs <= 10:
            return "CALENDAR_TIER2"
        else:
            return "CALENDAR_TIER3"

File path: formatters/problemset_data_formatter.py:
import logging

from leetcode_cli.models.problemset import ProblemSet, ProblemSummary
from leetcode_cli.exceptions.exceptions import FormattingError, ThemeError
from leetcode_cli.managers.theme_manager import ThemeManager

logger = logging.getLogger(__name__)


class ProblemSetFormatterError(Exception):
    """Custom exception for ProblemSetFormatter errors."""

    pass


class ProblemSetFormatter:
    """
    Replicates the original 'column-based' formatting of problem listings
    but uses theme data (from ThemeManager) for coloring and symbols.

    Format example (unchanged):
        \t{status_symbol}[{question_id}] {title} {difficulty} ({ac_rate} %)

    where:
      - {question_id} is right-justified in 4 spaces
      - {title} is left-justified with padding of 79 spaces
      - {difficulty} is left-justified with padding of 8 spaces
      - {ac_rate} is a floating percentage
    """

    def __init__(self, problemset: ProblemSet, theme_manager: ThemeManager):
        self.problemset = problemset
        self.theme_manager = theme_manager
        self.theme_data = self.theme_manager.load_theme_data()

        self.ANSI_RESET = "\033[0m"  # Reset all styles

    def _format_question(self, q: ProblemSummary) -> str:
        """
        Formats a single problem with spacing identical to the original code snippet.
        """
        # Title padded to 79 characters
        title = q.title.ljust(79)
        title_ansi, title_left, title_right = self.theme_manager.get_styling(
            "PROBLEMSET", "title"
        )
        formatted_title = (
            f"{title_ansi}{title_left}{title}{title_right}{self.ANSI_RESET}"
        )

        question_id = q.frontend_question_id.rjust(4)
        id_ansi, id_left, id_right = self.theme_manager.get_styling(
            "PROBLEMSET", "question_id"
        )
        formatted_question_id = (
            f"{id_ansi}{id_left}{question_id}{id_right}{self.ANSI_RESET}"
        )

        ac_rate = f"{float(q.ac_rate):.2f}"
        ac_ansi, ac_left, ac_right = self.theme_manager.get_styling(
            "PROBLEMSET", "acceptance_rate"
        )
        formatted_ac_rate = f"{ac_ansi}{ac_left}{ac_rate}{ac_right}{self.ANSI_RESET}"

        difficulty_str = q.difficulty
        diff_key = difficulty_str.capitalize()  # e.g., "Easy", "Medium", "Hard"
        try:
            diff_ansi, diff_left, diff_right = self.theme_manager.get_styling(
                "PROBLEMSET", diff_key
            )

        except ThemeError as te:
            raise te

        padded_diff = difficulty_str.ljust(8)
        formatted_difficulty = (
            f"{diff_ansi}{diff_left}{padded_diff}{diff_right}{self.ANSI_RESET}"
        )

        status_key = q.status.lower() if q.status else "not_started"
        try:
            status_ansi, status_left, status_right = self.theme_manager.get_styling(
                "PROBLEMSET", status_key
            )

        except ThemeError as te:
            raise te

        formatted_status_symbol = (
            f"{status_ansi}{status_left}{status_right}{self.ANSI_RESET}"
        )

        line = (
            f"\t{formatted_status_symbol}"  # e.g. "\t✔"
            f"{formatted_question_id} "  # e.g. "[ 299]" (4 digits right-justified)
            f"{formatted_title} "  # 79-char-ljust title
            f" {formatted_difficulty} "  # e.g. "Easy    " with theming
            f"{formatted_ac_rate}"  # e.g. "(53.45 %)"
        )
        return line

    def get_formatted_questions(self) -> str:
        """
        Returns a formatted string of all problems in the problemset,
        matching the old spacing & alignment, but theming is applied.
        """
        if not self.problemset.questions:
            logger.error("No questions available to format.")
            raise ProblemSetFormatterError("No questions available to format.")

        lines = [self._format_question(q) for q in self.problemset.questions]
        return "\n".join(lines)

File path: formatters/problem_data_formatter.py:
import logging

from bs4 import BeautifulSoup, NavigableString, Tag
from leetcode_cli.models.problem import Problem
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.exceptions.exceptions import ThemeError

logger = logging.getLogger(__name__)


class ProblemFormatter:
    """
    Formats a single Problem object, referencing MAPPINGS['PROBLEM_DESCRIPTION'] for tags, difficulties, etc.
    """

    def __init__(
        self, problem: Problem, format_conf: dict, theme_manager: ThemeManager
    ):
        self.problem = problem
        self.format_conf = format_conf
        self.theme_manager = theme_manager
        self.theme_data = theme_manager.load_theme_data()

        self.ANSI_RESET = "\033[0m"  # Reset all styles

    def get_formatted_problem(self) -> str:
        sections = []

        if self.format_conf.get("show_title", True):
            sections.append(self.title or "")

        if self.format_conf.get("show_tags", True):
            tags_str = self.topic_tags
            if tags_str:
                sections.append(tags_str)

        if self.format_conf.get("show_langs", True):
            sections.append(self.languages)

        if self.format_conf.get("show_description", True):
            desc_str = (
                self.description.rstrip("\xa0").lstrip("\n").rstrip("\n")
                or "No description available."
            )
            sections.append(desc_str)

        if self.format_conf.get("show_examples", True):
            ex_str = self.examples
            if ex_str.strip():
                sections.append(ex_str)
            else:
                sections.append("No examples available.")

        if self.format_conf.get("show_constraints", True):
            con_str = self.constraints
            if con_str.strip():
                sections.append(con_str)

        return "\n\n\n".join(sections)

    @property
    def title(self) -> str:
        difficulty = self.problem.difficulty
        try:
            # Styling for title
            title_ansi, title_symbol_left, title_symbol_right = (
                self.theme_manager.get_styling("PROBLEM_DESCRIPTION", "title")
            )
            styled_title = f"{title_ansi}{title_symbol_left}[{self.problem.question_frontend_id}] {self.problem.title}{title_symbol_right}"
            diff_ansi, diff_symbol_left, diff_symbol_right = (
                self.theme_manager.get_styling(
                    "PROBLEM_DESCRIPTION", difficulty.capitalize()
                )
            )

        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        return f"{styled_title}{self.ANSI_RESET} {diff_ansi}{diff_symbol_left}{difficulty}{diff_symbol_right}{self.ANSI_RESET}"

    @property
    def description(self) -> str:
        if not self.problem.description:
            return ""

        return self._html_to_ansi(self.problem.description)

    @property
    def examples(self) -> str:
        if not self.problem.examples:
            return ""

        return "\n\n".join(self._format_example(ex) for ex in self.problem.examples)

    @property
    def constraints(self) -> str:
        if not self.problem.constraints:
            return ""
        try:
            constraints_ansi, constraints_symbol_left, constraints_symbol_right = (
                self.theme_manager.get_styling(
                    "PROBLEM_DESCRIPTION", "constraints_string"
                )
            )

        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        constraints_html = [self._html_to_ansi(c) for c in self.problem.constraints]
        combined = "\n".join(constraints_html)

        return f"{constraints_ansi}{constraints_symbol_left}Constraints:{constraints_symbol_right}{self.ANSI_RESET}\n{combined}"

    @property
    def topic_tags(self) -> str:
        tags = self.problem.topic_tags
        if not tags:
            return ""
        try:
            label_ansi, label_symbol_left, label_symbol_right = (
                self.theme_manager.get_styling("PROBLEM_DESCRIPTION", "tag_label")
            )

        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        out = [
            f"{label_ansi}{label_symbol_left}tags:{label_symbol_right}{self.ANSI_RESET}"
        ]
        for t in tags:
            try:
                tag_ansi, tag_symbol_left, tag_symbol_right = (
                    self.theme_manager.get_styling("PROBLEM_DESCRIPTION", "tag")
                )

            except ThemeError as te:
                logger.error(f"Theming Error: {te}")
                raise te

            out.append(
                f"{tag_ansi}{tag_symbol_left}{t.lower()}{tag_symbol_right}{self.ANSI_RESET}"
            )

        return " ".join(out)

    @property
    def languages(self) -> str:
        langs = {
            sn["langSlug"] for sn in self.problem.code_snippets if sn.get("langSlug")
        }
        if not langs:
            return "No code snippets available."

        try:
            label_ansi, label_symbol_left, label_symbol_right = (
                self.theme_manager.get_styling("PROBLEM_DESCRIPTION", "language_label")
            )
            lang_ansi, lang_symbol_left, lang_symbol_right = (
                self.theme_manager.get_styling("PROBLEM_DESCRIPTION", "language")
            )

        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        out = [
            f"{label_ansi}{label_symbol_left}langs:{label_symbol_right}{self.ANSI_RESET}"
        ]
        for lang in sorted(langs):
            out.append(
                f"{lang_ansi}{lang_symbol_left}{lang}{lang_symbol_right}{self.ANSI_RESET}"
            )

        return " ".join(out)

    def _html_to_ansi(self, html_content: str) -> str:
        if not html_content:
            return ""

        soup = BeautifulSoup(html_content, "html.parser")
        ansi_str = ""
        style_stack = []

        def traverse(el):
            nonlocal ansi_str, style_stack
            if isinstance(el, NavigableString):
                ansi_str += el
            elif isinstance(el, Tag):
                # Handle <sup> tags by prefixing with caret (^)
                if el.name == "sup":
                    ansi_str += "^"
                    # Traverse the children without any additional styling
                    for child in el.children:
                        traverse(child)
                    return  # Skip further processing

                # Handle <sub> tags by prefixing with underscore (_)
                elif el.name == "sub":
                    ansi_str += "_"
                    # Traverse the children without any additional styling
                    for child in el.children:
                        traverse(child)
                    return  # Skip further processing

                # Handle empty <p> tags containing only non-breaking spaces
                if el.name == "p" and el.get_text(strip=True) == "\xa0":
                    return  # Skip adding anything for this tag

                # Get the styling for the current tag
                try:
                    ansi_code, symbol_left, symbol_right = (
                        self.theme_manager.get_styling("PROBLEM_DESCRIPTION", el.name)
                    )

                except ThemeError as te:
                    raise te

                # Apply the current tag's ANSI code and symbols
                if ansi_code:
                    ansi_str += f"{ansi_code}{symbol_left}"
                    style_stack.append((el.name, ansi_code))

                else:
                    style_stack.append((el.name, ""))

                # Traverse child elements
                for child in el.children:
                    traverse(child)

                # Close the current tag's styling
                if symbol_right:
                    ansi_str += f"{symbol_right}"

                # Pop the current tag from the stack
                popped_tag, popped_ansi = style_stack.pop()

                # Determine if an ANSI reset is needed
                if popped_tag in ["code", "pre"]:
                    ansi_str += self.ANSI_RESET
                    # Re-apply remaining styles
                    for tag, ansi in style_stack:
                        if ansi:
                            ansi_str += ansi
                else:
                    # Re-apply remaining styles by resetting and re-applying
                    if popped_ansi:
                        ansi_str += self.ANSI_RESET
                        for tag, ansi in style_stack:
                            if ansi:
                                ansi_str += ansi

        for child in soup.children:
            traverse(child)

        return ansi_str

    def _format_example(self, example: dict) -> str:
        ex_title = example.get("title", "Example")

        try:
            ex_title_ansi, ex_title_symbol_left, ex_title_symbol_right = (
                self.theme_manager.get_styling("PROBLEM_DESCRIPTION", "example_title")
            )

        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        lines = []
        lines.append(
            f"{ex_title_ansi}{ex_title_symbol_left}{ex_title}{ex_title_symbol_right}{self.ANSI_RESET}\n"
        )

        # Input
        raw_input = ", ".join(example.get("input", []))
        input_str = self._html_to_ansi(raw_input)
        try:
            ex_input_str_ansi, ex_input_symbol_left, ex_input_symbol_right = (
                self.theme_manager.get_styling(
                    "PROBLEM_DESCRIPTION", "example_input_string"
                )
            )
            (
                ex_input_data_ansi,
                ex_input_data_symbol_left,
                ex_input_data_symbol_right,
            ) = self.theme_manager.get_styling(
                "PROBLEM_DESCRIPTION", "example_input_data"
            )

        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        input_line = f"{ex_input_str_ansi}{ex_input_symbol_left}Input{ex_input_symbol_right}{self.ANSI_RESET}"
        input_line += f"{ex_input_data_ansi}{ex_input_data_symbol_left}{input_str}{ex_input_data_symbol_right}{self.ANSI_RESET}".replace(
            "\n",
            self.ANSI_RESET
            + "\n"
            + f"{ex_input_str_ansi}{ex_input_symbol_left}"
            + " " * (len(ex_input_symbol_right) + 5)
            + f"{self.ANSI_RESET}{ex_input_data_ansi}",
        )

        lines.append(input_line + "\n")

        # Output
        raw_output = example.get("output", "")
        out_str = self._html_to_ansi(raw_output)
        try:
            ex_output_str_ansi, ex_output_symbol_left, ex_output_symbol_right = (
                self.theme_manager.get_styling(
                    "PROBLEM_DESCRIPTION", "example_output_string"
                )
            )
            (
                ex_output_data_ansi,
                ex_output_data_symbol_left,
                ex_output_data_symbol_right,
            ) = self.theme_manager.get_styling(
                "PROBLEM_DESCRIPTION", "example_output_data"
            )

        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        output_line = f"{ex_output_str_ansi}{ex_output_symbol_left}Output{ex_output_symbol_right}{self.ANSI_RESET}"
        output_line += f"{ex_output_data_ansi}{ex_output_data_symbol_left}{out_str}{ex_output_data_symbol_right}{self.ANSI_RESET}".replace(
            "\n",
            self.ANSI_RESET
            + "\n"
            + f"{ex_output_str_ansi}{ex_output_symbol_left}"
            + " " * (len(ex_output_symbol_right) + 6)
            + f"{self.ANSI_RESET}{ex_output_data_ansi}",
        )

        lines.append(output_line + "\n")

        # Explanation
        explanation = example.get("explanation", "")
        if explanation:
            expl_str = self._html_to_ansi(explanation)
            try:
                ex_expl_str_ansi, ex_expl_symbol_left, ex_expl_symbol_right = (
                    self.theme_manager.get_styling(
                        "PROBLEM_DESCRIPTION", "example_explanation_string"
                    )
                )
                (
                    ex_expl_data_ansi,
                    ex_expl_data_symbol_left,
                    ex_expl_data_symbol_right,
                ) = self.theme_manager.get_styling(
                    "PROBLEM_DESCRIPTION", "example_explanation_data"
                )

            except ThemeError as te:
                logger.error(f"Theming Error: {te}")
                raise te

            # Replace newline characters with formatted ANSI reset and new lines with symbols
            explanation_line = f"{ex_expl_str_ansi}{ex_expl_symbol_left}Explanation{ex_expl_symbol_right}{self.ANSI_RESET}"
            explanation_line += f"{ex_expl_data_ansi}{ex_expl_data_symbol_left}{expl_str}{ex_expl_data_symbol_right}{self.ANSI_RESET}".replace(
                "\n",
                self.ANSI_RESET
                + "\n"
                + f"{ex_expl_str_ansi}{ex_output_symbol_left}"
                + " " * (len(ex_expl_symbol_right) + 11)
                + f"{self.ANSI_RESET}{ex_expl_data_ansi}",
            )

            lines.append(explanation_line + "\n")

        return "".join(lines)

File path: formatters/submission_result_formatter.py:
import logging

from leetcode_cli.models.submission import SubmissionResult
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.exceptions.exceptions import ThemeError

logger = logging.getLogger(__name__)


class SubmissionFormatter:
    """
    Formats submission results using (ansi, symbol_left, symbol_right) theming.
    """

    def __init__(
        self, result: SubmissionResult, format_conf: dict, theme_manager: ThemeManager
    ):
        self.result = result
        self.format_conf = format_conf
        self.theme_manager = theme_manager
        self.theme_data = theme_manager.load_theme_data()

        self.ANSI_RESET = "\033[0m"  # Reset all styles

    def get_formatted_submission(self) -> str:
        status_code = self.result.status_code
        status_msg = self.result.status_msg
        lang = self.result.pretty_lang or self.result.lang
        total_testcases = self.result.total_testcases

        show_language = self.format_conf.get("show_language", True)
        show_testcases = self.format_conf.get("show_testcases", True)
        show_runtime_memory = self.format_conf.get("show_runtime_memory", True)
        show_code_output = self.format_conf.get("show_code_output", True)
        show_stdout = self.format_conf.get("show_stdout", True)
        show_errors = self.format_conf.get("show_error_messages", True)
        detailed_errors = self.format_conf.get("show_detailed_error_messages", True)
        show_expected_output = self.format_conf.get("show_expected_output", True)

        time_ms = self.result.status_runtime
        time_beats = self.result.runtime_percentile
        memory_size = self.result.status_memory
        memory_beats = self.result.memory_percentile
        total_correct = self.result.total_correct
        total_testcases = self.result.total_testcases
        lang = self.result.pretty_lang or self.result.lang

        last_testcase = self.result.last_testcase
        expected_output = self.result.expected_output
        code_output = self.result.code_output
        std_output = self.result.std_output

        runtime_error = getattr(self.result, "runtime_error", None)
        compile_error = getattr(self.result, "compile_error", None)
        full_runtime_error = getattr(self.result, "full_runtime_error", None)
        full_compile_error = getattr(self.result, "full_compile_error", None)

        # Obtain the styling for the overall status line
        try:
            ansi_code, symbol_left, symbol_right = self.theme_manager.get_styling(
                "SUBMISSION", status_msg
            )
        except ThemeError as te:
            raise te

        ansi_status = (
            f"{ansi_code}{symbol_left}{status_msg}{symbol_right}{self.ANSI_RESET}"
        )
        parsed_result = f"\n  {ansi_status} \n"

        # Now we call _format_label_value for each item, instead of manually building strings
        if show_language and lang:
            parsed_result += self._format_label_value("Language", lang)

        if show_testcases and total_correct is not None and total_testcases is not None:
            parsed_result += self._format_label_value(
                "Passed Testcases", f"{total_correct} / {total_testcases}"
            )

        if show_runtime_memory:
            # Runtime
            if time_ms and time_beats is not None:
                runtime_str = f"{time_ms} (Beats: {time_beats:.2f}%)"
                parsed_result += self._format_label_value("Runtime", runtime_str)

            # Memory
            if memory_size and memory_beats is not None:
                memory_str = f"{memory_size} (Beats: {memory_beats:.2f}%)"
                parsed_result += self._format_label_value("Memory Usage", memory_str)

        if last_testcase and show_testcases:
            parsed_result += self._format_label_value(
                "Failed Testcase", last_testcase.replace("\n", ", ")
            )

        if show_expected_output and expected_output:
            parsed_result += self._format_label_value(
                "Expected Output", expected_output
            )

        if show_code_output and code_output:
            code_output_str = (
                code_output if isinstance(code_output, str) else "\n".join(code_output)
            )
            parsed_result += self._format_label_value("Your Output", code_output_str)

        if show_stdout and std_output:
            std_output_str = (
                std_output if isinstance(std_output, str) else "\n".join(std_output)
            )
            parsed_result += self._format_label_value("Stdout", std_output_str)

        if show_errors:
            if runtime_error:
                parsed_result += self._format_label_value(
                    "Error Message", runtime_error
                )
            if compile_error:
                parsed_result += self._format_label_value(
                    "Error Message", compile_error
                )

        if detailed_errors:
            if full_runtime_error:
                parsed_result += self._format_label_value(
                    "Detailed Error", full_runtime_error
                )
            if full_compile_error:
                parsed_result += self._format_label_value(
                    "Detailed Error", full_compile_error
                )

        return parsed_result

    def _format_label_value(self, label: str, value: str) -> str:
        """
        Combines label and value on one line in a columnar style, using
        `_format_field_label` and `_format_field_value` under the hood.
        If the value has multiple lines, subsequent lines are padded.
        """
        # Build the label portion
        label_str = self._format_field_label(label)
        # Build the multi-line value portion
        value_lines = self._format_field_value(value).split("\n")

        if len(value_lines) == 1:
            # Single line scenario
            return f"  {label_str} {value_lines[0]}\n"

        # Multi-line scenario: the first line is next to label, subsequent lines are padded
        first_line = f"  {label_str} {value_lines[0]}\n"
        subsequent = ""
        # Indent subsequent lines so they align under the value column
        # "  " + 25 chars from label => 2 + 25 + 1 space => 28 total
        padding = " " * (2 + 25 + 1)
        for line in value_lines[1:]:
            if line.strip():
                subsequent += f"{padding}{line}\n"
            else:
                # If the line is empty, we can still add a newline to keep spacing consistent
                subsequent += f"{padding}\n"

        return first_line + subsequent

    def _format_field_label(self, label: str, width: int = 25) -> str:
        """
        Formats the field label using the 'field_label' mapping from SUBMISSION.
        """
        try:
            ansi_code, symbol_left, symbol_right = self.theme_manager.get_styling(
                "SUBMISSION", "field_label"
            )
        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        # Combine label + symbol_right (often a colon) and left justify
        combined_label = f"{label}{symbol_right}"
        return f"{ansi_code}{symbol_left}{combined_label:<{width}}{self.ANSI_RESET}"

    def _format_field_value(self, value: str) -> str:
        """
        Formats the field value using the 'field_value' mapping from SUBMISSION.
        Handles multi-line values by splitting on newline.
        """
        try:
            ansi_code, symbol_left, symbol_right = self.theme_manager.get_styling(
                "SUBMISSION", "field_value"
            )
        except ThemeError as te:
            logger.error(f"Theming Error: {te}")
            raise te

        lines = value.split("\n")
        out_lines = []
        for line in lines:
            # Even if blank, we still produce a line
            out_lines.append(
                f"{ansi_code}{symbol_left}{line}{symbol_right}{self.ANSI_RESET}"
            )

        return "\n".join(out_lines)

File path: models/formatting_config.py:
from dataclasses import dataclass, field
from typing import Dict, Any


@dataclass
class FormattingConfig:
    """
    Represents the user's entire formatting configuration,
    including sub-sections: 'interpretation', 'submission', 'problem_show'.
    """

    interpretation: Dict[str, Any] = field(default_factory=dict)
    submission: Dict[str, Any] = field(default_factory=dict)
    problem_show: Dict[str, Any] = field(default_factory=dict)

File path: models/theme.py:
from dataclasses import dataclass, field
from typing import Dict


@dataclass
class ThemeData:
    """
    Holds all theme sub-dicts (ANSI_CODES, SYMBOLS, etc.).
    Each field corresponds to one key in the loaded theme data.
    """

    ANSI_CODES: Dict[str, str] = field(default_factory=dict)
    SYMBOLS: Dict[str, str] = field(default_factory=dict)
    INTERPRETATION: Dict[str, Dict[str, str]] = field(default_factory=dict)
    SUBMISSION: Dict[str, Dict[str, str]] = field(default_factory=dict)
    PROBLEMSET: Dict[str, Dict[str, str]] = field(default_factory=dict)
    PROBLEM_DESCRIPTION: Dict[str, Dict[str, str]] = field(default_factory=dict)
    STATS_FORMATTER: Dict[str, Dict[str, str]] = field(default_factory=dict)

File path: models/submission.py:
from dataclasses import dataclass
from typing import Optional


@dataclass
class SubmissionResult:
    status_code: int
    lang: str
    run_success: bool
    runtime_error: Optional[str]
    full_runtime_error: Optional[str]
    compile_error: Optional[str]
    full_compile_error: Optional[str]
    status_runtime: str
    memory: int
    display_runtime: str
    question_id: Optional[str]
    elapsed_time: Optional[int]
    compare_result: Optional[str]
    code_output: Optional[str]
    std_output: Optional[str]
    last_testcase: Optional[str]
    expected_output: Optional[str]
    task_finish_time: Optional[int]
    task_name: Optional[str]
    finished: Optional[bool]
    total_correct: Optional[int]
    total_testcases: Optional[int]
    runtime_percentile: Optional[float]
    status_memory: Optional[str]
    memory_percentile: Optional[float]
    pretty_lang: Optional[str]
    submission_id: Optional[str]
    input_formatted: Optional[str]
    input: Optional[str]
    status_msg: str
    state: str

File path: models/interpretation.py:
from dataclasses import dataclass
from typing import List, Optional


@dataclass
class InterpretationResult:
    status_code: int
    lang: str
    run_success: bool
    runtime_error: Optional[str]
    full_runtime_error: Optional[str]
    compile_error: Optional[str]
    full_compile_error: Optional[str]
    status_runtime: str
    memory: int
    display_runtime: str
    code_answer: List[str]
    code_output: List[str]
    std_output_list: List[str]
    elapsed_time: Optional[int]
    task_finish_time: Optional[int]
    task_name: Optional[str]
    expected_status_code: Optional[int]
    expected_lang: Optional[str]
    expected_run_success: Optional[bool]
    expected_status_runtime: Optional[str]
    expected_memory: Optional[int]
    expected_display_runtime: Optional[str]
    expected_code_answer: Optional[List[str]]
    expected_code_output: Optional[List[str]]
    expected_std_output_list: Optional[List[str]]
    expected_elapsed_time: Optional[int]
    expected_task_finish_time: Optional[int]
    expected_task_name: Optional[str]
    correct_answer: Optional[bool]
    compare_result: Optional[str]
    total_correct: Optional[int]
    total_testcases: Optional[int]
    runtime_percentile: Optional[float]
    status_memory: Optional[str]
    memory_percentile: Optional[float]
    pretty_lang: Optional[str]
    submission_id: Optional[str]
    status_msg: str
    state: str

File path: models/problem.py:
from dataclasses import dataclass, field
from typing import List, Dict, Optional


@dataclass
class Problem:
    title: str
    question_frontend_id: str
    description: str
    examples: List[Dict[str, str]]
    constraints: List[str]
    category_title: str
    difficulty: str
    topic_tags: List[str]
    stats: Dict[str, str]
    likes: int = 0
    dislikes: int = 0
    is_paid_only: bool = False
    solution_info: Optional[Dict] = None
    code_snippets: List[Dict[str, str]] = field(default_factory=list)

File path: models/stats.py:
# leetcode_cli/models/stats.py
from dataclasses import dataclass
from typing import Dict


@dataclass
class UserStatsModel:
    """
    Represents user stats by difficulty, including accepted, failed, and untouched counts.
    """

    accepted: Dict[str, int]
    failed: Dict[str, int]
    untouched: Dict[str, int]


@dataclass
class UserActivityModel:
    """
    Represents daily submission activity for a user, typically covering the past year.
    The activity is a dict with timestamps as keys and submission counts as values.
    """

    daily_activity: Dict[int, int]

File path: models/problemset.py:
from dataclasses import dataclass, field
from typing import List, Optional


@dataclass
class ProblemSummary:
    ac_rate: float
    difficulty: str
    question_id: str
    topic_tags: List[str]
    frontend_question_id: str
    paid_only: bool
    status: Optional[str]
    title: str
    title_slug: str


@dataclass
class ProblemSet:
    total: int
    questions: List[ProblemSummary] = field(default_factory=list)

File path: exceptions/exceptions.py:
class FetchingError(Exception):
    """Raised when there is an error fetching data from the external source."""

    pass


class ParsingError(Exception):
    """Raised when there is an error parsing the fetched data into the desired models."""

    pass


class FormattingError(Exception):
    """Raised when there is an error formatting the parsed data for output."""

    pass


class SubmissionError(Exception):
    """Raised when there is an error during submission or related actions."""

    pass


class ThemeError(Exception):
    """Raised when there is an error related to theme loading or validation."""

    pass


class ConfigError(Exception):
    """Raised when configuration is missing, invalid, or otherwise incorrect."""

    pass


class ProblemError(Exception):
    """Custom exception for problem-related errors."""

    pass


class CodeError(Exception):
    """Custom exception for code-related errors."""

    pass


class ProblemSetError(Exception):
    """Custom exception for problemset-related errors."""

    pass


class StatsError(Exception):
    """Custom exception for stats-related errors."""

    pass

File path: commands/test_solution.py:
import click
import logging

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.managers.code_manager import CodeManager
from leetcode_cli.managers.problem_manager import ProblemManager
from leetcode_cli.managers.formatting_config_manager import FormattingConfigManager
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.managers.problemset_manager import ProblemSetManager

from leetcode_cli.formatters.interpretation_result_formatter import (
    InterpretationFormatter,
)
from leetcode_cli.exceptions.exceptions import (
    ConfigError,
    CodeError,
    ProblemError,
    ThemeError,
)

logger = logging.getLogger(__name__)


@click.command(short_help="Test a solution file")
@click.argument("file_path", required=True, type=click.Path(exists=True))
@click.option(
    "--include",
    "-i",
    multiple=True,
    type=click.Choice(
        [
            "language",
            "testcases",
            "expected_output",
            "code_output",
            "stdout",
            "error_messages",
            "detailed_error_messages",
        ],
        case_sensitive=False,
    ),
    metavar="SECTION",
    help="Sections to display. Overrides formatting_config.",
)
def test_cmd(file_path, include):
    """
    Test a solution file with example testcases.
    """
    try:
        # 1) Setup
        config_manager = ConfigManager()
        auth_service = AuthService(config_manager)
        code_manager = CodeManager(config_manager)
        problemset_manager = ProblemSetManager(config_manager, auth_service)
        problem_manager = ProblemManager(
            config_manager, auth_service, problemset_manager
        )
        formatting_config_manager = FormattingConfigManager(config_manager)
        theme_manager = ThemeManager(config_manager)

        # 2) Load format config
        formatting_config = formatting_config_manager.load_formatting_config()
        format_conf = formatting_config.interpretation

        # 3) Override formatting sections if needed
        if include:
            for key in format_conf.keys():
                format_conf[key] = False
            for item in include:
                if item == "language":
                    format_conf["show_language"] = True
                elif item == "testcases":
                    format_conf["show_testcases"] = True
                elif item == "expected_output":
                    format_conf["show_expected_output"] = True
                elif item == "code_output":
                    format_conf["show_code_output"] = True
                elif item == "stdout":
                    format_conf["show_stdout"] = True
                elif item == "error_messages":
                    format_conf["show_error_messages"] = True
                elif item == "detailed_error_messages":
                    format_conf["show_detailed_error_messages"] = True

        # 4) Parse local file => question_id, slug, extension
        _, title_slug, file_extension = problem_manager.problem_data_from_path(
            file_path
        )

        # 5) Read code
        code = code_manager.read_code_from_file(file_path)

        # 6) Determine lang
        lang_slug = code_manager.determine_language_from_extension(file_extension)

        # 7) Get example testcases from the manager (optional approach)
        testcases_str = problem_manager.get_example_testcases(title_slug)

        # 8) Retrieve interpretation result from manager
        interpretation_res = problem_manager.get_interpretation_result(
            title_slug=title_slug,
            code=code,
            lang_slug=lang_slug,
            testcases=testcases_str,
        )

        # 9) Format
        formatter = InterpretationFormatter(
            interpretation_res,
            testcases_str,  # pass as a single string
            format_conf,
            theme_manager,
        )
        output_str = formatter.get_formatted_interpretation()

        # 10) Print
        click.echo(output_str)

    except (ConfigError, CodeError, ProblemError, ThemeError) as e:
        logger.error(e)
        click.echo(f"Error: {e}")

    except Exception as e:
        logger.exception("Unexpected error in test_cmd.")
        click.echo(f"An unexpected error occurred: {e}", err=True)

File path: commands/submit.py:
# file: commands/submit.py

import click
import logging

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.managers.formatting_config_manager import FormattingConfigManager
from leetcode_cli.managers.code_manager import CodeManager
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.managers.problem_manager import ProblemManager
from leetcode_cli.managers.problemset_manager import ProblemSetManager

from leetcode_cli.formatters.submission_result_formatter import SubmissionFormatter
from leetcode_cli.exceptions.exceptions import (
    ConfigError,
    CodeError,
    ProblemError,
    ThemeError,
)

logger = logging.getLogger(__name__)


@click.command(short_help="Submit a solution file to LeetCode")
@click.argument("file_path", required=True, type=click.Path(exists=True))
@click.option(
    "--include",
    "-i",
    multiple=True,
    type=click.Choice(
        [
            "language",
            "testcases",
            "runtime_memory",
            "code_output",
            "stdout",
            "error_messages",
            "detailed_error_messages",
            "expected_output",
        ],
        case_sensitive=False,
    ),
    metavar="SECTION",
    help="Sections to display. Overrides formatting_config.",
)
def submit_cmd(file_path, include):
    """
    Submit a solution file to LeetCode.
    """
    try:
        config_manager = ConfigManager()
        auth_service = AuthService(config_manager)
        formatting_config_manager = FormattingConfigManager(config_manager)
        code_manager = CodeManager(config_manager)
        theme_manager = ThemeManager(config_manager)
        problemset_manager = ProblemSetManager(config_manager, auth_service)
        problem_manager = ProblemManager(
            config_manager, auth_service, problemset_manager
        )

        # Load formatting config
        formatting_config = formatting_config_manager.load_formatting_config()
        format_conf = formatting_config.submission

        # override if user passed --include
        if include:
            for key in format_conf.keys():
                format_conf[key] = False
            for item in include:
                if item == "language":
                    format_conf["show_language"] = True
                elif item == "testcases":
                    format_conf["show_testcases"] = True
                elif item == "runtime_memory":
                    format_conf["show_runtime_memory"] = True
                elif item == "code_output":
                    format_conf["show_code_output"] = True
                elif item == "stdout":
                    format_conf["show_stdout"] = True
                elif item == "error_messages":
                    format_conf["show_error_messages"] = True
                elif item == "detailed_error_messages":
                    format_conf["show_detailed_error_messages"] = True
                elif item == "expected_output":
                    format_conf["show_expected_output"] = True

        # Parse path => (id, slug, ext)
        _, title_slug, file_extension = problem_manager.problem_data_from_path(
            file_path
        )

        # read code
        code = code_manager.read_code_from_file(file_path)

        # lang
        lang_slug = code_manager.determine_language_from_extension(file_extension)

        # manager fetches + parses the submission result
        submission_res = problem_manager.get_submission_result(
            title_slug=title_slug, code=code, lang_slug=lang_slug
        )

        # format
        formatter = SubmissionFormatter(submission_res, format_conf, theme_manager)
        result_str = formatter.get_formatted_submission()
        click.echo(result_str)

    except (ConfigError, ThemeError, CodeError, ProblemError) as e:
        logger.error(e)
        click.echo(f"Error: {e}")

    except Exception as e:
        logger.exception("Unexpected error in submit_cmd.")
        click.echo("An unexpected error occurred.", err=True)

File path: commands/create_solution.py:
import click
import logging

from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.code_manager import CodeManager
from leetcode_cli.managers.problem_manager import ProblemManager
from leetcode_cli.managers.problemset_manager import ProblemSetManager
from leetcode_cli.exceptions.exceptions import ConfigError, CodeError, ProblemError

logger = logging.getLogger(__name__)


@click.command(short_help="Create a solution file for a LeetCode problem")
@click.argument("title_slug_or_id", required=False, metavar="TITLE_SLUG_OR_ID")
def create_cmd(title_slug_or_id):
    """
    Create a solution file for the specified LeetCode problem.

    Usage Examples: leetcode create, leetcode create .cpp, leetcode create two-sum.py, leetcode create 1.two-sum.py, leetcode create two-sum, leetcode create 1, leetcode create 1.cpp
    """
    try:
        config_manager = ConfigManager()
        auth_service = AuthService(config_manager)
        code_manager = CodeManager(config_manager)
        problemset_manager = ProblemSetManager(config_manager, auth_service)
        problem_manager = ProblemManager(
            config_manager, auth_service, problemset_manager
        )

        # If user doesn't provide an argument => use the chosen problem
        if not title_slug_or_id:
            title_slug_or_id = config_manager.get_chosen_problem()

            if not title_slug_or_id:
                click.echo(
                    "Error: No chosen problem found. Please specify a problem or use 'leetcode show' to select one."
                )
                return

        # Distinguish whether the user typed only an extension, e.g. ".cpp"
        if title_slug_or_id.startswith("."):
            # e.g. user typed `.cpp` => meaning extension=cpp, slug from config
            file_ext = title_slug_or_id
            title_slug = config_manager.get_chosen_problem()

            if not title_slug:
                click.echo(
                    "Error: No chosen problem found. Please specify or use 'leetcode show' to select one."
                )
                return

            try:
                frontend_id = problem_manager.get_problem_frontend_id(title_slug)
                # Let code_manager handle extension -> lang
                lang_slug, file_extension = code_manager.infer_lang_and_ext(
                    user_ext=file_ext
                )
                code_manager.create_solution_file_with_snippet(
                    frontend_id, title_slug, lang_slug, file_extension
                )
                click.echo(
                    f"Solution file '{frontend_id}.{title_slug}.{file_extension}' created successfully."
                )
                return

            except (ProblemError, CodeError) as e:
                click.echo(f"Error: {e}")
                return

        # Next, parse if there's a '.' in the argument => might be "123.py" or "1.two-sum.py", etc.
        parts = title_slug_or_id.split(".")
        is_id = title_slug_or_id.isdigit()

        # Cases:
        # 1) "1.two-sum.py" => [ "1", "two-sum", "py" ]
        # 2) "123.py"       => [ "123", "py" ]
        # 3) "two-sum.py"   => [ "two-sum", "py" ]
        # 4) "123"          => no dot
        # 5) "two-sum"      => no dot

        if "." in title_slug_or_id:
            if len(parts) == 3 and parts[0].isdigit():
                # e.g. "1.two-sum.py"
                frontend_id, title_slug, user_ext = parts[0], parts[1], parts[2]
                lang_slug, file_extension = code_manager.infer_lang_and_ext(
                    user_ext=user_ext
                )
                try:
                    code_manager.create_solution_file_with_snippet(
                        frontend_id, title_slug, lang_slug, file_extension
                    )
                    click.echo(
                        f"Solution file '{frontend_id}.{title_slug}.{file_extension}' created successfully."
                    )
                except (ProblemError, CodeError) as e:
                    click.echo(f"Error: {e}")

            elif len(parts) == 2 and parts[0].isdigit():
                # e.g. "123.py"
                frontend_id, user_ext = parts[0], parts[1]
                lang_slug, file_extension = code_manager.infer_lang_and_ext(
                    user_ext=user_ext
                )
                try:
                    title_slug = problem_manager.get_title_slug_for_frontend_id(
                        frontend_id
                    )
                    code_manager.create_solution_file_with_snippet(
                        frontend_id, title_slug, lang_slug, file_extension
                    )
                    click.echo(
                        f"Solution file '{frontend_id}.{title_slug}.{file_extension}' created successfully."
                    )
                except (ProblemError, CodeError) as e:
                    click.echo(f"Error: {e}")

            elif len(parts) == 2:
                # e.g. "two-sum.py"
                title_slug, user_ext = parts[0], parts[1]
                lang_slug, file_extension = code_manager.infer_lang_and_ext(
                    user_ext=user_ext
                )
                try:
                    frontend_id = problem_manager.get_problem_frontend_id(title_slug)
                    code_manager.create_solution_file_with_snippet(
                        frontend_id, title_slug, lang_slug, file_extension
                    )
                    click.echo(
                        f"Solution file '{frontend_id}.{title_slug}.{file_extension}' created successfully."
                    )
                except (ProblemError, CodeError) as e:
                    click.echo(f"Error: {e}")
            else:
                # e.g. "two.sum.py" => multiple dots => unknown format
                click.echo(
                    "Error: Unrecognized file format. Use e.g. 'two-sum.py' or '1.two-sum.py'."
                )
                return

        else:
            # no '.' => might be "123" or "two-sum"
            if is_id:
                # e.g. "123"
                frontend_id = title_slug_or_id
                try:
                    title_slug = problem_manager.get_title_slug_for_frontend_id(
                        frontend_id
                    )
                except ProblemError as e:
                    click.echo(f"Error: {e}")
                    return

                # fallback to config
                try:
                    lang_slug, file_extension = code_manager.infer_lang_and_ext()
                    code_manager.create_solution_file_with_snippet(
                        frontend_id, title_slug, lang_slug, file_extension
                    )
                    click.echo(
                        f"Solution file '{frontend_id}.{title_slug}.{file_extension}' created successfully."
                    )
                except (ProblemError, CodeError) as e:
                    click.echo(f"Error: {e}")

            else:
                # e.g. "two-sum"
                try:
                    # We only have the slug => retrieve the frontend ID from problem_manager
                    frontend_id = problem_manager.get_problem_frontend_id(
                        title_slug_or_id
                    )
                    lang_slug, file_extension = code_manager.infer_lang_and_ext()
                    code_manager.create_solution_file_with_snippet(
                        frontend_id, title_slug_or_id, lang_slug, file_extension
                    )
                    click.echo(
                        f"Solution file '{frontend_id}.{title_slug_or_id}.{file_extension}' created successfully."
                    )

                except (ProblemError, CodeError) as e:
                    click.echo(f"Error: {e}")

    except ConfigError as e:
        logger.error(e)
        click.echo(f"Configuration Error: {e}", err=True)

    except Exception as e:
        logger.exception("An unexpected error occurred during solution creation.")
        click.echo("An unexpected error occurred. Please try again.", err=True)

File path: commands/config.py:
import click
import logging

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.exceptions.exceptions import ConfigError

logger = logging.getLogger(__name__)


@click.command(short_help="Configure user settings")
@click.argument("key")
@click.argument("value")
def config_cmd(key, value):
    """
    Configure user settings.

    KEY can be 'cookie', 'username', or 'language'.
    """
    valid_keys = ["cookie", "username", "language"]

    if key not in valid_keys:
        click.echo(
            f"Error: Invalid configuration key '{key}'. Valid keys: {', '.join(valid_keys)}"
        )
        return

    try:
        # Initialize ConfigManager
        config_manager = ConfigManager()

        if key == "cookie":
            config_manager.set_cookie(value)
            click.echo("Cookie set successfully.")

        elif key == "username":
            config_manager.set_username(value)
            click.echo(f"Username set to '{value}'.")

        elif key == "language":
            config_manager.set_language(value)
            click.echo(f"Language set to '{value}'.")

    except ConfigError as e:
        logger.error(e)
        click.echo(f"Configuration Error: {e}", err=True)

    except Exception as e:
        logger.exception("An unexpected error occurred during configuration.")
        click.echo("An unexpected error occurred. Please try again.", err=True)

File path: commands/theme.py:
import click
import logging

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.exceptions.exceptions import ThemeError, ConfigError

logger = logging.getLogger(__name__)


@click.command(short_help="Change or list themes")
@click.argument("theme_name", required=False)
def theme_cmd(theme_name):
    """
    Show or change the current theme.

    - If THEME_NAME is omitted, list available themes and show the current theme.
    - If THEME_NAME is provided, attempt to set the theme in config.json.
    """
    try:
        # Initialize managers
        config_manager = ConfigManager()
        theme_manager = ThemeManager(config_manager)

        if not theme_name:
            # Display current theme and list available themes
            current = theme_manager.get_current_theme()
            themes = theme_manager.list_themes()

            click.echo(f"Current theme: {current if current else 'None'}")
            click.echo("Available themes:")
            for t in themes:
                click.echo(f"   - {t}")

            return

        # Attempt to set the provided theme
        success = theme_manager.set_current_theme(theme_name)
        if not success:
            click.echo(
                f"Error: Theme '{theme_name}' not found. Use 'leetcode theme' to list available themes."
            )
            return

        # Load theme data to validate
        try:
            theme_data = theme_manager.load_theme_data()
            click.echo(f"Theme set to '{theme_name}'.")

        except ThemeError as e:
            click.echo(
                f"Warning: Theme '{theme_name}' is set, but it seems invalid:\n  {e}\n"
                "You may need to fix its YAML files or switch to another theme."
            )

    except (ConfigError, ThemeError) as e:
        logger.error(e)
        click.echo(f"Configuration/Theme Error: {e}", err=True)

    except Exception as e:
        logger.exception("An unexpected error occurred during theme configuration.")
        click.echo("An unexpected error occurred. Please try again.", err=True)

File path: commands/show_problem.py:
import click
import logging

from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.problem_manager import ProblemManager
from leetcode_cli.managers.problemset_manager import ProblemSetManager
from leetcode_cli.managers.formatting_config_manager import FormattingConfigManager
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.formatters.problem_data_formatter import ProblemFormatter
from leetcode_cli.exceptions.exceptions import (
    ConfigError,
    ProblemError,
    ThemeError,
    ProblemError,
)

logger = logging.getLogger(__name__)


@click.command(short_help="Show problem details")
@click.argument("title_slug_or_frontend_id", required=True)
@click.option(
    "--include",
    "-i",
    multiple=True,
    type=click.Choice(
        ["title", "tags", "langs", "description", "examples", "constraints"],
        case_sensitive=False,
    ),
    metavar="SECTION",
    help="Sections to display. Overrides formatting_config.",
)
def show_cmd(title_slug_or_frontend_id, include):
    """
    Show specific problem details.

    By default, which sections are displayed depends on formatting_config.yaml
    ("problem_show" section). Use --include to override and show only specific sections.
    """
    try:
        # Initialize managers
        config_manager = ConfigManager()
        auth_service = AuthService(config_manager)
        formatting_config_manager = FormattingConfigManager(config_manager)
        problemset_manager = ProblemSetManager(config_manager, auth_service)
        problem_manager = ProblemManager(
            config_manager, auth_service, problemset_manager
        )
        theme_manager = ThemeManager(config_manager)

        formatting_config = formatting_config_manager.load_formatting_config()

        # Override formatting configuration if --include is used
        format_conf = formatting_config.problem_show
        if include:
            for key in format_conf.keys():
                format_conf[key] = False

            mapping = {
                "title": "show_title",
                "tags": "show_tags",
                "langs": "show_langs",
                "description": "show_description",
                "examples": "show_examples",
                "constraints": "show_constraints",
            }
            for item in include:
                key = mapping.get(item.lower())
                if key:
                    format_conf[key] = True

        # Fetch problem data
        try:
            problem = problem_manager.get_specific_problem(title_slug_or_frontend_id)

        except ProblemError as e:
            click.echo(f"Error: {e}")
            return

        if title_slug_or_frontend_id.isdigit():
            # we used that as frontend ID, so fetch the real slug
            slug = problem_manager.get_title_slug_for_frontend_id(
                title_slug_or_frontend_id
            )

        else:
            # else it's a slug
            slug = title_slug_or_frontend_id

        config_manager.set_chosen_problem(slug)

        try:
            # Pass the theme_manager (not theme_data)
            formatter = ProblemFormatter(problem, format_conf, theme_manager)
            formatted_str = formatter.get_formatted_problem()
            click.echo()
            click.echo(formatted_str)
            click.echo()

        except Exception as e:
            logger.error(f"Failed to format problem data: {e}")
            click.echo(f"Error: {e}")

    except (ConfigError, ThemeError) as e:
        logger.error(e)
        click.echo(f"Configuration/Theme Error: {e}", err=True)

    except Exception as e:
        logger.exception("An unexpected error occurred while showing the problem.")
        click.echo("An unexpected error occurred. Please try again.", err=True)

File path: commands/download_problems.py:
import click
import logging

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.managers.problemset_manager import ProblemSetManager
from leetcode_cli.data_fetchers.problemset_data_fetcher import fetch_problemset_metadata
from leetcode_cli.exceptions.exceptions import ProblemSetError, ConfigError

logger = logging.getLogger(__name__)


@click.command(short_help="Download all problems metadata")
def download_problems_cmd():
    """
    Download all LeetCode problems metadata and save locally in order to speed up some commands and enable showing/creating by ID
    """
    try:
        # Initialize managers
        config_manager = ConfigManager()
        auth_service = AuthService(config_manager)
        problemset_manager = ProblemSetManager(config_manager, auth_service)

        # Fetch problemset metadata
        try:
            problems_data = fetch_problemset_metadata()
            if not problems_data:
                click.echo("Error: Failed to fetch problems metadata.")
                return

        except Exception as e:
            logger.error(f"Failed to fetch problemset metadata: {e}")
            click.echo(f"Error: Failed to fetch problems metadata. {e}")
            return

        # Save problemset metadata
        try:
            problemset_manager.save_problemset_metadata(problems_data)
            problems_path = problemset_manager.get_problems_data_path()
            click.echo(f"Problems metadata downloaded to '{problems_path}'.")

        except ProblemSetError as e:
            click.echo(f"Error: {e}")
            return

    except ConfigError as e:
        logger.error(e)
        click.echo(f"Configuration Error: {e}", err=True)

    except Exception as e:
        logger.exception(
            "An unexpected error occurred during problems metadata download."
        )
        click.echo("An unexpected error occurred. Please try again.", err=True)

File path: commands/stats.py:
# file: commands/stats.py

import click
import logging
from datetime import datetime

from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.managers.stats_manager import StatsManager
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.managers.formatting_config_manager import FormattingConfigManager

from leetcode_cli.formatters.stats_data_formatter import StatsFormatter
from leetcode_cli.exceptions.exceptions import ConfigError, StatsError, ThemeError

logger = logging.getLogger(__name__)


@click.command(short_help="Display user statistics from LeetCode")
@click.argument("username", required=False, default=None, metavar="USERNAME")
@click.option(
    "--include",
    "-i",
    multiple=True,
    type=click.Choice(["stats", "calendar"], case_sensitive=False),
    metavar="SECTION",
    help="Sections to display. Overrides formatting_config.",
)
def stats_cmd(username, include):
    """
    Show user stats and/or calendar activity. For example:
      leetcode stats <username> --include stats --include calendar
    """
    try:
        config_manager = ConfigManager()
        auth_service = AuthService(config_manager)
        stats_manager = StatsManager(config_manager, auth_service)
        theme_manager = ThemeManager(config_manager)
        formatting_config_manager = FormattingConfigManager(config_manager)

        # Possibly load formatting_config if the StatsFormatter uses it—(some do, some don't).
        # e.g., if you have "stats_show" or something. We'll skip that for now.

        if not username:
            username = config_manager.get_username()
            if not username:
                click.echo("Error: Username not found in config or CLI param.")
                return

        # If user didn't specify, show both
        if not include:
            include = ("stats", "calendar")

        # Create a StatsFormatter for final output
        formatter = StatsFormatter(theme_manager)

        if "stats" in include:
            try:
                user_stats = stats_manager.get_user_stats(username)
                formatted_stats = formatter.format_user_stats(user_stats)
                click.echo()
                click.echo(formatted_stats)
                click.echo()
            except StatsError as e:
                logger.error(f"Failed to fetch user stats: {e}")
                click.echo(f"Error: {e}")

        if "calendar" in include:
            try:
                current_year = datetime.now().year
                prev_year = current_year - 1
                user_activity = stats_manager.get_joined_activity(
                    username, prev_year, current_year
                )
                formatted_calendar = formatter.format_user_activity(user_activity)
                click.echo()
                click.echo(formatted_calendar)
                click.echo()
            except StatsError as e:
                logger.error(f"Failed to fetch user activity: {e}")
                click.echo(f"Error: {e}")

    except (ConfigError, ThemeError, StatsError) as e:
        logger.error(e)
        click.echo(f"Error: {e}", err=True)
    except Exception as e:
        logger.exception("An unexpected error occurred while fetching statistics.")
        click.echo("An unexpected error occurred. Please try again.", err=True)

File path: commands/list_problems.py:
import click
import logging

from leetcode_cli.constants.problem_constants import POSSIBLE_TAGS
from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.managers.problemset_manager import ProblemSetManager
from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.formatters.problemset_data_formatter import ProblemSetFormatter
from leetcode_cli.exceptions.exceptions import ProblemSetError, ThemeError, ConfigError

logger = logging.getLogger(__name__)


@click.command(short_help="List LeetCode problems with optional filters")
@click.option(
    "--difficulty",
    "-d",
    type=click.Choice(["EASY", "MEDIUM", "HARD"], case_sensitive=False),
    metavar="DIFFICULTY",
    help="Filter by difficulty (default: all difficulties).",
)
@click.option(
    "--tag",
    "-t",
    multiple=True,
    type=click.Choice(POSSIBLE_TAGS, case_sensitive=False),
    metavar="TAG_NAME",
    help="Filter by tag (default: all tags).",
)
@click.option(
    "--limit",
    "-l",
    type=int,
    default=50,
    callback=lambda ctx, param, value: (
        value if value > 0 else click.BadParameter("Must be greater than 0.")
    ),
    metavar="LIMIT",
    help="Number of results per page (default: 50).",
)
@click.option(
    "--page",
    "-p",
    type=int,
    default=1,
    callback=lambda ctx, param, value: (
        value if value > 0 else click.BadParameter("Must be greater than 0.")
    ),
    metavar="PAGE",
    help="Page number to display (default: 1).",
)
def list_cmd(difficulty, tag, limit, page):
    """
    List LeetCode problems with optional filters.
    """
    try:
        # Initialize managers
        config_manager = ConfigManager()
        auth_service = AuthService(config_manager)
        problemset_manager = ProblemSetManager(config_manager, auth_service)
        theme_manager = ThemeManager(config_manager)

        # Get problemset data
        try:
            problemset = problemset_manager.get_problemset(
                tags=tag, difficulty=difficulty, limit=limit, page=page
            )

        except Exception as e:
            click.echo(f"Error: {e}")
            return

        # Format and display problemset
        try:
            # Pass the ThemeManager instead of the raw theme_data
            formatter = ProblemSetFormatter(problemset, theme_manager)
            click.echo()
            click.echo(formatter.get_formatted_questions())
            click.echo()

        except Exception as e:
            logger.error(f"Failed to format problem set: {e}")
            click.echo(f"Error: {e}")

    except (ConfigError, ThemeError, ProblemSetError) as e:
        logger.error(e)
        click.echo(f"Error: {e}", err=True)

    except Exception as e:
        logger.exception("An unexpected error occurred while listing problems.")
        click.echo("An unexpected error occurred. Please try again.", err=True)

File path: commands/show_random.py:
# file: commands/show_random.py

import click
import logging

from leetcode_cli.constants.problem_constants import POSSIBLE_TAGS
from leetcode_cli.managers.config_manager import ConfigManager
from leetcode_cli.managers.problemset_manager import ProblemSetManager
from leetcode_cli.managers.formatting_config_manager import FormattingConfigManager
from leetcode_cli.managers.theme_manager import ThemeManager
from leetcode_cli.managers.problem_manager import ProblemManager
from leetcode_cli.managers.auth_service import AuthService
from leetcode_cli.formatters.problem_data_formatter import ProblemFormatter
from leetcode_cli.exceptions.exceptions import ConfigError, FormattingError, ProblemError, ThemeError, ParsingError

logger = logging.getLogger(__name__)


@click.command(short_help="Show a random problem")
@click.option(
    "--difficulty",
    "-d",
    type=click.Choice(["EASY", "MEDIUM", "HARD"], case_sensitive=False),
    metavar="DIFFICULTY",
    help="Filter random problems by difficulty.",
)
@click.option(
    "--tag",
    "-t",
    multiple=True,
    type=click.Choice(POSSIBLE_TAGS, case_sensitive=False),
    metavar="TAG_NAME",
    help="Filter random problems by tag.",
)
@click.option(
    "--include",
    "-i",
    multiple=True,
    type=click.Choice(
        ["title", "tags", "langs", "description", "examples", "constraints"],
        case_sensitive=False,
    ),
    metavar="SECTION",
    help="Sections to display. Overrides formatting_config.",
)
def random_cmd(difficulty, tag, include):
    """
    Show random problem details.

    By default, which sections are displayed depends on formatting_config.yaml
    ("problem_show" section). Use --include to override and show only specific sections.
    """
    try:
        config_manager = ConfigManager()
        auth_service = AuthService(config_manager)
        formatting_config_manager = FormattingConfigManager(config_manager)
        theme_manager = ThemeManager(config_manager)
        problemset_manager = ProblemSetManager(config_manager, auth_service)
        problem_manager = ProblemManager(
            config_manager, auth_service, problemset_manager
        )

        # Load format config
        formatting_config = formatting_config_manager.load_formatting_config()
        format_conf = formatting_config.problem_show

        # Override problem_show sections if user specified --include
        if include:
            for key in format_conf:
                format_conf[key] = False
            mapping = {
                "title": "show_title",
                "tags": "show_tags",
                "langs": "show_langs",
                "description": "show_description",
                "examples": "show_examples",
                "constraints": "show_constraints",
            }
            for item in include:
                if item in mapping:
                    format_conf[mapping[item]] = True

        # 1) Fetch random Problem object
        problem = problem_manager.get_random_problem(difficulty, tag)

        # 2) Update chosen problem in config
        # We'll need the slug. We added it to the object in get_random_problem
        slug = getattr(problem, "_title_slug", None)
        if not slug:
            # fallback if not present
            # (In your code, Problem does not store the slug natively.)
            # If we can't get slug, do nothing or raise an error
            click.echo("Error: Random problem has no slug. This shouldn't happen.")
            return

        config_manager.set_chosen_problem(slug)

        # 3) Format & display
        formatter = ProblemFormatter(problem, format_conf, theme_manager)
        formatted_str = formatter.get_formatted_problem()
        click.echo()
        click.echo(formatted_str)
        click.echo()

    except (ConfigError, ProblemError, ThemeError) as e:
        logger.error(e)
        click.echo(f"Error: {e}")

    except Exception as e:
        logger.exception("An unexpected error occurred in random_cmd.")
        click.echo(f"An error occurred: {e}")
