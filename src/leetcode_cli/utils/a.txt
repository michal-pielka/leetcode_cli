
File path: stats_utils.py:
# leetcode_cli/utils/stats_utils.py

import json
from datetime import datetime, timezone, timedelta
import logging
from leetcode_cli.graphics.ansi_codes import ANSI_CODES

logger = logging.getLogger(__name__)

def join_and_slice_calendars(previous_year_calendar: dict, current_year_calendar: dict) -> dict:
    """
    Joins and slices the activity calendars from the previous and current years.

    Args:
        previous_year_calendar (dict): The calendar data for the previous year.
        current_year_calendar (dict): The calendar data for the current year.

    Returns:
        dict: A dictionary with timestamps as keys and submission counts as values.

    Raises:
        Exception: If data is invalid or missing.
    """
    if not previous_year_calendar or not current_year_calendar:
        raise Exception("Previous or current year calendar data is missing.")

    try:
        # Load activity data from JSON strings
        previous_activity = json.loads(
            previous_year_calendar['data']['matchedUser']['userCalendar']['submissionCalendar']
        )
        current_activity = json.loads(
            current_year_calendar['data']['matchedUser']['userCalendar']['submissionCalendar']
        )

    except KeyError as error:
        logger.error(f"Missing key in submission_calendar data: {error}")
        raise Exception(f"Missing key in submission_calendar data: {error}")

    except json.JSONDecodeError as error:
        logger.error(f"JSON decoding error: {error}")
        raise Exception(f"JSON decoding error: {error}")

    # Merge activities ensuring the combined dictionary has all timestamps
    merged_activity = {**previous_activity, **current_activity}

    # Convert keys to integers
    merged_activity = {int(timestamp): count for timestamp, count in merged_activity.items()}

    # Get today's date in UTC
    today_utc = datetime.utcnow().date()
    start_date = today_utc - timedelta(days=365)

    # Create start and end datetime objects
    start_datetime = datetime.combine(start_date, datetime.min.time(), tzinfo=timezone.utc)
    end_datetime = datetime.combine(today_utc, datetime.min.time(), tzinfo=timezone.utc)

    start_timestamp = int(start_datetime.timestamp())
    end_timestamp = int(end_datetime.timestamp())

    sliced_activity = {
        timestamp: count for timestamp, count in merged_activity.items()
        if start_timestamp <= timestamp < end_timestamp
    }

    return sliced_activity

def fill_daily_activity(daily_activity: dict) -> dict:
    """
    Fills the daily activity dictionary to ensure every day in the past year is represented.

    Args:
        daily_activity (dict): The original activity data.

    Returns:
        dict: A filled dictionary with timestamps for each day.
    """
    filled_activity = {}
    today_utc = datetime.utcnow().date()
    start_date = today_utc - timedelta(days=365)

    # Create start and end datetime objects
    start_datetime = datetime.combine(start_date, datetime.min.time(), tzinfo=timezone.utc)
    end_datetime = datetime.combine(today_utc, datetime.min.time(), tzinfo=timezone.utc)

    # Generate all daily timestamps within the past year
    current_datetime = start_datetime

    while current_datetime <= end_datetime:
        timestamp = int(current_datetime.timestamp())
        filled_activity[timestamp] = daily_activity.get(timestamp, 0)
        current_datetime += timedelta(days=1)

    return filled_activity

def calculate_color(submissions: int, max_submissions: int, min_submissions: int) -> str:
    """
    Calculates the color code based on the number of submissions.

    Args:
        submissions (int): The number of submissions on a particular day.
        max_submissions (int): The maximum number of submissions in the dataset.
        min_submissions (int): The minimum number of submissions in the dataset.

    Returns:
        str: The ANSI color code.
    """
    CUSTOM_GREENS = [
        ANSI_CODES["GREEN1"],
        ANSI_CODES["GREEN2"],
        ANSI_CODES["GREEN3"],
        ANSI_CODES["GREEN4"],
        ANSI_CODES["GREEN5"],
        ANSI_CODES["GREEN6"]
    ]

    if max_submissions == min_submissions:
        # Avoid division by zero; default to the brightest green
        return CUSTOM_GREENS[-1]

    # Normalize submissions to a value between 0 and 1
    normalized = (submissions - min_submissions) / (max_submissions - min_submissions)
    normalized = max(0.0, min(1.0, normalized))  # Clamp between 0 and 1

    # Determine the index in the CUSTOM_GREENS list
    index = int(normalized * (len(CUSTOM_GREENS) - 1))

    return CUSTOM_GREENS[index]


File path: download_problems_utils.py:
from leetcode_cli.utils.config_utils import get_config_path

import logging
import os
import json

logger = logging.getLogger(__name__)

def get_problems_data_path() -> str:
    """
    Determines the path to the problems data file.

    Returns:
        str: The full path to the problems data file.
    """
    config_dir = os.path.dirname(get_config_path())
    problems_path = os.path.join(config_dir, "problems_metadata.json")
    return problems_path

def load_problems_metadata() -> dict:
    """
    Loads the cached problems metadata from the local JSON file.

    Returns:
        dict: The loaded problems metadata. Returns an empty dictionary if the file doesn't exist or is corrupted.
    """
    problems_path = get_problems_data_path()
    if os.path.exists(problems_path):
        try:
            with open(problems_path, "r") as f:
                return json.load(f)
        except json.JSONDecodeError:
            logger.warning("Problems data file is corrupted. Starting with an empty problems data.")
    return {}

def save_problems_data(data: dict) -> None:
    """
    Saves the problems metadata to a local JSON file.

    Args:
        data (dict): The problems metadata to save.
    """
    problems_path = get_problems_data_path()
    try:
        os.makedirs(os.path.dirname(problems_path), exist_ok=True)
        with open(problems_path, "w") as f:
            json.dump(data, f, indent=4)
        logger.info(f"Problems data saved to {problems_path}")
    except OSError as e:
        logger.error(f"Failed to save problems data: {e}")



def get_problem_by_key_value(problems_data, key, value):
    questions = problems_data.get('data', {}).get('problemsetQuestionList', {}).get('questions', [])

    for problem in questions:
        if str(problem.get(key, "")).lower() == str(value).lower():
            return problem

    logger.warning(f"Problem with {key}='{value}' not found in cached data.")

    return {}

def filter_problems(problems_data, difficulty=None, tags=None):
    """
    Filters the given problems data based on difficulty and tags.

    Args:
        problems_data (dict): The problems metadata.
        difficulty (str, optional): The difficulty level ('Easy', 'Medium', 'Hard'). Defaults to None.
        tags (list of str, optional): A list of tag slugs to filter by. Defaults to None.

    Returns:
        list: The list of filtered problems.
    """
    # Extract the list of questions
    questions = problems_data.get('data', {}).get('problemsetQuestionList', {}).get('questions', [])
    
    if not questions:
        logger.error("No questions found in problems data.")
        return None

    # Apply difficulty filter if specified
    if difficulty:
        difficulty_capitalize = difficulty.capitalize()

        questions = [q for q in questions if q.get('difficulty', '').capitalize() == difficulty_capitalize]
        if not questions:
            logger.warning(f"No problems found with difficulty '{difficulty}'.")
            return None

    # Apply tags filter if specified
    if tags:
        tags_lower = set(tag.lower() for tag in tags)
        filtered_questions = []
        for q in questions:
            problem_tags = q.get('topicTags', [])
            if not problem_tags:
                continue 

            problem_tags_slugs = set(tag['slug'].lower() for tag in problem_tags)
            if tags_lower.issubset(problem_tags_slugs):
                filtered_questions.append(q)

        questions = filtered_questions
        if not questions:
            logger.warning(f"No problems found with tags {', '.join(tags)}.")
            return None

    return questions

def select_random_problem(questions):
    """
    Selects a random problem from the given list of questions.

    Args:
        questions (list): List of problem metadata dictionaries.

    Returns:
        dict: The randomly selected problem's data, or None if the list is empty.
    """
    if not questions:
        return None

    import random

    selected_problem = random.choice(questions)
    logger.info(f"Random problem selected: {selected_problem.get('title', 'Unknown Title')} (Slug: {selected_problem.get('titleSlug', 'N/A')})")
    return selected_problem

def problem_data_from_path(filepath):
    filename = os.path.basename(filepath)
    # Split the filename by the dots to extract parts
    parts = filename.split('.')
    if len(parts) != 3:
        raise ValueError("Invalid filepath format. Expected {question_id}.{title_slug}.{file_extension}")
    
    # Extract parts
    frontend_id = parts[0]
    title_slug = '.'.join(parts[1:-1])  # Join middle parts as the title_slug can have dots
    file_extension = parts[-1]
    
    return frontend_id, title_slug, file_extension








File path: theme_utils.py:
# utils/theme_utils.py

import os
import json
import logging
from leetcode_cli.utils.config_utils import get_config_path, _load_config
from leetcode_cli.exceptions.exceptions import ThemeError

# Import the existing required keys from your theme_validation folder.
from leetcode_cli.constants.theme_validation.problem_validation_constants import (
    PROBLEM_FORMATTER_ANSI_CODES_REQUIRED,
    PROBLEM_FORMATTER_SYMBOLS_REQUIRED
)
from leetcode_cli.constants.theme_validation.interpretation_validation_constants import (
    INTERPRETATION_ANSI_CODES_REQUIRED,
    INTERPRETATION_SYMBOLS_REQUIRED
)
from leetcode_cli.constants.theme_validation.submission_validation_constants import (
    SUBMISSION_ANSI_CODES_REQUIRED,
    SUBMISSION_SYMBOLS_REQUIRED
)
from leetcode_cli.constants.theme_validation.problemset_validation_constants import (
    PROBLEMSET_FORMATTER_ANSI_CODES_REQUIRED,
    PROBLEMSET_FORMATTER_SYMBOLS_REQUIRED
)
from leetcode_cli.constants.theme_validation.stats_validation_constants import (
    STATS_FORMATTER_DIFFICULTY_COLORS_REQUIRED,
    STATS_FORMATTER_SYMBOLS_REQUIRED
)

logger = logging.getLogger(__name__)

def get_themes_dir():
    """
    Returns the path to the 'themes' directory,
    which is typically next to config or inside your user config folder, etc.
    """
    config_dir = os.path.dirname(get_config_path())
    return os.path.join(config_dir, "themes")


def list_themes():
    """
    Return a list of all folder names inside the themes directory.
    """
    themes_dir = get_themes_dir()
    if not os.path.exists(themes_dir):
        return []
    return [d for d in os.listdir(themes_dir) if os.path.isdir(os.path.join(themes_dir, d))]


def get_current_theme() -> str:
    """
    Reads user's current theme from config.json.
    Defaults to 'default_theme' if not set.
    """
    config = _load_config()
    theme_name = config.get("theme", "default_theme")
    return theme_name


def set_current_theme(theme_name: str) -> bool:
    """
    Persists the selected theme in config.json,
    but doesn't validate it immediately.
    You can call 'validate_entire_theme()' or 'load_theme_data()'
    afterwards to ensure it's valid.
    """
    available = list_themes()
    if theme_name not in available:
        logger.error(f"Theme '{theme_name}' does not exist in: {available}")
        return False

    # Save it in config
    config = _load_config()
    config["theme"] = theme_name
    from leetcode_cli.utils.config_utils import _save_config
    _save_config(config)

    logger.info(f"Theme set to '{theme_name}'.")
    return True


def _load_json_file(theme_name: str, filename: str) -> dict:
    """
    Loads a JSON file from the user's chosen theme folder.
    Raises ThemeError if missing or invalid.
    """
    theme_path = os.path.join(get_themes_dir(), theme_name)
    file_path = os.path.join(theme_path, filename)

    if not os.path.exists(file_path):
        error_msg = f"File '{filename}' is missing for theme '{theme_name}'."
        logger.error(error_msg)
        raise ThemeError(error_msg)

    try:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data
    except json.JSONDecodeError:
        error_msg = f"File '{filename}' in theme '{theme_name}' is not valid JSON."
        logger.error(error_msg)
        raise ThemeError(error_msg)


def load_theme_data() -> dict:
    """
    Unified loading of ALL theme data from three files:
        1) ansi_codes.json → theme_data["ANSI_CODES"]
        2) symbols.json → theme_data["SYMBOLS"]
        3) mappings.json → merges directly
           (e.g. "PROBLEM_FORMATTER_ANSI_CODES", "SUBMISSION_SYMBOLS", etc.)

    After loading, we validate everything and then resolve references.

    If any key is missing, or any reference is invalid,
    we raise ThemeError and do not fallback.
    """
    theme_name = get_current_theme()

    # Load ansi_codes.json
    ansi_data = _load_json_file(theme_name, "ansi_codes.json")
    if "ANSI_CODES" not in ansi_data:
        raise ThemeError(f"'ANSI_CODES' missing in ansi_codes.json for theme '{theme_name}'.")

    # Load symbols.json
    symbols_data = _load_json_file(theme_name, "symbols.json")
    if "SYMBOLS" not in symbols_data:
        raise ThemeError(f"'SYMBOLS' missing in symbols.json for theme '{theme_name}'.")

    # Load mappings.json
    mappings_data = _load_json_file(theme_name, "mappings.json")

    # Merge them all
    theme_data = {
        "ANSI_CODES": ansi_data["ANSI_CODES"],
        "SYMBOLS": symbols_data["SYMBOLS"],
    }
    for k, v in mappings_data.items():
        theme_data[k] = v

    # Validate
    _validate_entire_theme_dict(theme_data, theme_name)

    # Resolve references
    _resolve_all_ansi_and_symbol_refs(theme_data)

    return theme_data


def _validate_entire_theme_dict(theme_data: dict, theme_name: str) -> None:
    """
    Checks that all required sections exist and that all required keys
    are present in each mapping. If anything is missing, raises ThemeError.
    """
    # Check existence of main sections
    if "PROBLEM_FORMATTER_ANSI_CODES" not in theme_data:
        raise ThemeError(f"Missing 'PROBLEM_FORMATTER_ANSI_CODES' in mappings.json for theme '{theme_name}'.")
    if "PROBLEM_FORMATTER_SYMBOLS" not in theme_data:
        raise ThemeError(f"Missing 'PROBLEM_FORMATTER_SYMBOLS' in mappings.json for theme '{theme_name}'.")

    if "INTERPRETATION_ANSI_CODES" not in theme_data:
        raise ThemeError(f"Missing 'INTERPRETATION_ANSI_CODES' in mappings.json for theme '{theme_name}'.")
    if "INTERPRETATION_SYMBOLS" not in theme_data:
        raise ThemeError(f"Missing 'INTERPRETATION_SYMBOLS' in mappings.json for theme '{theme_name}'.")

    if "SUBMISSION_ANSI_CODES" not in theme_data:
        raise ThemeError(f"Missing 'SUBMISSION_ANSI_CODES' in mappings.json for theme '{theme_name}'.")
    if "SUBMISSION_SYMBOLS" not in theme_data:
        raise ThemeError(f"Missing 'SUBMISSION_SYMBOLS' in mappings.json for theme '{theme_name}'.")

    if "PROBLEMSET_FORMATTER_ANSI_CODES" not in theme_data:
        raise ThemeError(f"Missing 'PROBLEMSET_FORMATTER_ANSI_CODES' in mappings.json for theme '{theme_name}'.")
    if "PROBLEMSET_FORMATTER_SYMBOLS" not in theme_data:
        raise ThemeError(f"Missing 'PROBLEMSET_FORMATTER_SYMBOLS' in mappings.json for theme '{theme_name}'.")

    if "STATS_FORMATTER_DIFFICULTY_COLORS" not in theme_data:
        raise ThemeError(f"Missing 'STATS_FORMATTER_DIFFICULTY_COLORS' in mappings.json for theme '{theme_name}'.")
    if "STATS_FORMATTER_SYMBOLS" not in theme_data:
        raise ThemeError(f"Missing 'STATS_FORMATTER_SYMBOLS' in mappings.json for theme '{theme_name}'.")

    # Validate required keys in each subsection

    # Problem
    for req in PROBLEM_FORMATTER_ANSI_CODES_REQUIRED:
        if req not in theme_data["PROBLEM_FORMATTER_ANSI_CODES"]:
            raise ThemeError(f"Missing '{req}' in PROBLEM_FORMATTER_ANSI_CODES for theme '{theme_name}'.")
    for req in PROBLEM_FORMATTER_SYMBOLS_REQUIRED:
        if req not in theme_data["PROBLEM_FORMATTER_SYMBOLS"]:
            raise ThemeError(f"Missing '{req}' in PROBLEM_FORMATTER_SYMBOLS for theme '{theme_name}'.")

    # Interpretation
    for req in INTERPRETATION_ANSI_CODES_REQUIRED:
        if req not in theme_data["INTERPRETATION_ANSI_CODES"]:
            raise ThemeError(f"Missing '{req}' in INTERPRETATION_ANSI_CODES for theme '{theme_name}'.")
    for req in INTERPRETATION_SYMBOLS_REQUIRED:
        if req not in theme_data["INTERPRETATION_SYMBOLS"]:
            raise ThemeError(f"Missing '{req}' in INTERPRETATION_SYMBOLS for theme '{theme_name}'.")

    # Submission
    for req in SUBMISSION_ANSI_CODES_REQUIRED:
        if req not in theme_data["SUBMISSION_ANSI_CODES"]:
            raise ThemeError(f"Missing '{req}' in SUBMISSION_ANSI_CODES for theme '{theme_name}'.")
    for req in SUBMISSION_SYMBOLS_REQUIRED:
        if req not in theme_data["SUBMISSION_SYMBOLS"]:
            raise ThemeError(f"Missing '{req}' in SUBMISSION_SYMBOLS for theme '{theme_name}'.")

    # Problemset
    for req in PROBLEMSET_FORMATTER_ANSI_CODES_REQUIRED:
        if req not in theme_data["PROBLEMSET_FORMATTER_ANSI_CODES"]:
            raise ThemeError(f"Missing '{req}' in PROBLEMSET_FORMATTER_ANSI_CODES for theme '{theme_name}'.")
    for req in PROBLEMSET_FORMATTER_SYMBOLS_REQUIRED:
        if req not in theme_data["PROBLEMSET_FORMATTER_SYMBOLS"]:
            raise ThemeError(f"Missing '{req}' in PROBLEMSET_FORMATTER_SYMBOLS for theme '{theme_name}'.")

    # Stats
    for req in STATS_FORMATTER_DIFFICULTY_COLORS_REQUIRED:
        if req not in theme_data["STATS_FORMATTER_DIFFICULTY_COLORS"]:
            raise ThemeError(f"Missing '{req}' in STATS_FORMATTER_DIFFICULTY_COLORS for theme '{theme_name}'.")
    for req in STATS_FORMATTER_SYMBOLS_REQUIRED:
        if req not in theme_data["STATS_FORMATTER_SYMBOLS"]:
            raise ThemeError(f"Missing '{req}' in STATS_FORMATTER_SYMBOLS for theme '{theme_name}'.")


def _resolve_all_ansi_and_symbol_refs(theme_data: dict):
    """
    Replace references in each mapping sub-dict with the actual ANSI codes or symbols
    from theme_data["ANSI_CODES"] and theme_data["SYMBOLS"].

    If something is not found, raise ThemeError. We do not fallback.
    """

    def resolve_ansi(mapping_dict):
        for key, value in mapping_dict.items():
            # e.g. "GREEN BOLD" → ["GREEN", "BOLD"]
            parts = value.split()
            combined = ""
            for part in parts:
                if part not in theme_data["ANSI_CODES"]:
                    raise ThemeError(
                        f"ANSI code '{part}' (used in key '{key}') not found in 'ANSI_CODES'."
                    )
                combined += theme_data["ANSI_CODES"][part]
            mapping_dict[key] = combined

    def resolve_symbols(mapping_dict):
        for key, value in mapping_dict.items():
            # e.g. "CHECKMARK" → "✔"
            if value not in theme_data["SYMBOLS"]:
                raise ThemeError(
                    f"Symbol '{value}' (used in key '{key}') not found in 'SYMBOLS'."
                )
            mapping_dict[key] = theme_data["SYMBOLS"][value]

    # Problem
    resolve_ansi(theme_data["PROBLEM_FORMATTER_ANSI_CODES"])
    resolve_symbols(theme_data["PROBLEM_FORMATTER_SYMBOLS"])
    # Interpretation
    resolve_ansi(theme_data["INTERPRETATION_ANSI_CODES"])
    resolve_symbols(theme_data["INTERPRETATION_SYMBOLS"])
    # Submission
    resolve_ansi(theme_data["SUBMISSION_ANSI_CODES"])
    resolve_symbols(theme_data["SUBMISSION_SYMBOLS"])
    # Problemset
    resolve_ansi(theme_data["PROBLEMSET_FORMATTER_ANSI_CODES"])
    resolve_symbols(theme_data["PROBLEMSET_FORMATTER_SYMBOLS"])
    # Stats
    resolve_ansi(theme_data["STATS_FORMATTER_DIFFICULTY_COLORS"])
    resolve_symbols(theme_data["STATS_FORMATTER_SYMBOLS"])


def validate_entire_theme() -> None:
    """
    Convenience function that attempts to load and validate the entire theme.
    If anything fails, a ThemeError is raised.
    """
    load_theme_data()  # just load, which triggers validation and resolution

File path: code_utils.py:
from leetcode_cli.utils.config_utils import get_language
from leetcode_cli.constants.problem_constants import LANG_SLUG_TO_EXTENSION, EXTENSION_TO_LANG_SLUG, POSSIBLE_LANG_SLUGS

def read_code_from_file(file_path: str) -> str:
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()

def determine_language_from_extension(file_extension: str) -> str:
    lang = EXTENSION_TO_LANG_SLUG.get(file_extension.lower(), None)
    if not lang:
        raise ValueError(f"Unsupported file extension '{file_extension}'.")

    return lang

def get_language_and_extension(file_extension=None):
    """
    Determine language and extension.

    If file_extension is provided, map it directly to language.
    If file_extension is None, use default language from config and map that to extension.
    """
    if file_extension:
        lang_slug = EXTENSION_TO_LANG_SLUG.get(file_extension.lower())
        if not lang_slug:
            return None, None

        return lang_slug, file_extension.lower()
    else:
        # Use default language from config
        lang_slug = get_language()
        if not lang_slug or lang_slug.lower() not in POSSIBLE_LANG_SLUGS:
            return None, None

        file_extension = LANG_SLUG_TO_EXTENSION.get(lang_slug.lower())
        if not file_extension:
            return None, None

        return lang_slug.lower(), file_extension.lower()


File path: formatting_config_utils.py:
import json
import os

from leetcode_cli.utils.config_utils import get_config_path
from leetcode_cli.constants.default_formatting_config import DEFAULT_FORMATTING_CONFIG

def load_formatting_config() -> dict:
    config_dir = os.path.dirname(get_config_path())
    formatting_config_path = os.path.join(config_dir, "formatting_config.json")

    if not os.path.exists(formatting_config_path):
        # Create with defaults
        with open(formatting_config_path, "w") as f:
            json.dump(DEFAULT_FORMATTING_CONFIG, f, indent=4)

        return DEFAULT_FORMATTING_CONFIG

    try:
        with open(formatting_config_path, "r") as f:
            user_config = json.load(f)
            return _merge_dicts(DEFAULT_FORMATTING_CONFIG, user_config)

    except (json.JSONDecodeError, OSError) as e:
        return DEFAULT_FORMATTING_CONFIG


def _merge_dicts(defaults, user_config):
    for key, value in defaults.items():
        if key in user_config:
            if isinstance(value, dict) and isinstance(user_config[key], dict):
                _merge_dicts(value, user_config[key])

            else:
                defaults[key] = user_config[key]

    return defaults


File path: config_utils.py:
import json
import os
import platform
import logging

logger = logging.getLogger(__name__)


def get_config_path() -> str:
    """
    Determines the configuration file path based on the operating system.

    Returns:
        str: The full path to the configuration file.
    """
    if platform.system() == "Windows":
        config_dir = os.getenv("APPDATA", os.path.expanduser("~\\AppData\\Roaming"))
        config_path = os.path.join(config_dir, "leetcode", "config.json")
    else:  # macOS and Linux
        config_dir = os.path.expanduser("~/.config/leetcode")
        config_path = os.path.join(config_dir, "config.json")
    return config_path


def _load_config():
    """
    Loads the configuration from the config file.

    Returns:
        dict: The configuration dictionary.
    """
    config_path = get_config_path()
    if os.path.exists(config_path):
        try:
            with open(config_path, "r") as f:
                return json.load(f)
        except json.JSONDecodeError:
            logger.warning("Config file is corrupted. Starting with an empty config.")
    return {}



def _save_config(config):
    """
    Saves the configuration dictionary to the config file.

    Args:
        config (dict): The configuration dictionary to save.
    """
    config_path = get_config_path()
    config_dir = os.path.dirname(config_path)
    try:
        os.makedirs(config_dir, exist_ok=True)
        with open(config_path, "w") as f:
            json.dump(config, f, indent=4)
        logger.info(f"Configuration saved to {config_path}")
    except OSError as e:
        logger.error(f"Failed to save configuration: {e}")

def set_cookie(cookie: str) -> None:
    """
    Sets the user's cookie in the configuration file.

    Args:
        cookie (str): The cookie string to save.
    """
    config = _load_config()
    config["cookie"] = cookie
    _save_config(config)

def set_username(username: str) -> None:
    """
    Sets the user's username in the configuration file.

    Args:
        username (str): The username to save.
    """
    config = _load_config()
    config["username"] = username
    _save_config(config)

def set_language(language: str) -> None:
    """
    Sets the user's preferred programming language in the configuration file.

    Args:
        language (str): The programming language to save.
    """
    config = _load_config()
    config["language"] = language
    _save_config(config)

def set_chosen_problem(title_slug: str) -> None:
    """
    Sets the solution file path in the configuration file.

    Args:
        file_path (str): The solution file path to save.
    """
    config = _load_config()
    config["chosen_problem"] = title_slug
    _save_config(config)

def extract_csrf_token(cookie: str) -> str:
    """
    Extracts the CSRF token from the cookie string.

    Args:
        cookie (str): The cookie string.

    Returns:
        str: The CSRF token if found, else an empty string.
    """
    import re
    try:
        match = re.search(r'csrftoken=([^;]+)', cookie)

    except Exception:
        return None

    if match:
        return match.group(1)
    else:
        logger.error("CSRF token not found in the cookie.")
        return None

def get_cookie():
    config = _load_config()
    cookie = config.get("cookie", None)

    if not cookie:
        logger.error("Cookie not found in configuration.")

    return cookie

def get_username():
    config = _load_config()
    username = config.get("username", None)

    if not username:
        logger.error("Username not found in configuration.")
        
    return username

def get_language():
    config = _load_config()
    language = config.get("language", None)

    if not language:
        logger.error("Language not found in configuration.")

    return language

def get_chosen_problem():
    config = _load_config()
    chosen_problem = config.get("chosen_problem", None)

    if not chosen_problem:
        logger.error("Solution file path not found in configuration.")

    return chosen_problem

