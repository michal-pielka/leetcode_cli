
File path: user_utils.py:
import json
import os
import platform
import re
import logging
from typing import Dict

logger = logging.getLogger(__name__)


def get_config_path() -> str:
    """
    Determines the configuration file path based on the operating system.

    Returns:
        str: The full path to the configuration file.
    """
    if platform.system() == "Windows":
        config_dir = os.getenv("APPDATA", os.path.expanduser("~\\AppData\\Roaming"))
        config_path = os.path.join(config_dir, "leetcode", "config.json")
    else:  # macOS and Linux
        config_dir = os.path.expanduser("~/.config/leetcode")
        config_path = os.path.join(config_dir, "config.json")
    return config_path


def _load_config() -> Dict[str, str]:
    """
    Loads the configuration from the config file.

    Returns:
        dict: The configuration dictionary.
    """
    config_path = get_config_path()
    if os.path.exists(config_path):
        try:
            with open(config_path, "r") as f:
                return json.load(f)
        except json.JSONDecodeError:
            logger.warning("Config file is corrupted. Starting with an empty config.")
    return {}


def _save_config(config: Dict[str, str]) -> None:
    """
    Saves the configuration dictionary to the config file.

    Args:
        config (dict): The configuration dictionary to save.
    """
    config_path = get_config_path()
    config_dir = os.path.dirname(config_path)
    try:
        os.makedirs(config_dir, exist_ok=True)
        with open(config_path, "w") as f:
            json.dump(config, f, indent=4)
        logger.info(f"Configuration saved to {config_path}")
    except OSError as e:
        logger.error(f"Failed to save configuration: {e}")


def set_cookie(cookie: str) -> None:
    """
    Sets the user's cookie in the configuration file.

    Args:
        cookie (str): The cookie string to save.
    """
    config = _load_config()
    config["cookie"] = cookie
    _save_config(config)


def set_username(username: str) -> None:
    """
    Sets the user's username in the configuration file.

    Args:
        username (str): The username to save.
    """
    config = _load_config()
    config["username"] = username
    _save_config(config)


def set_language(language: str) -> None:
    """
    Sets the user's preferred programming language in the configuration file.

    Args:
        language (str): The programming language to save.
    """
    config = _load_config()
    config["language"] = language
    _save_config(config)


def extract_csrf_token(cookie: str) -> str:
    """
    Extracts the CSRF token from the cookie string.

    Args:
        cookie (str): The cookie string.

    Returns:
        str: The CSRF token if found, else an empty string.
    """
    match = re.search(r'csrftoken=([^;]+)', cookie)
    if match:
        return match.group(1)
    else:
        logger.error("CSRF token not found in the cookie.")
        return ""


def get_cookie() -> str:
    """
    Loads the user's cookie from the configuration file.

    Returns:
        str: The cookie string if found, else an empty string.
    """
    config = _load_config()
    cookie = config.get("cookie", "")
    if not cookie:
        logger.error("Cookie not found in configuration.")
    return cookie


def get_username() -> str:
    """
    Loads the user's username from the configuration file.

    Returns:
        str: The username string if found, else an empty string.
    """
    config = _load_config()
    username = config.get("username", "")
    if not username:
        logger.error("Username not found in configuration.")
    return username


def get_language() -> str:
    """
    Loads the user's preferred language from the configuration file.

    Returns:
        str: The language string if found, else an empty string.
    """
    config = _load_config()
    language = config.get("language", "")
    if not language:
        logger.error("Language not found in configuration.")
    return language

File path: test.py:
from .data_fetching.leetcode_stats import fetch_leetcode_stats, fetch_leetcode_activity
from .data_fetching.fetch_code_snippet import fetch_code_snippet
from .data_fetching.leetcode_problem_fetcher import LeetCodeProblemFetcher

from .parsers.parser_utils.leetcode_stats_parser import *
from .parsers.submission_parser import parse_submission
from .parsers.leetcode_stats_parser import parse_leetcode_stats, parse_daily_activity
from .parsers.leetcode_problem_parser import LeetCodeProblemParser
from .parsers.leetcode_problemset_parser import LeetCodeProblemsetParser

from .parsers.parser_utils.leetcode_stats_parser import *

# Test parsing stats
def parse_stats():
    username = "BucketAbuser"
    user_stats = fetch_leetcode_stats(username)

    parsed_stats = parse_leetcode_stats(user_stats)
    print(parsed_stats)

def parse_activity():
    username = "BucketAbuser"
    y1activ = fetch_leetcode_activity(username, 2024)
    y2activ = fetch_leetcode_activity(username, 2023)

    joinedActiv = join_and_slice_calendars(y2activ, y1activ)
    filledActiv = fill_daily_activity(joinedActiv)

    parsed = parse_daily_activity(filledActiv)
    print(parsed)


def parse_problem(title_slug = "house-robber"):
    problem = LeetCodeProblemFetcher()
    metadata = problem.fetch_problem_data(title_slug)

    parser = LeetCodeProblemParser(metadata)

    print(parser.get_formatted_title())
    print()
    print(parser.get_formatted_topic_tags())
    print()
    print(parser.get_formatted_languages())
    print(parser.get_formatted_description())
    print(parser.get_formatted_examples())
    print()
    print(parser.get_formatted_constraints())

def parse_problemset():
    tags = []
    difficulty = "Medium" 
    limit = 50
    skip = 0
    category_slug = "all-code-essentials"
    problems_dict = LeetCodeProblemFetcher.fetch_problemset(tags = tags, difficulty = difficulty, limit = limit, skip = skip, category_slug=category_slug)

    parser = LeetCodeProblemsetParser(problems_dict)
    s = parser.parse_questions()
    print(s)

#parse_stats()
#parse_activity()
parse_problemset()

File path: parsers/leetcode_stats_parser.py:
from datetime import datetime, timedelta, timezone

from ..data_fetching.leetcode_stats import fetch_leetcode_stats, fetch_leetcode_activity
from ..graphics.symbols import SYMBOLS
from ..graphics.escape_sequences import ANSI_CODES, ANSI_RESET
from ..parsers.parser_utils.leetcode_stats_parser import (
    join_and_slice_calendars,
    fill_daily_activity,
    calculate_color,
)
import logging

logger = logging.getLogger(__name__)

RECTANGLES_TOTAL = 66
DIFFICULTIES = ["EASY", "MEDIUM", "HARD"]
MONTH_NAMES = [
    "Jan", "Feb", "Mar", "Apr", "May", "Jun",
    "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
]
MONTH_SEPARATION = 3
COLUMNS = 100


def parse_leetcode_stats(data: dict) -> str:
    try:
        user_progress = data["data"]["userProfileUserQuestionProgressV2"]

        # Extract counts by difficulty
        accepted = {item["difficulty"].upper(): item["count"] for item in user_progress.get("numAcceptedQuestions", [])}
        failed = {item["difficulty"].upper(): item["count"] for item in user_progress.get("numFailedQuestions", [])}
        untouched = {item["difficulty"].upper(): item["count"] for item in user_progress.get("numUntouchedQuestions", [])}
        logger.debug(f"Accepted: {accepted}, Failed: {failed}, Untouched: {untouched}")

        # Calculate total per difficulty
        total_counts = {}
        for difficulty in DIFFICULTIES:
            total_counts[difficulty] = (
                accepted.get(difficulty, 0) +
                failed.get(difficulty, 0) +
                untouched.get(difficulty, 0)
            )

        # Define colors for difficulties
        difficulty_colors = {
            "EASY": ANSI_CODES["GREEN"],
            "MEDIUM": ANSI_CODES["ORANGE"],
            "HARD": ANSI_CODES["RED"]
        }

        stats_lines = []
        for difficulty in DIFFICULTIES:
            passed = accepted.get(difficulty, 0)
            total = total_counts.get(difficulty, 0)

            if total == 0:
                percentage = 0.0
            else:
                percentage = (passed / total) * 100

            # Calculate filled rectangles
            if total > 0:
                progress_ratio = passed / total
            else:
                progress_ratio = 0.0
            filled = int(round(progress_ratio * RECTANGLES_TOTAL))
            filled = max(0, min(filled, RECTANGLES_TOTAL))  # Clamp between 0 and RECTANGLES_TOTAL

            # Create progress bar with filled and empty rectangles (without coloring the symbols)
            filled_bar = SYMBOLS['FILLED_SQUARE'] * filled
            empty_bar = SYMBOLS['EMPTY_SQUARE'] * (RECTANGLES_TOTAL - filled)
            progress_bar = filled_bar + empty_bar

            # Get the color for the entire line
            color = difficulty_colors.get(difficulty, ANSI_RESET)

            # Formatting
            stats_line = (
                f"{color}{difficulty:<7} {passed:>4}/{total:<4} ({percentage:.2f}%) {progress_bar}{ANSI_RESET}"
            )
            stats_lines.append(stats_line)

        # Combine all outputs
        formatted_stats = "\n".join(stats_lines)
        return formatted_stats

    except (KeyError, TypeError, ZeroDivisionError) as error:
        logger.error(f"Error parsing LeetCode stats: {error}")
        return ""


def parse_daily_activity(filled_activity: dict) -> str:
    """
    Parses daily activity and returns a formatted calendar string.

    Args:
        filled_activity (dict): A dictionary with timestamps as keys and submission counts as values.

    Returns:
        str: A formatted string representing the activity calendar.
    """
    if not filled_activity:
        logger.error("No daily activity data available")
        return ""

    # Initialize output: 7 rows for days of the week, COLUMNS weeks
    output = [[' ' for _ in range(COLUMNS)] for _ in range(7)]

    # Convert timestamps to dates and map counts
    date_counts = {}
    for ts, count in filled_activity.items():
        try:
            date = datetime.fromtimestamp(int(ts), tz=timezone.utc).date()
            date_counts[date] = count
        except (ValueError, OverflowError):
            continue  # Skip invalid timestamps

    if not date_counts:
        logger.error("No valid daily activity data available")
        return ""

    months_starting_indexes = []

    # Determine the date range
    min_date = min(date_counts.keys())
    max_date = max(date_counts.keys())
    min_submissions = min(date_counts.values())
    max_submissions = max(date_counts.values())

    # Generate all dates from start_date to end_date
    total_days = (max_date - min_date).days + 1
    all_dates = [min_date + timedelta(days=i) for i in range(total_days)]

    # Initialize tracking variables
    weekday = all_dates[0].weekday()  # Monday=0, Sunday=6
    week_index = 3  # Starting week index
    for date in all_dates:
        submissions = date_counts.get(date, 0)

        if submissions > 0:
            color = calculate_color(submissions, max_submissions, min_submissions)
            output[weekday][week_index] = f"{color}{SYMBOLS['FILLED_SQUARE']}{ANSI_RESET}"
        else:
            output[weekday][week_index] = f"{ANSI_CODES['GRAY']}{SYMBOLS['FILLED_SQUARE']}{ANSI_RESET}"

        # Check if it's the last day of the month
        if date.day == 1 and week_index < COLUMNS - 1:
            months_starting_indexes.append(week_index)
            week_index += MONTH_SEPARATION

        # Move to next day
        if weekday == 6:
            weekday = 0
            week_index += 1
        else:
            weekday += 1

    # Generate month labels
    months_parsed_list = [' ' for _ in range(COLUMNS)]
    for idx, start_index in enumerate(months_starting_indexes):
        month = MONTH_NAMES[(min_date.month + idx - 1) % 12]
        for i, char in enumerate(month):
            target_index = start_index - 3 + i
            if 0 <= target_index < COLUMNS:
                months_parsed_list[target_index] = char

    months_parsed = ''.join(months_parsed_list)

    # Generate calendar lines
    calendar_parsed = '\n'.join(''.join(row) for row in output)

    return f"{months_parsed}\n{calendar_parsed}"

File path: parsers/leetcode_problemset_parser.py:

from ..graphics.escape_sequences import ANSI_CODES, ANSI_RESET
from ..graphics.symbols import SYMBOLS

class LeetCodeProblemsetParser:
    DIFFICULTY_TO_ANSI = {
        "Easy" : ANSI_CODES["GREEN"],
        "Medium" : ANSI_CODES["ORANGE"],
        "Hard" : ANSI_CODES["RED"]
    }

    QUESTION_STATUS_TO_COLORED_SYMBOL = {
        "ac" : ANSI_CODES["GREEN"] + SYMBOLS["CHECKMARK"] + ANSI_RESET,
        "notac" : ANSI_CODES["ORANGE"] + SYMBOLS["ATTEMPTED"] + ANSI_RESET,
        #None: ANSI_CODES["RED"] + SYMBOLS["X"] + ANSI_RESET
        None: " "
    }

    def __init__(self, problemset_metadata):
        self.problemset_metadata = problemset_metadata

        print(problemset_metadata)
        self.problemset_data = self.problemset_metadata.get("data", None)

        self.problemset_question_list = self.problemset_data.get("problemsetQuestionList", None)
        self.total_problems = self.problemset_question_list.get("total", None)
        self.questions = self.problemset_question_list.get("questions", None)

    def _parse_question(self, question_data):
        title = question_data.get("title", "").ljust(79)  # Adjust width for title alignment
        question_id = str(question_data.get("frontendQuestionId", "")).rjust(4)  # Align ID for up to 4 digits
        acceptance_rate = f"{float(question_data.get('acRate', 0)):.2f}"  # Format acceptance rate with two decimals
        difficulty = question_data.get("difficulty", "")
        status = question_data.get("status", None)
        # Colorize and align difficulty
        formatted_difficulty = f"{self.DIFFICULTY_TO_ANSI[difficulty]}{difficulty.ljust(8)}{ANSI_RESET}"

        # Combine all parts into a formatted string
        
        parsed_question = f"\t{self.QUESTION_STATUS_TO_COLORED_SYMBOL[status]}[{question_id}] {title} {formatted_difficulty} ({acceptance_rate} %)"
        return parsed_question

    def parse_questions(self):
        parsed_string = ""

        for question in self.questions:
            parsed_question = self._parse_question(question)
            parsed_string += parsed_question
            parsed_string += "\n"

        return parsed_string
        
        


File path: parsers/submission_parser.py:
from ..graphics.escape_sequences import ANSI_CODES, ANSI_RESET
import logging

logger = logging.getLogger(__name__)

# TODO: Make submissions friendlier

def parse_submission(submission: dict) -> str:
    status_code = submission.get("status_code")

    # Map status codes to their corresponding parser functions
    parsers = {
        10: parse_accepted,
        11: parse_wrong_answer,
        12: parse_memory_limit_exceeded,
        13: parse_output_limit_exceeded,
        14: parse_time_limit_exceeded,
        15: parse_runtime_error,
        20: parse_compile_error,
    }

    parse_function = parsers.get(status_code)
    if parse_function:
        return parse_function(submission)
    else:
        logger.error("Unknown submission status code.")
        return "Unknown submission status code."


def parse_accepted(submission: dict) -> str:
    time_ms = submission.get("status_runtime", "N/A")
    memory_size = submission.get("status_memory", "N/A")

    parsed_result = (
        f"{ANSI_CODES['GREEN']}Accepted{ANSI_RESET}\n"
        f"Runtime: {time_ms}\n"
        f"Memory Usage: {memory_size}"
    )

    return parsed_result


def parse_wrong_answer(submission: dict) -> str:
    last_testcase = submission.get("last_testcase", "")
    expected_output = submission.get("expected_output", "")
    code_output = submission.get("code_output", "")
    parsed_result = (
        f"{ANSI_CODES['RED']}Wrong Answer{ANSI_CODES['RESET_COLOR']}\n"
        f"Testcase: {last_testcase}\n"
        f"Expected Output: {expected_output}\n"
        f"Your Output: {code_output}"
    )

    return parsed_result


def parse_memory_limit_exceeded(submission: dict) -> str:
    return f"{ANSI_CODES['RED']}Memory Limit Exceeded{ANSI_CODES['RESET_COLOR']}"


def parse_output_limit_exceeded(submission: dict) -> str:
    return f"{ANSI_CODES['RED']}Output Limit Exceeded{ANSI_CODES['RESET_COLOR']}"


def parse_time_limit_exceeded(submission: dict) -> str:
    return f"{ANSI_CODES['RED']}Time Limit Exceeded{ANSI_CODES['RESET_COLOR']}"


def parse_runtime_error(submission: dict) -> str:
    error_msg = submission.get("runtime_error", "No error message.")
    return f"{ANSI_CODES['RED']}Runtime Error{ANSI_CODES['RESET_COLOR']}\n{error_msg}"


def parse_compile_error(submission: dict) -> str:
    error_msg = submission.get("compile_error", "No error message.")
    return f"{ANSI_CODES['RED']}Compile Error{ANSI_CODES['RESET_COLOR']}\n{error_msg}"

File path: parsers/leetcode_problem_parser.py:
from bs4 import BeautifulSoup, NavigableString, Tag
import re

from ..graphics.escape_sequences import *
from ..graphics.symbols import SYMBOLS

#from ..data_fetching.leetcode_problem_fetcher

class LeetCodeProblemParser:
    HTML_TO_ANSI = {
        "strong": ANSI_CODES["BOLD"],
        "b": ANSI_CODES["BOLD"],
        "em": ANSI_CODES["ITALIC"],
        "i": ANSI_CODES["ITALIC"],
        "u": ANSI_CODES["UNDERLINE"],
        "code": ANSI_CODES["GRAY_BG"],
        "pre": ANSI_CODES["RED"],
        "tag": ANSI_CODES["BABY_BLUE_BG"] + ANSI_CODES["WHITE"] + ANSI_CODES["BOLD"],
        "language": ANSI_CODES["ORANGE_BG"] + ANSI_CODES["BLACK"] + ANSI_CODES["BOLD"],
        "title": ANSI_CODES["BOLD"],
        "example_title": ANSI_CODES["BOLD"],
        "example_input_string": ANSI_CODES["BOLD"],
        "example_output_string": ANSI_CODES["BOLD"],
        "example_explanation_string": ANSI_CODES["BOLD"],
        "example_input_data": ANSI_CODES["GRAY"],
        "example_output_data": ANSI_CODES["GRAY"],
        "example_explanation_data": ANSI_CODES["GRAY"],
        "constraints_string": ANSI_CODES["BOLD"],
        "Easy": ANSI_CODES["GREEN_BG"],
        "Medium": ANSI_CODES["ORANGE_BG"],
        "Hard": ANSI_CODES["RED_BG"],
    }

    HTML_TO_SYMBOL = {
        "sup": SYMBOLS["CARET"],
        "li": SYMBOLS["DOT"] + " ",
    }

    def __init__(self, metadata: dict):
        """
        Initializes the parser with problem metadata.

        Args:
            metadata (dict): The raw problem metadata fetched from LeetCode API.
        """
        if not metadata or not isinstance(metadata, dict):
            raise ValueError("Metadata must be a non-empty dictionary.")

        self.metadata = metadata
        self.question_data = self._extract_question_data()
        self.question_html_content = self.question_data.get("content", "")
        self.is_paid_only = self.question_data.get("isPaidOnly", False)

        # Extracted attributes
        self.question_id = self.question_data.get("questionId", "")
        self.question_title = self.question_data.get("title", "")
        self.question_description = self._extract_question_description()
        self.question_examples = self._extract_question_examples()
        self.question_constraints = self._extract_question_constraints()
        self.question_hints = self.question_data.get("hints", [])
        self.question_topic_tags = self.question_data.get("topicTags", [])
        self.question_languages = self.metadata.get("data", {}).get("submittableLanguageList", [])
        self.question_difficulty = self.question_data.get("difficulty", "")
        self.question_likes = self.question_data.get("likes", 0)
        self.question_dislikes = self.question_data.get("dislikes", 0)
        self.question_example_testcases = self.question_data.get("exampleTestcases", "")

    def _extract_question_data(self) -> dict:
        """
        Extracts question data from metadata.

        Returns:
            dict: The question data.
        """
        try:
            return self.metadata["data"]["question"]
        except KeyError as e:
            raise KeyError(f"Missing key in metadata: {e}")

    def _extract_question_description(self) -> str:
        """
        Extracts the question description from HTML content.

        Returns:
            str: The question description in HTML.
        """
        soup = BeautifulSoup(self.question_html_content, "html.parser")
        description_elements = []
        for element in soup.find_all(['p', 'ul']):
            if element.find('strong', string=re.compile(r'Example')):
                break
            description_elements.append(str(element))
        description_html = "\n".join(description_elements).strip()
        return description_html

    def _extract_question_examples(self) -> list:
        """
        Extracts examples from the question content.

        Returns:
            list: A list of example dictionaries.
        """
        soup = BeautifulSoup(self.question_html_content, "html.parser")
        examples = []
        example_headers = soup.find_all('strong', string=re.compile(r'Example \d+'))
        for header in example_headers:
            example = self._parse_example_section(header)
            if example:
                examples.append(example)
        return examples

    def _parse_example_section(self, header) -> dict:
        """
        Parses an example section from the HTML.

        Args:
            header (Tag): The header tag of the example.

        Returns:
            dict: A dictionary containing the example data.
        """
        example_title = header.get_text(strip=True).rstrip(':')
        pre_tag = header.find_next('pre')
        if not pre_tag:
            return None
        example_content = pre_tag.decode_contents()
        parsed_example = self._parse_example_content(example_content)
        if parsed_example:
            parsed_example['title'] = example_title
            return parsed_example
        return None

    def _parse_example_content(self, html_content: str) -> dict:
        """
        Parses the content of an example.

        Args:
            html_content (str): The HTML content of the example.

        Returns:
            dict: A dictionary containing input, output, and explanation.
        """
        soup = BeautifulSoup(html_content, "html.parser")
        content_text = soup.get_text(separator="\n").strip()
        example_dict = {}
        input_match = re.search(r'Input:\s*(.*)', content_text)
        output_match = re.search(r'Output:\s*(.*)', content_text)
        explanation_match = re.search(r'Explanation:\s*(.*)', content_text, re.DOTALL)
        if input_match:
            example_dict['input'] = self._parse_input(input_match.group(1))
        if output_match:
            example_dict['output'] = output_match.group(1).strip()
        if explanation_match:
            example_dict['explanation'] = explanation_match.group(1).strip()
        return example_dict

    def _parse_input(self, input_str: str) -> dict:
        """
        Parses the input string of an example.

        Args:
            input_str (str): The input string.

        Returns:
            dict: A dictionary of input parameters.
        """
        input_dict = {}
        parts = re.split(r',\s*(?![^[]*\])', input_str)
        for part in parts:
            if '=' in part:
                key, value = part.split('=', 1)
                input_dict[key.strip()] = value.strip()
            else:
                input_dict['value'] = part.strip()
        return input_dict

    def _extract_question_constraints(self) -> list:
        """
        Extracts the constraints from the question content.

        Returns:
            list: A list of constraint strings.
        """
        soup = BeautifulSoup(self.question_html_content, "html.parser")
        constraints_header = soup.find('strong', string='Constraints:')
        if not constraints_header:
            return []
        ul_tag = constraints_header.find_next('ul')
        if not ul_tag:
            return []
        constraints = [str(li) for li in ul_tag.find_all('li')]
        return constraints

    def html_to_ansi(self, html_content: str) -> str:
        """
        Converts HTML content to ANSI-formatted string.

        Args:
            html_content (str): The HTML content.

        Returns:
            str: The ANSI-formatted string.
        """
        if not html_content:
            return ""
        soup = BeautifulSoup(html_content, "html.parser")
        ansi_str = ""
        style_stack = []

        def traverse(element):
            nonlocal ansi_str
            if isinstance(element, NavigableString):
                ansi_str += element
            elif isinstance(element, Tag):
                if element.name in self.HTML_TO_SYMBOL:
                    ansi_str += self.HTML_TO_SYMBOL[element.name]
                if element.name in self.HTML_TO_ANSI:
                    ansi_code = self.HTML_TO_ANSI[element.name]
                    ansi_str += ansi_code
                    style_stack.append(ansi_code)
                if element.name in ['p', 'br', 'ul']:
                    ansi_str += '\n'
                for child in element.children:
                    traverse(child)
                if element.name in self.HTML_TO_ANSI:
                    ansi_str += ANSI_RESET
                    if style_stack:
                        style_stack.pop()

        for child in soup.children:
            traverse(child)
        return ansi_str

    def get_formatted_topic_tags(self) -> str:
        """
        Formats the topic tags.

        Returns:
            str: A formatted string of topic tags.
        """
        formatted_tags = ["Tags:"]

        for tag in self.question_topic_tags:
            tag_name = " " + tag["name"].lower() + " "
            formatted_tags.append(self.HTML_TO_ANSI["tag"] + tag_name + ANSI_RESET + " ")

        return " ".join(formatted_tags)

    def get_formatted_languages(self) -> str:
        """
        Formats the submittable languages.

        Returns:
            str: A formatted string of languages
        """
        formatted_languages = ["Langs:"]

        for language in self.question_languages:
            language_name = " " + language["name"] + " "
            formatted_language = f"{self.HTML_TO_ANSI['language']}{language_name}{ANSI_RESET}"
            formatted_languages.append(formatted_language)

        return " ".join(formatted_languages)

    def get_formatted_title(self) -> str:
        """
        Formats the question title.

        Returns:
            str: The formatted title.
        """
        title = f"[{self.question_id}] {self.question_title} {self.HTML_TO_ANSI[self.question_difficulty]} [{self.question_difficulty}] {ANSI_RESET}"
        return f"{self.HTML_TO_ANSI['title']}{title}{ANSI_RESET}"

    def get_formatted_description(self) -> str:
        """
        Formats the question description.

        Returns:
            str: The formatted description.
        """
        return self.html_to_ansi(self.question_description)

    def _format_example(self, example: dict) -> str:
        """
        Formats a single example.

        Args:
            example (dict): The example data.

        Returns:
            str: The formatted example string.
        """
        parts = []
        parts.append(f"{self.HTML_TO_ANSI['example_title']}{example['title']}{ANSI_RESET}\n\n")
        input_str = ', '.join(f"{k} = {v}" for k, v in example['input'].items())
        parts.append(f"| {self.HTML_TO_ANSI['example_input_string']}Input: {ANSI_RESET}{self.HTML_TO_ANSI['example_input_data']}{input_str}{ANSI_RESET}\n")
        parts.append(f"| {self.HTML_TO_ANSI['example_output_string']}Output: {ANSI_RESET}{self.HTML_TO_ANSI['example_output_data']}{example['output']}{ANSI_RESET}")
        if 'explanation' in example:
            explanation = example['explanation'].replace("\n", f"{ANSI_RESET}\n| {self.HTML_TO_ANSI['example_explanation_data']}")
            parts.append(f"\n| {self.HTML_TO_ANSI['example_explanation_string']}Explanation: {ANSI_RESET}{self.HTML_TO_ANSI['example_explanation_data']}{explanation}{ANSI_RESET}")
        return "".join(parts)

    def get_formatted_examples(self) -> str:
        """
        Formats all examples.

        Returns:
            str: The formatted examples.
        """
        formatted_examples = [self._format_example(example) for example in self.question_examples]
        return "\n\n".join(formatted_examples)

    def get_formatted_constraints(self) -> str:
        """
        Formats the constraints.

        Returns:
            str: The formatted constraints.
        """
        if not self.question_constraints:
            return ""
        constraints = [self.html_to_ansi(html) for html in self.question_constraints]
        constraints_str = "\n".join(constraints)
        return f"{self.HTML_TO_ANSI['constraints_string']}Constraints:{ANSI_RESET}\n\n{constraints_str}"



File path: parsers/parser_utils/leetcode_stats_parser.py:
import json
from datetime import datetime, timezone, timedelta
import logging

from ...graphics.escape_sequences import ANSI_CODES

logger = logging.getLogger(__name__)


def join_and_slice_calendars(previous_year_calendar: dict, current_year_calendar: dict) -> dict:
    """
    Joins and slices the activity calendars from the previous and current years.

    Args:
        previous_year_calendar (dict): The calendar data for the previous year.
        current_year_calendar (dict): The calendar data for the current year.

    Returns:
        dict: A dictionary with timestamps as keys and submission counts as values.
    """
    if not previous_year_calendar or not current_year_calendar:
        return {}

    try:
        # Load activity data from JSON strings
        previous_activity = json.loads(
            previous_year_calendar['data']['matchedUser']['userCalendar']['submissionCalendar']
        )
        current_activity = json.loads(
            current_year_calendar['data']['matchedUser']['userCalendar']['submissionCalendar']
        )

    except KeyError as error:
        logger.error(f"Missing key in submission_calendar data: {error}")
        return {}

    except json.JSONDecodeError as error:
        logger.error(f"JSON decoding error: {error}")
        return {}

    # Merge activities ensuring the combined dictionary has all timestamps
    merged_activity = {**previous_activity, **current_activity}

    # Convert keys to integers
    merged_activity = {int(timestamp): count for timestamp, count in merged_activity.items()}

    # Get today's date in UTC
    today_utc = datetime.utcnow().date()
    start_date = today_utc - timedelta(days=365)

    # Create start and end datetime objects
    start_datetime = datetime.combine(start_date, datetime.min.time(), tzinfo=timezone.utc)
    end_datetime = datetime.combine(today_utc, datetime.min.time(), tzinfo=timezone.utc)

    start_timestamp = int(start_datetime.timestamp())
    end_timestamp = int(end_datetime.timestamp())

    sliced_activity = {
        timestamp: count for timestamp, count in merged_activity.items()
        if start_timestamp <= timestamp < end_timestamp
    }

    return sliced_activity


def fill_daily_activity(daily_activity: dict) -> dict:
    """
    Fills the daily activity dictionary to ensure every day in the past year is represented.

    Args:
        daily_activity (dict): The original activity data.

    Returns:
        dict: A filled dictionary with timestamps for each day.
    """
    filled_activity = {}
    today_utc = datetime.utcnow().date()
    start_date = today_utc - timedelta(days=365)

    # Create start and end datetime objects
    start_datetime = datetime.combine(start_date, datetime.min.time(), tzinfo=timezone.utc)
    end_datetime = datetime.combine(today_utc, datetime.min.time(), tzinfo=timezone.utc)

    # Generate all daily timestamps within the past year
    current_datetime = start_datetime

    while current_datetime <= end_datetime:
        timestamp = int(current_datetime.timestamp())
        filled_activity[timestamp] = daily_activity.get(timestamp, 0)
        current_datetime += timedelta(days=1)

    return filled_activity


def calculate_color(submissions: int, max_submissions: int, min_submissions: int) -> str:
    """
    Calculates the color code based on the number of submissions.

    Args:
        submissions (int): The number of submissions on a particular day.
        max_submissions (int): The maximum number of submissions in the dataset.
        min_submissions (int): The minimum number of submissions in the dataset.

    Returns:
        str: The ANSI color code.
    """
    CUSTOM_GREENS = [
        ANSI_CODES["GREEN1"],
        ANSI_CODES["GREEN2"],
        ANSI_CODES["GREEN3"],
        ANSI_CODES["GREEN4"],
        ANSI_CODES["GREEN5"],
        ANSI_CODES["GREEN6"]
    ]

    if max_submissions == min_submissions:
        # Avoid division by zero; default to the brightest green
        return CUSTOM_GREENS[-1]

    # Normalize submissions to a value between 0 and 1
    normalized = (submissions - min_submissions) / (max_submissions - min_submissions)
    normalized = max(0.0, min(1.0, normalized))  # Clamp between 0 and 1

    # Determine the index in the CUSTOM_GREENS list
    index = int(normalized * (len(CUSTOM_GREENS) - 1))

    return CUSTOM_GREENS[index]

File path: parsers/parser_utils/__init__.py:

from .leetcode_stats_parser import join_and_slice_calendars, fill_daily_activity, calculate_color

__all__ = ['join_and_slice_calendars', 'fill_daily_activity', 'calculate_color']

File path: leetcode_problem/create_solution_file.py:
from ..data_fetching.graphql_data_fetchers.fetch_code_snippet import fetch_code_snippet

def create_solution_file(title_slug, lang_slug):
    file_name = f"{title_slug}.{lang_slug}"
    code_snippet = fetch_code_snippet(title_slug, lang_slug)
    
    with open(file_name, 'w') as file:
        file.write(code_snippet)


File path: leetcode_problem/submit_problem.py:
import time
import requests
from user_utils import extract_csrf_token, get_cookie
from data_fetching.graphql_data_fetchers.leetcode_problem_fetcher import LeetCodeProblemFetcher
import logging

logger = logging.getLogger(__name__)


def map_extension_to_language(file_extension: str) -> str:
    extension_mapping = {
        "py": "python3",
        "js": "javascript",
        "ts": "typescript",
        "java": "java",
        "c": "c",
        "cpp": "cpp",
        "cs": "csharp",
        "rb": "ruby",
        "php": "php",
        "swift": "swift",
        "kt": "kotlin",
        "go": "golang",
        "rs": "rust",
        "scala": "scala",
        "sql": "mysql",
        "sh": "bash",
        "dart": "dart",
    }

    normalized_extension = file_extension.lstrip(".").lower()
    return extension_mapping.get(normalized_extension)


def submit_solution(cookie: str, title_slug: str, question_id: str, solution_file_path: str) -> str:
    submit_url = f"https://leetcode.com/problems/{title_slug}/submit/"
    csrf_token = extract_csrf_token(cookie)

    if not csrf_token:
        logger.error("CSRF token is None")
        return ""

    try:
        with open(solution_file_path, 'r', encoding='utf-8') as file:
            code = file.read()

    except IOError as e:
        logger.error(f"Error reading solution file: {e}")
        return ""

    # Determine language from file extension
    try:
        file_extension = solution_file_path[solution_file_path.rindex(".") + 1:]
    except ValueError:
        logger.error("Solution file path is incorrect.")
        return ""

    language = map_extension_to_language(file_extension)
    if not language:
        logger.error("Unknown file extension.")
        return ""

    # Create submission payload
    payload = {
        "lang": language,
        "question_id": str(question_id),
        "typed_code": code,
    }

    # Set headers
    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0",
        "Cookie": cookie,
        "x-csrftoken": csrf_token,
        "Referer": f"https://leetcode.com/problems/{title_slug}/",
    }

    # Submit code
    response = requests.post(submit_url, json=payload, headers=headers)
    response.raise_for_status()
    submission = response.json()

    return submission.get('submission_id', "")


def check_submission(cookie: str, submission_id: str, title_slug: str) -> dict:
    check_submission_url = f"https://leetcode.com/submissions/detail/{submission_id}/check/"

    csrf_token = extract_csrf_token(cookie)

    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0",
        "Cookie": cookie,
        "x-csrftoken": csrf_token,
        "Referer": f"https://leetcode.com/problems/{title_slug}/",
    }

    while True:
        response = requests.get(check_submission_url, headers=headers)
        response.raise_for_status()
        submission_result = response.json()

        if submission_result.get('state') == "SUCCESS":
            return submission_result

        time.sleep(0.25)


def submit_and_get_result(cookie: str, title_slug: str, question_id: str, solution_file_path: str) -> dict:
    submission_id = submit_solution(cookie, title_slug, question_id, solution_file_path)

    if not submission_id:
        return {}

    submission_result = check_submission(cookie, submission_id, title_slug)
    return submission_result

File path: graphics/escape_sequences.py:
ANSI_RESET = "\033[0m"       # Reset all styles

ANSI_CODES = {
    # Foreground colors
    "GREEN"         : "\033[32m",                        # Standard green
    "ORANGE"        : "\033[38;5;208m",                 # 256-color mode orange
    "RED"           : "\033[31m",                       # Standard red
    "GRAY"          : "\033[90m",                       # Dim gray
    "CYAN"          : "\033[96m",                       # Bright cyan
    "WHITE"         : "\033[38;2;255;255;255m",         # RGB white
    "BLACK"         : "\033[38;2;0;0;0m",               # RGB black

    # Custom shades of green for stats
    "GREEN1"        : "\033[38;2;1;155;1m",             # Darkest green
    "GREEN2"        : "\033[38;2;16;175;16m",
    "GREEN3"        : "\033[38;2;33;195;33m",
    "GREEN4"        : "\033[38;2;61;215;61m",
    "GREEN5"        : "\033[38;2;82;235;82m",
    "GREEN6"        : "\033[38;2;100;255;100m",         # Lightest green

    # Background colors
    "GRAY_BG"       : "\033[100m",                      # Dim gray background
    "GREEN_BG"      : "\033[42m",                       # Standard green background
    "BABY_BLUE_BG"  : "\033[48;2;66;205;245m",         # RGB baby blue background
    "RED_BG"        : "\033[41m",                       # Standard red background
    "ORANGE_BG"     : "\033[48;2;245;158;66m",

    # Text styles
    "BOLD"          : "\033[1m",                        # Bold text
    "ITALIC"        : "\033[3m",                        # Italic text (not supported in all terminals)
    "UNDERLINE"     : "\033[4m",                        # Underlined text
}

File path: graphics/symbols.py:
# TODO: implement additional dictionary for symbols and ansi_sequences so that each elemtn's symbol/esc_seq maps to x['stats_color'] -> colors['red']
SYMBOLS = {
    "FILLED_SQUARE" : "◼",
    "EMPTY_SQUARE"  : "▫",
    
    "CARET" : "^",
    "DOT"   : "•",

    "CHECKMARK" : "✔",
    "X" : "✘",
    "ATTEMPTED" : "❋"
}

File path: data_fetching/leetcode_stats.py:
from ..data_fetching.graphql_queries import GRAPHQL_QUERIES, GRAPHQL_URL

import requests

def fetch_leetcode_stats(username):
    if not username:
        print("Error: Username was not provided")
        return None

    payload = {
        "query": GRAPHQL_QUERIES['problem_stats'],

        "variables": {
            "userSlug": username
        },

        "operationName": "userProfileUserQuestionProgressV2"
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        if response.status_code == 200:
            result = response.json()

            if "errors" in result:
                print(f"Error from API: {result['errors']}")
                return None

            return result

        elif response.status_code == 401:
            print("Error: Unauthorized. Cookie might be invalid or expired.")

        else:
            print(f"Error: Failed to fetch stats. HTTP Status Code: {response.status_code}")
    except requests.RequestException as e:

        print(f"Error: Network or API issue occurred: {e}")

    return None


def fetch_leetcode_activity(username, year):
    if not username:
        print("Error: Username was not provided")
        return None


    if year is None:
        print("Error: year is None")
        return None

    payload = {
        "query": GRAPHQL_QUERIES['user_calendar'],
        "variables": {
            "username": username,
            "year": year
        },
        "operationName": "userProfileCalendar"
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)

        if response.status_code == 200:
            result = response.json()

            if "errors" in result:
                print(f"Error from API: {result['errors']}")
                return None

            return result

        elif response.status_code == 401:
            print("Error: Unauthorized. Cookie might be invalid or expired.")

        else:
            print(f"Error: Failed to fetch activity data. HTTP Status Code: {response.status_code}")

    except requests.RequestException as e:
        print(f"Error: Network or API issue occurred: {e}")

    return None


File path: data_fetching/fetch_code_snippet.py:
import requests
import json

from ..data_fetching.graphql_queries import GRAPHQL_URL, GRAPHQL_QUERIES

# TODO: Implement code snippet builder for each language, so it doesn't waste time doing request

def fetch_code_snippet(title_slug, lang_slug):
    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0"
    }

    variables = {
        "titleSlug": title_slug
    }

    payload = {
        "query": GRAPHQL_QUERIES["code_snippets"],
        "variables": variables
    }

    try:
        response = requests.post(GRAPHQL_URL, headers=headers, data=json.dumps(payload))

    except requests.RequestException as e:
        raise ConnectionError(f"An error occurred while making the request: {e}")

    if response.status_code != 200:
        raise ConnectionError(f"Failed to fetch data from API. Status code: {response.status_code}")

    try:
        data = response.json()
    except json.JSONDecodeError:
        raise ValueError("Response content is not valid JSON.")

    try:
        code_snippets = data['data']['question']['codeSnippets']
    except KeyError:
        raise ValueError("Unexpected JSON structure received from API.")

    # Search for the code snippet in the desired language
    for snippet in code_snippets:
        if snippet['langSlug'].lower() == lang_slug.lower():
            return snippet['code']

    # If code snippet is not found
    raise ValueError(f"No code snippet found for language slug: '{lang_slug}'")

File path: data_fetching/graphql_queries.py:
GRAPHQL_URL = "https://leetcode.com/graphql"

GRAPHQL_QUERIES = {
    'problem_stats': """
        query userProfileUserQuestionProgressV2($userSlug: String!) {
          userProfileUserQuestionProgressV2(userSlug: $userSlug) {
            numAcceptedQuestions {
              count
              difficulty
            }
            numFailedQuestions {
              count
              difficulty
            }
            numUntouchedQuestions {
              count
              difficulty
            }
            userSessionBeatsPercentage {
              difficulty
              percentage
            }
            totalQuestionBeatsPercentage
          }
        }
    """,

    'user_calendar': """
        query userProfileCalendar($username: String!, $year: Int) {
          matchedUser(username: $username) {
            userCalendar(year: $year) {
              activeYears
              streak
              totalActiveDays
              dccBadges {
                timestamp
                badge {
                  name
                  icon
                }
              }
              submissionCalendar
            }
          }
        }
    """,

    'problemset_data': """
        query problemsetQuestionList($categorySlug: String, $limit: Int, $skip: Int, $filters: QuestionListFilterInput) {
          problemsetQuestionList: questionList(
            categorySlug: $categorySlug
            limit: $limit
            skip: $skip
            filters: $filters
          ) {
            total: totalNum
            questions: data {
              acRate
              difficulty
              freqBar
              frontendQuestionId: questionFrontendId
              isFavor
              paidOnly: isPaidOnly
              status
              title
              titleSlug
              topicTags {
                name
                id
                slug
              }
              hasSolution
              hasVideoSolution
            }
          }
        }
    """,

    'code_snippets': """
        query getQuestionDetail($titleSlug: String!) {
            question(titleSlug: $titleSlug) {
                codeSnippets {
                    lang
                    langSlug
                    code
                }
            }
        }
        """,

    'problem_data': """
        query questionData($titleSlug: String!) {
          submittableLanguageList {
            id
            name
            verboseName
          }
          question(titleSlug: $titleSlug) {
            questionId
            title
            titleSlug
            content
            difficulty
            likes
            dislikes
            exampleTestcases
            topicTags {
              name
              slug
            }
            hints
            isPaidOnly
          }
        }
        """

}

File path: data_fetching/leetcode_problem_fetcher.py:
from ..data_fetching.graphql_queries import GRAPHQL_QUERIES, GRAPHQL_URL 

from ..user_utils import get_cookie, extract_csrf_token

import requests

class LeetCodeProblemFetcher:

    @staticmethod
    def fetch_problemset(tags=None, difficulty=None, limit=50, skip=0, category_slug="all-code-essentials"):
        if not category_slug:
            print("Error: category_slug is required but not provided.")
            return None

        if tags is not None and not isinstance(tags, list):
            print("Error: tags must be a list of strings.")
            return None

        if difficulty is not None and not (isinstance(difficulty, str) or (isinstance(difficulty, list) and all(isinstance(d, str) for d in difficulty))):
            print("Error: difficulty must be a string or a list of strings.")
            return None

        # Validate difficulty values
        valid_difficulties = {"EASY", "MEDIUM", "HARD"}
        difficulties = []
        if isinstance(difficulty, str):
            difficulties = [difficulty.upper()]

        elif isinstance(difficulty, list):
            difficulties = [d.upper() for d in difficulty]

        for d in difficulties:
            if d not in valid_difficulties:
                print(f"Error: Invalid difficulty level '{d}'. Valid options are EASY, MEDIUM, HARD.")
                return None

        query = GRAPHQL_QUERIES['problemset_data']

        payload = {
            "query": query,
            "variables": {
                "categorySlug": category_slug,
                "skip": skip,
                "limit": limit,
                "filters": {}
            },
            "operationName": "problemsetQuestionList"
        }

        # Add tags to filters if provided
        if tags:
            payload["variables"]["filters"]["tags"] = tags
            print("Tags filter applied:", tags)

        # Add difficulty to filters if provided
        if difficulties:
            if len(difficulties) == 1:
                payload["variables"]["filters"]["difficulty"] = difficulties[0]
            else:
                payload["variables"]["filters"]["difficulty"] = difficulties
            print("Difficulty filter applied:", difficulties)

        cookie = get_cookie()
        headers = None

        # TODO: Check if cookie is valid: cookie might be set but inactive
        try:
            if cookie:
                headers = {
                    "Content-Type": "application/json",
                    "User-Agent": "Mozilla/5.0",
                    "Cookie": cookie,
                    "x-csrftoken": extract_csrf_token(cookie),
                    "Referer": f"https://leetcode.com/problemset/",
                }

                response = requests.post(GRAPHQL_URL, json=payload, headers=headers)

            else:
                response = requests.post(GRAPHQL_URL, json=payload)
            
            if response.status_code == 200:
                result = response.json()

                if "errors" in result:
                    print(f"Error from API: {result['errors']}")
                    return None


                return result

            elif response.status_code == 401:
                print("Error: Unauthorized. Cookie might be invalid or expired.")

            else:
                print(f"Error: Failed to fetch problems. HTTP Status Code: {response.status_code}")

        except requests.RequestException as e:
            print(f"Error: Network or API issue occurred: {e}")

        return None

    @staticmethod
    def fetch_problem_data(title_slug):
        if not title_slug:
            print("Error: title_slug is required but not provided.")
            return None


        query = GRAPHQL_QUERIES['problem_data']

        payload = {
            "query": query,
            "variables": {
                "titleSlug": title_slug
            },
            "operationName": "questionData"
        }

        try:
            response = requests.post(GRAPHQL_URL, json=payload)
            
            if response.status_code == 200:
                result = response.json()

                if "errors" in result:
                    print(f"Error from API: {result['errors']}")
                    return None

                return result

            elif response.status_code == 401:
                print("Error: Unauthorized. Cookie might be invalid or expired.")

            else:
                print(f"Error: Failed to fetch question details. HTTP Status Code: {response.status_code}")

        except requests.RequestException as e:
            print(f"Error: Network or API issue occurred: {e}")

        return None
