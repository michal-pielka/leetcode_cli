
File path: user_utils.py:
import json
import re
import os
import platform

def get_config_path():
    if platform.system() == "Windows":
        config_dir = os.getenv("APPDATA", os.path.expanduser("~\\AppData\\Roaming"))
        config_path = os.path.join(config_dir, "leetcode", "config.json")

    else:  # macOS and Linux
        config_dir = os.path.expanduser("~/.config/leetcode")
        config_path = os.path.join(config_dir, "config.json")

    return config_path


def set_cookie(cookie):
    config_path = get_config_path()
    config_dir = os.path.dirname(config_path)

    # Create the config directory if it doesn't exist
    os.makedirs(config_dir, exist_ok=True)

    # Load existing config if it exists, else start with an empty dict
    config = {}
    if os.path.exists(config_path):
        with open(config_path, "r") as f:
            try:
                config = json.load(f)
            except json.JSONDecodeError:
                print("Warning: Config file is corrupted. Overwriting it.")

    # Update the cookie value
    config["cookie"] = cookie

    # Save the updated config back to the file
    with open(config_path, "w") as f:
        json.dump(config, f, indent=4)

    print(f"Cookie saved to {config_path}")


def extract_csrf_token(cookie):
    match = re.search(r'csrftoken=([^;]+)', cookie)

    if match:
        return match.group(1)
    else:
        return None


def set_username(username):
    config_path = get_config_path()
    config_dir = os.path.dirname(config_path)

    # Create the config directory if it doesn't exist
    os.makedirs(config_dir, exist_ok=True)

    # Load existing config if it exists, else start with an empty dict
    config = {}
    if os.path.exists(config_path):
        with open(config_path, "r") as f:
            try:
                config = json.load(f)
            except json.JSONDecodeError:
                print("Warning: Config file is corrupted. Overwriting it.")

    # Update the user_slug value
    config["username"] = username

    # Save the updated config back to the file
    with open(config_path, "w") as f:
        json.dump(config, f, indent=4)

    print(f"Username saved to {config_path}")


def load_cookie():
    config_path = get_config_path()

    if os.path.exists(config_path):
        try:
            with open(config_path, "r") as f:
                config = json.load(f)
                return config.get("cookie")
        except (json.JSONDecodeError, KeyError):
            print("Error: Invalid config file format.")
            return None
    else:
        print("Error: Config file not found. Use 'save_cookie' to create one.")
        return None


# Example usage
if __name__ == "__main__":
    username = "BucketAbuser"
    cookie = '__stripe_mid=50af2006-33dc-414e-b857-14bc3e74ac84742cff; cf_clearance=kK.2EfoZktQ.kN9BwHEULRvqhpGRXgKzIkFlSsL_._8-1731354607-1.2.1.1-THHVDQhzyCa0xdOZr4Aj0VvK_NWcDlJqe7Y1JXr53eYiLfPwzy04n1zJVcin0cyYRUYGDxa_ul0UpEOfyGe3ndoJ3LDmj2z2Pp23.EeJhSRjpbq.W2tUNo8epGlY9adZT_y_s6qtqIykedkjVnd0FD6kJlEpxfdl7OaXeagxQw2K0a2DR5N1EKKTsA6F5Ql1TdEAT09JdUnz3supzh0xJ1VNSKrF.n5uHH_vdQFNV5cAZFf_.BDhEmIhJ7ZLzQDc7EMBFWrstNokCAv0dGix9SrTnsKdyquXYnG.MHq2.kynS0Ti3p8rQFDUydGW8akf0DTYh_xtW3_gBTLP1kod3lJ3gF7n6bDZb4Ep3DxSKuFzPct7LJh6jDVlcG.rct9ThQfhVpB8kiZ1qh5R6NyYWSVf7foqvPolqdCPvJWpAVaBW05IkbxfhjkZ1qEYVcNL; csrftoken=tKsgNsn78jkr8zPZEBlwQhfjLdCqjzdpUIOfvE4utfWkFIuBJNstG5fpoG9NakSY; messages=.eJyLjlaKj88qzs-Lz00tLk5MT1XSMdAxMtVRCi5NTgaKpJXm5FQqFGem56WmKGTmKSQWKziVJmenljgmlRanFukpxepQbEIsABb7LkM:1tAaQK:tKp42SuG0Dl-oSPWsZ0BojMl2iTyREsyPB7hQ5STU1E; LEETCODE_SESSION=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJfYXV0aF91c2VyX2lkIjoiNzIxNzc4NCIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImFsbGF1dGguYWNjb3VudC5hdXRoX2JhY2tlbmRzLkF1dGhlbnRpY2F0aW9uQmFja2VuZCIsIl9hdXRoX3VzZXJfaGFzaCI6IjM1NDEwZGJkZTBhZmE2MjhhM2NhYjZkZmI1ZDViNjcyMmRmOTg5OTRmMGRkZjc5MmJhOTQ0Y2JmOGI2M2RmZGEiLCJpZCI6NzIxNzc4NCwiZW1haWwiOiJtcGllbGthNzI2QGdtYWlsLmNvbSIsInVzZXJuYW1lIjoiQnVja2V0QWJ1c2VyIiwidXNlcl9zbHVnIjoiQnVja2V0QWJ1c2VyIiwiYXZhdGFyIjoiaHR0cHM6Ly9hc3NldHMubGVldGNvZGUuY29tL3VzZXJzL2RlZmF1bHRfYXZhdGFyLmpwZyIsInJlZnJlc2hlZF9hdCI6MTczMjYxNjY0NCwiaXAiOiIxMDkuMjQzLjEuOTMiLCJpZGVudGl0eSI6ImE0NTVlYmM2N2QwYjUwMDdlMmEwNTU0MTRkZDE0ZDc4IiwiZGV2aWNlX3dpdGhfaXAiOlsiZDk5MzBhOGIxMTZhNzdkZGQzN2MyOGI2ZGI3MGIxNmQiLCIxMDkuMjQzLjEuOTMiXSwic2Vzc2lvbl9pZCI6MTgwNjEzLCJfc2Vzc2lvbl9leHBpcnkiOjEyMDk2MDB9.FHPzMW1NFOnELXXcHzB3WIUGJOSs7Woh36JuYlqsvR0; ip_check=(false, "109.243.1.93"); INGRESSCOOKIE=6542b644a233f3d8a33703e8cfe82090|8e0876c7c1464cc0ac96bc2edceabd27; __cf_bm=a45.X5vniCgYusorKY77Z18pSrW5BX0iZ2jOZi15bso-1732626577-1.0.1.1-5ulEYk_3r.mq7KsUDVCejAs7MqaVvdBYNSrv6tqReVInEcFT45iLSVadbq_dA9Us_w9w_B6dsi88.yPjqYo9Zw'

    set_cookie(cookie)
    set_username(username)

File path: komendy.txt:

Komendy:
  leetcode list                     - lists questions (PAID/UNPAID)
    ARGUMENTS:
      --tag=algorithms
      --tags=algorithms,arrays

  leetcode stat                     - prints user stats

  leetcode pick INT/TITLE-SLUG      - picks a problem

  leetcode show INT/TITLE-SLUG      - shows problem data

  leetcode choose DIFFICULTY
    

File path: o.txt:

File path: parsers/leetcode_stats_parser.py:
# TODO: Tf is this code nigga

from datetime import datetime, timedelta, timezone
import sys
import calendar

# Import fetch functions (ensure these paths are correct in your project structure)
from ..data_fetching.graphql_data_fetchers.leetcode_stats import (
    fetch_leetcode_stats,
    fetch_leetcode_activity,
)

from ..graphics.symbols import SYMBOLS
from ..graphics.escape_sequences import ANSI_CODES, ANSI_RESET

from ..parsers.parser_utils.leetcode_stats_parser import (
    join_and_slice_calendars,
    fill_daily_activity,
    calculate_color,
)

# Constants
RECTANGLES_TOTAL = 66
DIFFICULTIES = ["EASY", "MEDIUM", "HARD"]

MONTH_NAMES = ["Jan", "Feb", "Mar", "Apr", "May", "Jun",
               "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
MONTH_SEPARATION = 3
COLUMNS = 100

def parse_leetcode_stats(data, username):
    """
    Parses LeetCode statistics and returns a formatted string.
    """
    try:
        user_progress = data["data"]["userProfileUserQuestionProgressV2"]

        # Extract counts by difficulty
        accepted = {item["difficulty"]: item["count"] for item in user_progress.get("numAcceptedQuestions", [])}
        failed = {item["difficulty"]: item["count"] for item in user_progress.get("numFailedQuestions", [])}
        untouched = {item["difficulty"]: item["count"] for item in user_progress.get("numUntouchedQuestions", [])}
        beats_percentage = {item["difficulty"]: item["percentage"] for item in user_progress.get("userSessionBeatsPercentage", [])}

        # Define colors for difficulties
        difficulty_colors = {
            "EASY": ANSI_CODES["GREEN"],
            "MEDIUM": ANSI_CODES["ORANGE"],
            "HARD": ANSI_CODES["RED"]
        }

        # Calculate total questions per difficulty
        total_questions = {}
        for difficulty in DIFFICULTIES:
            total = accepted.get(difficulty, 0) + failed.get(difficulty, 0) + untouched.get(difficulty, 0)
            total_questions[difficulty] = total

        stats_lines = []
        for difficulty in DIFFICULTIES:
            passed = accepted.get(difficulty, 0)
            total = total_questions[difficulty]
            percentage = beats_percentage.get(difficulty, 0.0)

            # Calculate filled rectangles
            if total > 0:
                filled = round((passed / total) * RECTANGLES_TOTAL)
            else:
                filled = 0
            filled = max(0, min(filled, RECTANGLES_TOTAL))  # Clamp between 0 and RECTANGLES_TOTAL
            progress_bar = SYMBOLS["FILLED_SQUARE"] * filled + SYMBOLS["EMPTY_SQUARE"] * (RECTANGLES_TOTAL - filled)

            # Formatting
            color = difficulty_colors.get(difficulty, ANSI_RESET)
            stats_line = (
                f"{color}{difficulty:<6} {passed:>4}/{total:<4} ({percentage:.2f}%) {progress_bar} {ANSI_RESET}"
            )
            stats_lines.append(stats_line)

        # Combine all outputs
        formatted_stats = f"LeetCode Stats for {username}\n" + "\n".join(stats_lines)
        return formatted_stats

    except (KeyError, TypeError, ZeroDivisionError) as error:
        print(f"Error parsing LeetCode stats: {error}", file=sys.stderr)
        return ""

def parse_daily_activity(filled_activity):
    """
    Parses daily activity and returns a formatted calendar string.
    """
    if not filled_activity:
        print("No daily activity data available", file=sys.stderr)
        return ""

    # Initialize output: 7 rows for days of the week, COLUMNS weeks
    output = [[' ' for _ in range(COLUMNS)] for _ in range(7)]

    # Convert timestamps to dates and map counts
    date_counts = {}
    for ts, count in filled_activity.items():
        try:
            date = datetime.fromtimestamp(int(ts), tz=timezone.utc).date()
            date_counts[date] = count
        except (ValueError, OverflowError):
            continue  # Skip invalid timestamps

    if not date_counts:
        print("No valid daily activity data available", file=sys.stderr)
        return ""

    months_starting_indexes = []

    # Determine the date range
    min_date = min(date_counts.keys())
    max_date = max(date_counts.keys())
    min_submissions = min(date_counts.values())
    max_submissions = max(date_counts.values())

    # Generate all dates from start_date to end_date
    total_days = (max_date - min_date).days + 1
    all_dates = [min_date + timedelta(days=i) for i in range(total_days)]

    # Initialize tracking variables
    weekday = all_dates[0].weekday()  # Monday=0, Sunday=6
    week_index = 3  # Starting week index
    for date in all_dates:
        submissions = date_counts.get(date, 0)

        if submissions > 0:
            color = calculate_color(submissions, max_submissions, min_submissions)
            output[weekday][week_index] = f"{color}{SYMBOLS['FILLED_SQUARE']}{ANSI_RESET}"
        else:
            output[weekday][week_index] = f"{ANSI_CODES['GRAY']}{SYMBOLS['FILLED_SQUARE']}{ANSI_RESET}"

        # Check if it's the last day of the month
        last_day = calendar.monthrange(date.year, date.month)[1]
        if date.day == last_day and week_index < COLUMNS - 1:
            months_starting_indexes.append(week_index)
            week_index += MONTH_SEPARATION

        # Move to next day
        if weekday == 6:
            weekday = 0
            week_index += 1
        else:
            weekday += 1

    # Generate month labels
    MONTHS = [MONTH_NAMES[(min_date.month - 1 + i) % len(MONTH_NAMES)] for i in range(len(MONTH_NAMES))]
    months_parsed_list = [' ' for _ in range(COLUMNS)]

    for idx, start_index in enumerate(months_starting_indexes):
        month = MONTHS[(min_date.month + idx + 1) % 12]
        for i, char in enumerate(month):
            target_index = start_index - 3 + i
            if 0 <= target_index < COLUMNS:
                months_parsed_list[target_index] = char

    months_parsed = ''.join(months_parsed_list)

    # Generate calendar lines
    calendar_parsed = '\n'.join(''.join(row) for row in output)

    return f"{months_parsed}\n{calendar_parsed}"

def main():
    """
    Main function to fetch and display LeetCode stats and activity.
    """
    username = "BucketAbuser"

    # Fetch and parse stats
    stats = fetch_leetcode_stats(username)
    if stats:
        parsed_stats = parse_leetcode_stats(stats, username)
        print()
        print(parsed_stats)
    else:
        print("Failed to fetch LeetCode stats.", file=sys.stderr)

    # Fetch and parse activity
    current_year = datetime.now().year
    activity_past_year = fetch_leetcode_activity(username, current_year - 1)
    activity_this_year = fetch_leetcode_activity(username, current_year)
    sliced_activity = join_and_slice_calendars(activity_this_year, activity_past_year)
    filled_activity = fill_daily_activity(sliced_activity)

    if filled_activity:
        print()
        print()
        parsed_activity = parse_daily_activity(filled_activity)
        print(parsed_activity)
    else:
        print("Failed to fetch daily activity.", file=sys.stderr)

    print()
    print()


if __name__ == "__main__":
    main()

File path: parsers/leetcode_problemset_parser.py:

from ..data_fetching.graphql_data_fetchers.leetcode_problem_fetcher import LeetCodeProblemFetcher
from ..graphics.escape_sequences import ANSI_CODES, ANSI_RESET
from ..graphics.symbols import SYMBOLS

class LeetCodeProblemsetParser:
    DIFFICULTY_TO_ANSI = {
        "Easy" : ANSI_CODES["GREEN"],
        "Medium" : ANSI_CODES["ORANGE"],
        "Hard" : ANSI_CODES["RED"]
    }

    QUESTION_STATUS_TO_COLORED_SYMBOL = {
        "ac" : ANSI_CODES["GREEN"] + SYMBOLS["CHECKMARK"] + ANSI_RESET,
        "notac" : ANSI_CODES["ORANGE"] + SYMBOLS["ATTEMPTED"] + ANSI_RESET,
        #None: ANSI_CODES["RED"] + SYMBOLS["X"] + ANSI_RESET
        None: " "
    }

    def __init__(self, problemset_metadata):
        self.problemset_metadata = problemset_metadata

        #{'acRate': 35.78945760464872, 'difficulty': 'Medium', 'freqBar': None, 'frontendQuestionId': '3', 'isFavor': False, 'paidOnly': False, 'status': None, 'title': 'Longest Substring Without Repeating Characters', 'titleSlug': 'longest-substring-without-repeating-characters', 'topicTags': [{'name': 'Hash Table', 'id': 'VG9waWNUYWdOb2RlOjY=', 'slug': 'hash-table'}, {'name': 'String', 'id': 'VG9waWNUYWdOb2RlOjEw', 'slug': 'string'}, {'name': 'Sliding Window', 'id': 'VG9waWNUYWdOb2RlOjU1ODIx', 'slug': 'sliding-window'}], 'hasSolution': True, 'hasVideoSolution': True}        
        self.problemset_data = self.problemset_metadata.get("data", None)

        self.problemset_question_list = self.problemset_data.get("problemsetQuestionList", None)
        self.total_problems = self.problemset_question_list.get("total", None)
        self.questions = self.problemset_question_list.get("questions", None)

    def _parse_question(self, question_data):
        title = question_data.get("title", "").ljust(79)  # Adjust width for title alignment
        question_id = str(question_data.get("frontendQuestionId", "")).rjust(4)  # Align ID for up to 4 digits
        acceptance_rate = f"{float(question_data.get('acRate', 0)):.2f}"  # Format acceptance rate with two decimals
        difficulty = question_data.get("difficulty", "")
        status = question_data.get("status", None)
        # Colorize and align difficulty
        formatted_difficulty = f"{self.DIFFICULTY_TO_ANSI[difficulty]}{difficulty.ljust(8)}{ANSI_RESET}"

        # Combine all parts into a formatted string
        
        parsed_question = f"\t{self.QUESTION_STATUS_TO_COLORED_SYMBOL[status]}[{question_id}] {title} {formatted_difficulty} ({acceptance_rate} %)"
        return parsed_question
        
        



tags = []
limit = 50
skip = 0
category_slug = "all-code-essentials"
problems_dict = LeetCodeProblemFetcher.fetch_problemset(tags = tags, limit = limit, skip = skip, category_slug=category_slug)

l = LeetCodeProblemsetParser(problems_dict)
questions = l.questions

for i in range(len(questions)):
    x = l._parse_question(questions[i])
    print(x)


File path: parsers/submission_parser.py:
# TODO: Make the parsed message 'friendlier'
from ..graphics.colors import COLORS

def parse_submission(submission):
    status_code = submission.get("status_code")

    # Map status codes to their corresponding parser functions
    parsers = {
        10: parse_accepted,
        11: parse_wrong_answer,
        12: parse_memory_limit_exceeded,
        13: parse_output_limit_exceeded,
        14: parse_time_limit_exceeded,
        15: parse_runtime_error,
        20: parse_compile_error,
    }

    parse_function = parsers.get(status_code)
    if parse_function:
        return parse_function(submission)
    else:
        print("Unknown submission status code.")
        return None

def parse_accepted(submission):
    time_ms = submission.get("status_runtime", "N/A")
    memory_size = submission.get("status_memory", "N/A")

    parsed_result = (
        f"{COLORS["GREEN"]}Accepted{COLORS["RESET_COLOR"]}\n"
        f"Runtime: {time_ms}\n"
        f"Memory Usage: {memory_size}"
    )

    return parsed_result

def parse_wrong_answer(submission):
    last_testcase = submission.get("last_testcase", "")
    expected_output = submission.get("expected_output", "")
    code_output = submission.get("code_output", "")
    parsed_result = (
        f"{COLORS["RED"]}Wrong Answer{COLORS["RESET_COLOR"]}"
        f"Testcase: {last_testcase}\n"
        f"Expected Output: {expected_output}\n"
        f"Your Output: {code_output}"
    )

    return parsed_result

def parse_memory_limit_exceeded(submission):
    return f"{COLORS["RED"]}Memory Limit Exceeded{COLORS["RESET_COLOR"]}"

def parse_output_limit_exceeded(submission):
    return f"{COLORS["RED"]}Output Limit Exceeded{COLORS["RESET_COLOR"]}"

def parse_time_limit_exceeded(submission):
    return f"{COLORS["RED"]}Time Limit Exceeded{COLORS["RESET_COLOR"]}"

def parse_runtime_error(submission):
    error_msg = submission.get("runtime_error", "No error message.")
    return f"{COLORS["RED"]}Runtime Error{COLORS["RESET_COLOR"]}\n{error_msg}"

def parse_compile_error(submission):
    error_msg = submission.get("compile_error", "No error message.")
    return f"{COLORS["RED"]}Compile Error{COLORS["RESET_COLOR"]}\n{error_msg}"

File path: parsers/leetcode_problem_parser.py:
from bs4 import BeautifulSoup, NavigableString, Tag
import re

from ..graphics.escape_sequences import ANSI_CODES, ANSI_RESET
from ..graphics.symbols import SYMBOLS

class LeetCodeProblemParser:
    HTML_TO_ANSI = {
        "strong": ANSI_CODES["BOLD"],
        "b": ANSI_CODES["BOLD"],
        "em": ANSI_CODES["ITALIC"],
        "i": ANSI_CODES["ITALIC"],
        "u": ANSI_CODES["UNDERLINE"],
        "code": ANSI_CODES["GRAY_BG"],
        "pre": ANSI_CODES["RED"],
        "title": ANSI_CODES["BOLD"],
        "example_title": ANSI_CODES["BOLD"],
        "example_input_string": ANSI_CODES["BOLD"],
        "example_output_string": ANSI_CODES["BOLD"],
        "example_explanation_string": ANSI_CODES["BOLD"],
        "example_input_data": ANSI_CODES["GRAY"],
        "example_output_data": ANSI_CODES["GRAY"],
        "example_explanation_data": ANSI_CODES["GRAY"],
        "constraints_string": ANSI_CODES["BOLD"],
        "Easy" : ANSI_CODES["GREEN_BG"],
        "Medium" : ANSI_CODES["ORANGE_BG"],
        "Hard" : ANSI_CODES["RED_BG"],
    }

    HTML_TO_SYMBOL = {
        "sup": SYMBOLS["CARET"],
        "li": SYMBOLS["DOT"] + " ",
    }

    def __init__(self, metadata):
        if not metadata or not isinstance(metadata, dict):
            raise ValueError("Metadata must be a non-empty dictionary.")

        self.metadata = metadata
        self.question_data = self._extract_question_data()
        self.question_html_content = self.question_data.get("content", "")
        self.is_paid_only = self.question_data.get("isPaidOnly", False)

        # Extracted attributes
        self.question_id = self.question_data.get("questionId", "")
        self.question_title = self.question_data.get("title", "")
        self.question_description = self._extract_question_description()
        self.question_examples = self._extract_question_examples()
        self.question_constraints = self._extract_question_constraints()
        self.question_hints = self.question_data.get("hints", [])
        self.question_topic_tags = self.question_data.get("topicTags", [])
        self.question_difficulty = self.question_data.get("difficulty", "")
        self.question_likes = self.question_data.get("likes", 0)
        self.question_dislikes = self.question_data.get("dislikes", 0)
        self.question_example_testcases = self.question_data.get("exampleTestcases", "")

    def _extract_question_data(self):
        try:
            return self.metadata["data"]["question"]
        except KeyError as e:
            raise KeyError(f"Missing key in metadata: {e}")

    def _extract_question_description(self):
        soup = BeautifulSoup(self.question_html_content, "html.parser")
        description_elements = []
        for element in soup.find_all(['p', 'ul']):
            if element.find('strong', string=re.compile(r'Example')):
                break
            description_elements.append(str(element))
        description_html = "\n".join(description_elements).strip()
        return description_html

    def _extract_question_examples(self):
        soup = BeautifulSoup(self.question_html_content, "html.parser")
        examples = []
        example_headers = soup.find_all('strong', string=re.compile(r'Example \d+'))
        for header in example_headers:
            example = self._parse_example_section(header)
            if example:
                examples.append(example)
        return examples

    def _parse_example_section(self, header):
        example_title = header.get_text(strip=True).rstrip(':')
        pre_tag = header.find_next('pre')
        if not pre_tag:
            return None
        example_content = pre_tag.decode_contents()
        parsed_example = self._parse_example_content(example_content)
        if parsed_example:
            parsed_example['title'] = example_title
            return parsed_example
        return None

    def _parse_example_content(self, html_content):
        soup = BeautifulSoup(html_content, "html.parser")
        content_text = soup.get_text(separator="\n").strip()
        example_dict = {}
        input_match = re.search(r'Input:\s*(.*)', content_text)
        output_match = re.search(r'Output:\s*(.*)', content_text)
        explanation_match = re.search(r'Explanation:\s*(.*)', content_text, re.DOTALL)
        if input_match:
            example_dict['input'] = self._parse_input(input_match.group(1))
        if output_match:
            example_dict['output'] = output_match.group(1).strip()
        if explanation_match:
            example_dict['explanation'] = explanation_match.group(1).strip()
        return example_dict

    def _parse_input(self, input_str):
        input_dict = {}
        # Split inputs by commas, accounting for brackets
        parts = re.split(r',\s*(?![^[]*\])', input_str)
        for part in parts:
            if '=' in part:
                key, value = part.split('=', 1)
                input_dict[key.strip()] = value.strip()
            else:
                input_dict['value'] = part.strip()
        return input_dict

    def _extract_question_constraints(self):
        soup = BeautifulSoup(self.question_html_content, "html.parser")
        constraints_header = soup.find('strong', string='Constraints:')
        if not constraints_header:
            return []
        ul_tag = constraints_header.find_next('ul')
        if not ul_tag:
            return []
        constraints = [str(li) for li in ul_tag.find_all('li')]
        return constraints

    def html_to_ansi(self, html_content):
        if not html_content:
            return ""
        soup = BeautifulSoup(html_content, "html.parser")
        ansi_str = ""
        style_stack = []

        def traverse(element):
            nonlocal ansi_str
            if isinstance(element, NavigableString):
                ansi_str += element
            elif isinstance(element, Tag):
                if element.name in self.HTML_TO_SYMBOL:
                    ansi_str += self.HTML_TO_SYMBOL[element.name]
                if element.name in self.HTML_TO_ANSI:
                    ansi_code = self.HTML_TO_ANSI[element.name]
                    ansi_str += ansi_code
                    style_stack.append(ansi_code)
                if element.name in ['p', 'br', 'ul']:
                    ansi_str += '\n'
                for child in element.children:
                    traverse(child)
                if element.name in self.HTML_TO_ANSI:
                    ansi_str += ANSI_RESET
                    if style_stack:
                        style_stack.pop()

        for child in soup.children:
            traverse(child)
        return ansi_str

    def get_formatted_title(self):
        title = f"{self.HTML_TO_ANSI['title'] + self.question_id}. {self.question_title + ANSI_RESET} {self.HTML_TO_ANSI[self.question_difficulty]}[{self.question_difficulty}]{ANSI_RESET}"

        return f"{self.HTML_TO_ANSI['title']}{title}{ANSI_RESET}"

    def get_formatted_description(self):
        return self.html_to_ansi(self.question_description)

    def _format_example(self, example):
        parts = []
        parts.append(f"{self.HTML_TO_ANSI['example_title']}{example['title']}{ANSI_RESET}\n\n")
        input_str = ', '.join(f"{k} = {v}" for k, v in example['input'].items())
        parts.append(f"| {self.HTML_TO_ANSI['example_input_string']}Input: {ANSI_RESET}{self.HTML_TO_ANSI['example_input_data']}{input_str}{ANSI_RESET}\n")
        parts.append(f"| {self.HTML_TO_ANSI['example_output_string']}Output: {ANSI_RESET}{self.HTML_TO_ANSI['example_output_data']}{example['output']}{ANSI_RESET}")
        if 'explanation' in example:
            explanation = example['explanation'].replace("\n", f"{ANSI_RESET}\n| {self.HTML_TO_ANSI['example_explanation_data']}")
            parts.append(f"\n| {self.HTML_TO_ANSI['example_explanation_string']}Explanation: {ANSI_RESET}{self.HTML_TO_ANSI['example_explanation_data']}{explanation}{ANSI_RESET}")
        return "".join(parts)

    def get_formatted_examples(self):
        formatted_examples = [self._format_example(example) for example in self.question_examples]
        return "\n\n".join(formatted_examples)

    def get_formatted_constraints(self):
        if not self.question_constraints:
            return ""
        constraints = [self.html_to_ansi(html) for html in self.question_constraints]
        constraints_str = "\n".join(constraints)
        return f"{self.HTML_TO_ANSI['constraints_string']}Constraints:{ANSI_RESET}\n\n{constraints_str}"


from ..data_fetching.graphql_data_fetchers.leetcode_problem_fetcher import LeetCodeProblemFetcher


title_slug = "two-sum"
metadata = LeetCodeProblemFetcher.fetch_problem_data(title_slug)

l = LeetCodeProblemParser(metadata)
print(l.get_formatted_title())
print(l.get_formatted_description())
print(l.get_formatted_examples())
print("\n")
print(l.get_formatted_constraints())



File path: parsers/parser_utils/leetcode_stats_parser.py:
# TODO: Fix deprecated values

import json
from datetime import datetime, timezone

from ...graphics.escape_sequences import ANSI_CODES, ANSI_RESET

def join_and_slice_calendars(previous_year_calendar, current_year_calendar):
    if not previous_year_calendar or not current_year_calendar:
        return {}

    try:
        # Load activity data from JSON strings
        previous_activity = json.loads(
            previous_year_calendar['data']['matchedUser']['userCalendar']['submissionCalendar']
        )
        current_activity = json.loads(
            current_year_calendar['data']['matchedUser']['userCalendar']['submissionCalendar']
        )

    except KeyError as error:
        print(f"Missing key in submission_calendar data: {error}")
        return {}

    except json.JSONDecodeError as error:
        print(f"JSON decoding error: {error}")
        return {}

    # Merge activities ensuring the combined dictionary has all timestamps
    merged_activity = {**previous_activity, **current_activity}

    # Convert keys to integers
    merged_activity = {int(timestamp): count for timestamp, count in merged_activity.items()}

    # Get today's date in UTC
    today_utc = datetime.utcnow().date()

    # Handle the special case for leap years
    if today_utc.month == 2 and today_utc.day == 29:
        # Roll back to March 1 of the previous year
        start_date = today_utc.replace(year=today_utc.year - 1, month=3, day=1)
    else:
        start_date = today_utc.replace(year=today_utc.year - 1)

    # Create start and end datetime objects without using `combine`
    start_datetime = datetime(
        year=start_date.year,
        month=start_date.month,
        day=start_date.day,
        hour=0,
        minute=0,
        second=0,
        tzinfo=timezone.utc
    )

    end_datetime = datetime(
        year=today_utc.year,
        month=today_utc.month,
        day=today_utc.day,
        hour=0,
        minute=0,
        second=0,
        tzinfo=timezone.utc
    )

    start_timestamp = int(start_datetime.timestamp())
    end_timestamp = int(end_datetime.timestamp())

    sliced_activity = {timestamp : count for timestamp, count in merged_activity.items() if start_timestamp <= timestamp < end_timestamp}

    return sliced_activity


def fill_daily_activity(daily_activity):
    filled_activity = {}
    today_utc = datetime.utcnow().date()

    # Handle the special case for leap years
    if today_utc.month == 2 and today_utc.day == 29:
        start_date = today_utc.replace(year=today_utc.year - 1, month=3, day=1)
    else:
        start_date = today_utc.replace(year=today_utc.year - 1)

    # Create start and end datetime objects without using `combine`
    start_datetime = datetime(
        year=start_date.year,
        month=start_date.month,
        day=start_date.day,
        hour=0,
        minute=0,
        second=0,
        tzinfo=timezone.utc
    )
    end_datetime = datetime(
        year=today_utc.year,
        month=today_utc.month,
        day=today_utc.day,
        hour=0,
        minute=0,
        second=0,
        tzinfo=timezone.utc
    )

    # Convert to timestamps
    start_timestamp = int(start_datetime.timestamp())
    end_timestamp = int(end_datetime.timestamp())

    # Generate all daily timestamps within the past year
    current_timestamp = start_timestamp

    while current_timestamp <= end_timestamp:
        filled_activity[current_timestamp] = daily_activity.get(current_timestamp, 0)
        current_timestamp += 86400  # Increment by one day (in seconds)

    return filled_activity


def calculate_color(submissions: int, max_submissions: int, min_submission: int) -> str:
    CUSTOM_GREENS = [ANSI_CODES["GREEN1"], ANSI_CODES["GREEN2"], ANSI_CODES["GREEN3"], ANSI_CODES["GREEN4"],
                     ANSI_CODES["GREEN5"], ANSI_CODES["GREEN6"]]
    
    if max_submissions == min_submission:
        # Avoid division by zero; default to the brightest green
        return f"\033[38;2;{CUSTOM_GREENS[-1][0]};{CUSTOM_GREENS[-1][1]};{CUSTOM_GREENS[-1][2]}m"
    
    # Normalize submissions to a value between 0 and 1
    normalized = (submissions - min_submission) / (max_submissions - min_submission)
    normalized = max(0.0, min(1.0, normalized))  # Clamp between 0 and 1
    
    # Determine the index in the CUSTOM_GREENS list
    index = int(normalized * (len(CUSTOM_GREENS) - 1))
    
    return CUSTOM_GREENS[index]

File path: leetcode_problem/submit_problem.py:
from ..user_utils import extract_csrf_token, load_cookie

import requests
import time


def map_extension_to_language(file_extension):
    extension_mapping = {
        "py": "python3",
        "js": "javascript",
        "ts": "typescript",
        "java": "java",
        "c": "c",
        "cpp": "cpp",
        "cs": "csharp",
        "rb": "ruby",
        "php": "php",
        "swift": "swift",
        "kt": "kotlin",
        "go": "golang",
        "rs": "rust",
        "scala": "scala",
        "sql": "mysql",
        "sh": "bash",
        "dart": "dart",
    }

    normalized_extension = file_extension.lstrip(".").lower()
    return extension_mapping.get(normalized_extension, None)


def submit_solution(cookie, title_slug, question_id, solution_file_path):
    SUBMIT_URL = f"https://leetcode.com/problems/{title_slug}/submit/"
    csrf_token = extract_csrf_token(cookie)

    if csrf_token == None:
        print("Error: csrf_token is None")
        return None

    try:
        with open(solution_file_path, 'r', encoding='utf-8') as file:
            code = file.read()

    except IOError as e:
        print(f"Error reading solution file: {e}")
        return -1

    # Determine language from file extension
    try:
        file_extension = solution_file_path[solution_file_path.rindex(".") + 1:]

    except ValueError:
        print("Solution file path is incorrect.")
        return None

    language = map_extension_to_language(file_extension)
    if not language:
        print("Unknown file extension.")
        return None

    # Create submission payload
    payload = {
        "lang": language,
        "question_id": str(question_id),
        "typed_code": code,
    }

    # Set headers
    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0",
        "Cookie": cookie,
        "x-csrftoken": csrf_token,
        "Referer": f"https://leetcode.com/problems/{title_slug}/",
    }

    # Submit code
    response = requests.post(SUBMIT_URL, json=payload, headers=headers)
    response.raise_for_status()
    submission = response.json()

    return submission.get('submission_id', None)


def check_submission(cookie, submission_id, title_slug):
    CHECK_SUBMISSION_URL = f"https://leetcode.com/submissions/detail/{submission_id}/check/"

    csrf_token = extract_csrf_token(cookie)

    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0",
        "Cookie": cookie,
        "x-csrftoken": csrf_token,
        "Referer": f"https://leetcode.com/problems/{title_slug}/",
    }

    while True:
        response = requests.get(CHECK_SUBMISSION_URL, headers=headers)
        response.raise_for_status()
        submission_result = response.json()

        if submission_result.get('state') == "SUCCESS":
            return submission_result

        time.sleep(0.25)


def submit_and_get_result(cookie, title_slug, question_id, solution_file_path):
    submission_id = submit_solution(cookie, title_slug, question_id, solution_file_path)

    if submission_id == -1:
        return None

    submission_result = check_submission(cookie, submission_id, title_slug)
    return submission_result

cookie = load_cookie()
x = submit_and_get_result(cookie, "two-sum", "1", "sol.py")
from ..parsers.submission_parser import parse_submission
print(parse_submission(x))

File path: graphics/escape_sequences.py:
ANSI_RESET = "\033[0m"       # Reset all styles

ANSI_CODES = {
    # Foreground colors
    "GREEN"         : "\033[32m",
    "ORANGE"        : "\033[38;5;208m",
    "RED"           : "\033[31m",
    "GRAY"          : "\033[90m",
    "CYAN"          : "\033[96m",
    
    # Colors to display stats
    "GREEN1"        : f"\033[38;2;1;155;1m",
    "GREEN2"        : f"\033[38;2;16;175;16m",
    "GREEN3"        : f"\033[38;2;33;195;33m",
    "GREEN4"        : f"\033[38;2;61;215;61m",
    "GREEN5"        : f"\033[38;2;82;235;82m",
    "GREEN6"        : f"\033[38;2;100;255;100m",

    # Background Colors
    "GRAY_BG"       : "\033[100m",
    "GREEN_BG"      : "\033[42m",
    "ORANGE_BG"     : "\033[48;5;208m",
    "RED_BG": "\033[41m", 


    # Styles
    "BOLD"          : "\033[1m",
    "ITALIC"        : "\033[3m",
    "UNDERLINE"     : "\033[4m",
}

File path: graphics/symbols.py:
SYMBOLS = {
    "FILLED_SQUARE" : "◼",
    "EMPTY_SQUARE"  : "▫",
    
    "CARET" : "^",
    "DOT"   : "•",

    "CHECKMARK" : "✔",
    "X" : "✘",
    "ATTEMPTED" : "❋"
}

File path: data_fetching/api_data_fetchers/leetcode_problems.py:
import json
import requests

def fetch_leetcode_problems():
    API_URL = "https://leetcode.com/api/problems/algorithms/"

    try:
        response = requests.get(API_URL)
        response.raise_for_status()  # Raise an exception for HTTP errors

    except requests.RequestException as e:
        print(f"Error: Failed to fetch problems from LeetCode API. Details: {e}")
        return None

    try:
        data = response.json()

    except json.JSONDecodeError:
        print("Error: Failed to parse JSON response from LeetCode API.")
        return None

    # Initialize the list to hold problem details
    problems = []

    # Iterate over each problem entry in the response
    for pair in data.get("stat_status_pairs", []):
        stat = pair.get("stat", {})
        
        # Extract difficulty level and map it to string
        difficulty_level = pair.get("difficulty", {}).get("level", 0)
        
        # Extract passed_submissions and total_submissions
        passed_submissions = pair.get("stat", {}).get("total_acs", 0)
        total_submissions = pair.get("stat", {}).get("total_submitted", 0)
        
        problem = {
            "title": stat.get("question__title"),
            "title_slug": stat.get("question__title_slug"),
            "question_id": stat.get("question_id"),
            "is_paid_only": pair.get("paid_only", False),
            "difficulty": difficulty_level,
            "passed_submissions": passed_submissions,
            "total_submissions": total_submissions
        }

        problems.append(problem)

    print(f"Fetched {len(problems)} problems.")
    return problems

File path: data_fetching/graphql_data_fetchers/leetcode_stats.py:
from ..graphql_data_fetchers.graphql_queries import GRAPHQL_QUERIES, GRAPHQL_URL

import requests

def fetch_leetcode_stats(username):
    if not username:
        print("Error: Username was not found in config file nor provided in this call.")
        return None

    payload = {
        "query": GRAPHQL_QUERIES['user_problem_stats'],

        "variables": {
            "userSlug": username
        },

        "operationName": "userProfileUserQuestionProgressV2"
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)
        if response.status_code == 200:
            result = response.json()

            if "errors" in result:
                print(f"Error from API: {result['errors']}")
                return None

            return result

        elif response.status_code == 401:
            print("Error: Unauthorized. Cookie might be invalid or expired.")

        else:
            print(f"Error: Failed to fetch stats. HTTP Status Code: {response.status_code}")
    except requests.RequestException as e:

        print(f"Error: Network or API issue occurred: {e}")

    return None


def fetch_leetcode_activity(username, year):
    if not username:
        print("Error: Username was not found in config file nor provided in this call.")
        return None


    if year is None:
        print("Error: year is None")
        return None

    payload = {
        "query": GRAPHQL_QUERIES['user_calendar'],
        "variables": {
            "username": username,
            "year": year
        },
        "operationName": "userProfileCalendar"
    }

    try:
        response = requests.post(GRAPHQL_URL, json=payload)

        if response.status_code == 200:
            result = response.json()

            if "errors" in result:
                print(f"Error from API: {result['errors']}")
                return None

            return result

        elif response.status_code == 401:
            print("Error: Unauthorized. Cookie might be invalid or expired.")

        else:
            print(f"Error: Failed to fetch activity data. HTTP Status Code: {response.status_code}")

    except requests.RequestException as e:
        print(f"Error: Network or API issue occurred: {e}")

    return None


File path: data_fetching/graphql_data_fetchers/graphql_queries.py:
GRAPHQL_URL = "https://leetcode.com/graphql"

GRAPHQL_QUERIES = {
    'user_problem_stats': """
        query userProfileUserQuestionProgressV2($userSlug: String!) {
          userProfileUserQuestionProgressV2(userSlug: $userSlug) {
            numAcceptedQuestions {
              count
              difficulty
            }
            numFailedQuestions {
              count
              difficulty
            }
            numUntouchedQuestions {
              count
              difficulty
            }
            userSessionBeatsPercentage {
              difficulty
              percentage
            }
            totalQuestionBeatsPercentage
          }
        }
    """,

    'user_calendar': """
        query userProfileCalendar($username: String!, $year: Int) {
          matchedUser(username: $username) {
            userCalendar(year: $year) {
              activeYears
              streak
              totalActiveDays
              dccBadges {
                timestamp
                badge {
                  name
                  icon
                }
              }
              submissionCalendar
            }
          }
        }
    """,

    'problems_by_tags': """
        query problemsetQuestionList($categorySlug: String, $limit: Int, $skip: Int, $filters: QuestionListFilterInput) {
          problemsetQuestionList: questionList(
            categorySlug: $categorySlug
            limit: $limit
            skip: $skip
            filters: $filters
          ) {
            total: totalNum
            questions: data {
              acRate
              difficulty
              freqBar
              frontendQuestionId: questionFrontendId
              isFavor
              paidOnly: isPaidOnly
              status
              title
              titleSlug
              topicTags {
                name
                id
                slug
              }
              hasSolution
              hasVideoSolution
            }
          }
        }
    """
}

File path: data_fetching/graphql_data_fetchers/leetcode_problem_fetcher.py:
from ..graphql_data_fetchers.graphql_queries import GRAPHQL_QUERIES, GRAPHQL_URL 

from ...user_utils import load_cookie, extract_csrf_token

import requests

class LeetCodeProblemFetcher:

    @staticmethod
    def fetch_problemset(tags, limit=50, skip=0, category_slug="all-code-essentials"):
        if not category_slug:
            print("Error: category_slug is required but not provided.")
            return None

        if not isinstance(tags, list):
            print("Error: tags must be a list of strings.")
            return None


        payload = {
            "query": GRAPHQL_QUERIES['problems_by_tags'],
            "variables": {
                "categorySlug": category_slug,
                "skip": skip,
                "limit": limit,
                "filters": {}
            },
            "operationName": "problemsetQuestionList"
        }

        if tags:
            payload["variables"]["filters"]["tags"] = tags
            print("found tags")


        cookie = load_cookie()
        headers = None

        if cookie:
            headers = {
                "Content-Type": "application/json",
                "User-Agent": "Mozilla/5.0",
                "Cookie": cookie,
                "x-csrftoken": extract_csrf_token(cookie),
                "Referer": f"https://leetcode.com/problemset/",
            }


        try:
            if cookie:
                response = requests.post(GRAPHQL_URL, json=payload, headers=headers)
            else:
                response = requests.post(GRAPHQL_URL, json=payload)
            
            if response.status_code == 200:
                result = response.json()

                if "errors" in result:
                    print(f"Error from API: {result['errors']}")
                    return None

                return result

            elif response.status_code == 401:
                print("Error: Unauthorized. Cookie might be invalid or expired.")

            else:
                print(f"Error: Failed to fetch problems. HTTP Status Code: {response.status_code}")

        except requests.RequestException as e:
            print(f"Error: Network or API issue occurred: {e}")

        return None

    @staticmethod
    def fetch_problem_data(title_slug):
        if not title_slug:
            print("Error: title_slug is required but not provided.")
            return None

        query = """
        query questionData($titleSlug: String!) {
          question(titleSlug: $titleSlug) {
            questionId
            title
            titleSlug
            content
            difficulty
            likes
            dislikes
            exampleTestcases
            topicTags {
              name
              slug
            }
            hints
            isPaidOnly
          }
        }
        """

        payload = {
            "query": query,
            "variables": {
                "titleSlug": title_slug
            },
            "operationName": "questionData"
        }

        try:
            response = requests.post(GRAPHQL_URL, json=payload)
            
            if response.status_code == 200:
                result = response.json()

                if "errors" in result:
                    print(f"Error from API: {result['errors']}")
                    return None

                return result

            elif response.status_code == 401:
                print("Error: Unauthorized. Cookie might be invalid or expired.")

            else:
                print(f"Error: Failed to fetch question details. HTTP Status Code: {response.status_code}")

        except requests.RequestException as e:
            print(f"Error: Network or API issue occurred: {e}")

        return None
